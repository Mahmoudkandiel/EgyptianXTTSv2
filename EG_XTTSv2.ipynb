{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports + Git"
      ],
      "metadata": {
        "id": "p0MQd_i1HGp_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "KoIzNXnRNCL4",
        "outputId": "63a994fa-7457-4434-ce70-5651a0897d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TTS'...\n",
            "remote: Enumerating objects: 32844, done.\u001b[K\n",
            "remote: Counting objects: 100% (2774/2774), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 32844 (delta 2725), reused 2701 (delta 2701), pack-reused 30070 (from 1)\u001b[K\n",
            "Receiving objects: 100% (32844/32844), 166.14 MiB | 14.02 MiB/s, done.\n",
            "Resolving deltas: 100% (23844/23844), done.\n",
            "/content/TTS\n",
            "Obtaining file:///content/TTS\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.22.0 (from TTS==0.22.0)\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (3.0.11)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (1.13.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (0.12.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (0.10.2.post1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (0.60.0)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (7.4.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (4.67.1)\n",
            "Collecting anyascii>=0.3.0 (from TTS==0.22.0)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (3.11.10)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (24.2)\n",
            "Collecting mutagen==1.47.0 (from TTS==0.22.0)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (3.1.0)\n",
            "Collecting pysbd>=0.3.4 (from TTS==0.22.0)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting umap-learn>=0.5.1 (from TTS==0.22.0)\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pandas<2.0,>=1.4 (from TTS==0.22.0)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (3.8.0)\n",
            "Collecting trainer>=0.0.36 (from TTS==0.22.0)\n",
            "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting coqpit>=0.0.16 (from TTS==0.22.0)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (0.42.1)\n",
            "Collecting pypinyin (from TTS==0.22.0)\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hangul_romanize (from TTS==0.22.0)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS==0.22.0)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (3.9.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS==0.22.0)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting bangla (from TTS==0.22.0)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting bnnumerizer (from TTS==0.22.0)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from TTS==0.22.0)\n",
            "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (0.8.0)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from TTS==0.22.0) (4.47.1)\n",
            "Collecting encodec>=0.1.1 (from TTS==0.22.0)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from TTS==0.22.0)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting num2words (from TTS==0.22.0)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS==0.22.0) (3.7.5)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (2.16.0)\n",
            "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS==0.22.0)\n",
            "  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting black (from TTS==0.22.0)\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coverage (from TTS==0.22.0)\n",
            "  Downloading coverage-7.6.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting isort (from TTS==0.22.0)\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nose2 (from TTS==0.22.0)\n",
            "  Downloading nose2-0.15.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pylint==2.10.2 (from TTS==0.22.0)\n",
            "  Downloading pylint-2.10.2-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting bokeh==1.4.0 (from TTS==0.22.0)\n",
            "  Downloading bokeh-1.4.0.tar.gz (32.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.4/32.4 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mecab-python3==1.0.6 (from TTS==0.22.0)\n",
            "  Downloading mecab_python3-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting unidic-lite==1.0.8 (from TTS==0.22.0)\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cutlet (from TTS==0.22.0)\n",
            "  Downloading cutlet-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==1.4.0->TTS==0.22.0) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==1.4.0->TTS==0.22.0) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.10/dist-packages (from bokeh==1.4.0->TTS==0.22.0) (3.1.4)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==1.4.0->TTS==0.22.0) (11.0.0)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.10/dist-packages (from bokeh==1.4.0->TTS==0.22.0) (6.3.3)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pylint==2.10.2->TTS==0.22.0) (4.3.6)\n",
            "Collecting astroid<2.8,>=2.7.2 (from pylint==2.10.2->TTS==0.22.0)\n",
            "  Downloading astroid-2.7.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting mccabe<0.7,>=0.6 (from pylint==2.10.2->TTS==0.22.0)\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pylint==2.10.2->TTS==0.22.0) (0.10.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS==0.22.0) (1.18.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS==0.22.0) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS==0.22.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS==0.22.0) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS==0.22.0) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS==0.22.0) (10.5.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS==0.22.0) (4.4.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa>=0.10.0 (from TTS==0.22.0)\n",
            "  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS==0.22.0) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS==0.22.0) (3.2.0)\n",
            "Collecting docopt>=0.6.2 (from num2words->TTS==0.22.0)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS==0.22.0) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS==0.22.0) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS==0.22.0) (3.5.0)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy>=1.11.2 (from TTS==0.22.0)\n",
            "  Downloading scipy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS==0.22.0) (1.17.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.15.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.10.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.5.0)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Downloading SudachiPy-0.6.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS==0.22.0)\n",
            "  Downloading SudachiDict_core-20241021-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS==0.22.0) (3.16.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS==0.22.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1->TTS==0.22.0) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.36->TTS==0.22.0) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.36->TTS==0.22.0) (2.17.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS==0.22.0) (0.27.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS==0.22.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS==0.22.0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS==0.22.0) (0.4.5)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS==0.22.0)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->TTS==0.22.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->TTS==0.22.0)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->TTS==0.22.0) (2.2.1)\n",
            "Collecting jaconv (from cutlet->TTS==0.22.0)\n",
            "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fugashi (from cutlet->TTS==0.22.0)\n",
            "  Downloading fugashi-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting mojimoji (from cutlet->TTS==0.22.0)\n",
            "  Downloading mojimoji-0.0.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting lazy-object-proxy>=1.4.0 (from astroid<2.8,>=2.7.2->pylint==2.10.2->TTS==0.22.0)\n",
            "  Downloading lazy_object_proxy-1.10.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
            "Collecting wrapt<1.13,>=1.11 (from astroid<2.8,>=2.7.2->pylint==2.10.2->TTS==0.22.0)\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS==0.22.0) (2.22)\n",
            "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->TTS==0.22.0)\n",
            "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS==0.22.0) (5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.7->bokeh==1.4.0->TTS==0.22.0) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (7.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (4.25.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.36->TTS==0.22.0) (0.7.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS==0.22.0) (0.1.2)\n",
            "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mecab_python3-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.6/581.6 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylint-2.10.2-py3-none-any.whl (392 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.6/392.6 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
            "Downloading coverage-7.6.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cutlet-0.5.0-py3-none-any.whl (11 kB)\n",
            "Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading nose2-0.15.1-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astroid-2.7.3-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiDict_core-20241021-py3-none-any.whl (72.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SudachiPy-0.6.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugashi-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.7/671.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mojimoji-0.0.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_object_proxy-1.10.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: TTS, gruut, bokeh, unidic-lite, encodec, bnnumerizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, jaconv, wrapt\n",
            "  Building editable for TTS (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TTS: filename=TTS-0.22.0-0.editable-cp310-cp310-linux_x86_64.whl size=15043 sha256=34a2131e1dba24055ac62ff79d447c49558e0d9a265a4ad93f429b9669c1211d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wss5ya2q/wheels/c4/ee/51/7ae272f137a19c06a50ae47c926e3eb3862d04b1e0fb0372ba\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75788 sha256=d6135768545e4090ad3774ee2bc73f25c93fedc2c6cd54f1e2f4ae7700b43a89\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bokeh: filename=bokeh-1.4.0-py3-none-any.whl size=23689190 sha256=192ffad95337078e56fdd1621e37f1aa0148fbcfadd0750f17b1d4499e38510c\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/59/c1/80a2a0b9fd3df425558ddb2afcfbd4b1a0d144c21d1ca388b0\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=88475b17fe0e1d601513d97bc33de10644dfae5c0b777473dd642380b19b1e86\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=ceb40d91fe6139097e0871152fe15424b1a59f7fee981a566bde94510c944504\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=782835721fe04b279dc97fda9d1e33a2cdb2cb579c4e7d784e9ee128927f67da\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=eaf0326c5c5002e6fd6eda740b95f0dcc265cd106c11be89b45eb73dc71ea23b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=4617b3e7b23fc2e4f9c38d9dbc072e011073ddf06a4213f2735985eff10be83f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498313 sha256=7a467aa6f7e2534b08145a7f2bb5c5ecf1d4b35ea7ce6f427429597491634b96\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/80/5f/775b357ae61d7cb68793327c7470d848715cbc60bb373af8dd\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326857 sha256=7eeaf3c6c05c321137da86bebb2f5a057a69c7e0e9acfaa03ba31e937a4d8e23\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/8d/b7/d484d224facd899ed188e00374f25dd3f19d1a3f53da6517bd\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173928 sha256=3239c29cd8b7a57337e30769e50cf7fcb117144efb4d5ddb4e5a395855d9dfac\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/bd/96/5ddde14e8e6932a96f12c5ab5de62b619d39e2507d7daf5188\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=8f8b7d2d742d42bba18f8f8545fd2c194397e36e149b838e850e2b4bdd3454db\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.4.0-py3-none-any.whl size=18229 sha256=aa7196e92f8da46d031e8e34abf3239c6892bfc327d12ae1dd1c4872f440f7f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/95/99/94e8d7545125181756857f6b1fc085ed4e0811ad9be7321af7\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp310-cp310-linux_x86_64.whl size=71454 sha256=e9bf7b29bfe827f37454f10673fb57fa78076af90aa8885933fb7d71af6eaf1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/61/d3/d9e7053100177668fa43216a8082868c55015f8706abd974f2\n",
            "Successfully built TTS gruut bokeh unidic-lite encodec bnnumerizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr jaconv wrapt\n",
            "Installing collected packages: wrapt, unidic-lite, sudachipy, mecab-python3, mccabe, jamo, jaconv, hangul_romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, python-crfsuite, pysbd, pypinyin, pathspec, numpy, num2words, nose2, networkx, mypy-extensions, mutagen, mojimoji, lazy-object-proxy, jsonlines, isort, gruut-ipa, fugashi, coverage, coqpit, anyascii, scipy, pandas, g2pkk, dateparser, cutlet, contourpy, bokeh, black, astroid, trainer, pylint, gruut, pynndescent, librosa, encodec, umap-learn, TTS\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.1\n",
            "    Uninstalling contourpy-1.3.1:\n",
            "      Successfully uninstalled contourpy-1.3.1\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 3.6.2\n",
            "    Uninstalling bokeh-3.6.2:\n",
            "      Successfully uninstalled bokeh-3.6.2\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.2.post1\n",
            "    Uninstalling librosa-0.10.2.post1:\n",
            "      Successfully uninstalled librosa-0.10.2.post1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.7 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "bigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "holoviews 1.20.0 requires bokeh>=3.1, but you have bokeh 1.4.0 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.0 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 1.22.0 which is incompatible.\n",
            "mizani 0.13.1 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "numexpr 2.10.2 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "panel 1.5.4 requires bokeh<3.7.0,>=3.5.0, but you have bokeh 1.4.0 which is incompatible.\n",
            "plotnine 0.14.4 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.25.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.11.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 astroid-2.7.3 bangla-0.0.2 black-24.10.0 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 bokeh-1.4.0 contourpy-1.2.1 coqpit-0.0.17 coverage-7.6.10 cutlet-0.5.0 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 fugashi-1.4.0 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul_romanize-0.1.0 isort-5.13.2 jaconv-0.4.0 jamo-0.4.1 jsonlines-1.2.0 lazy-object-proxy-1.10.0 librosa-0.10.0 mccabe-0.6.1 mecab-python3-1.0.6 mojimoji-0.0.13 mutagen-1.47.0 mypy-extensions-1.0.0 networkx-2.8.8 nose2-0.15.1 num2words-0.5.14 numpy-1.22.0 pandas-1.5.3 pathspec-0.12.1 pylint-2.10.2 pynndescent-0.5.13 pypinyin-0.53.0 pysbd-0.3.4 python-crfsuite-0.9.11 scipy-1.11.4 sudachidict-core-20241021 sudachipy-0.6.9 trainer-0.0.36 umap-learn-0.5.7 unidecode-1.3.8 unidic-lite-1.0.8 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "4750445d40fd46cbabc0e8c943c350bb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# prompt: ERROR: file:///content/TTS/TTS/tts/layers/xtts does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found\n",
        "\n",
        "!git clone https://github.com/coqui-ai/TTS\n",
        "%cd TTS\n",
        "!pip install -e .[all,dev,notebooks]  # Select the relevant extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "dsg7E7VvQ41p",
        "outputId": "8c6f88a6-70d4-4289-906a-d1d7b6f8e7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23\n",
            "  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.0\n",
            "    Uninstalling numpy-1.22.0:\n",
            "      Successfully uninstalled numpy-1.22.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.23.0 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.0 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.0 which is incompatible.\n",
            "bigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.23.0 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "holoviews 1.20.0 requires bokeh>=3.1, but you have bokeh 1.4.0 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.23.0 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
            "mizani 0.13.1 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "panel 1.5.4 requires bokeh<3.7.0,>=3.5.0, but you have bokeh 1.4.0 which is incompatible.\n",
            "plotnine 0.14.4 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n",
            "plotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.0 which is incompatible.\n",
            "scikit-image 0.25.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.23.0 which is incompatible.\n",
            "xarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.23.0 which is incompatible.\n",
            "xarray 2024.11.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "64c6e13bfcee4f8b8eba6365eed0a5cc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install numpy==1.23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lBsVlvhQCpO"
      },
      "source": [
        "Testing tokonizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neueFOpvOCt1"
      },
      "outputs": [],
      "source": [
        "from TTS.TTS.tts.layers.xtts.tokenizer import VoiceBpeTokenizer\n",
        "\n",
        "# Path to the vocab.json file\n",
        "vocab_path = \"/content/vocab.json\"\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = VoiceBpeTokenizer(vocab_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJXI9H8sOTfm",
        "outputId": "42c1c99d-10dd-47c2-d20c-37ff9864af8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Output: [5022, 3961, 4066, 3953, 2, 4268, 4105]\n"
          ]
        }
      ],
      "source": [
        "# Text to tokenize\n",
        "text = \"صباح الخير\"\n",
        "\n",
        "# Tokenize the text (encode it)\n",
        "tokens = tokenizer.encode(text, lang=\"ar\")\n",
        "\n",
        "# Print tokenized output\n",
        "print(\"Tokenized Output:\", tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset from Google drive"
      ],
      "metadata": {
        "id": "sRNyvnCdHLlS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e383J1qUQFKG"
      },
      "source": [
        "downloading dataset from google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "kzqhK_5jLlVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22dca57-b3bb-4cb5-f120-00e47ac3485f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1-EB55BAs92xLQa_sM3PptWZ6xlJ6yZhY"
      ],
      "metadata": {
        "id": "X_doWh_bLkqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942c5ad4-ca65-4c50-ee8e-24b5cb2ce66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-EB55BAs92xLQa_sM3PptWZ6xlJ6yZhY\n",
            "From (redirected): https://drive.google.com/uc?id=1-EB55BAs92xLQa_sM3PptWZ6xlJ6yZhY&confirm=t&uuid=6525b4d3-7f5a-40b6-9c62-adb9002f0923\n",
            "To: /content/txt_to_speech_dataset.zip\n",
            "100% 15.6G/15.6G [01:58<00:00, 132MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SevNM8-gQKOk",
        "outputId": "75db3f87-3f19-4862-80fa-35250d5c36a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully unzipped to /content/lJspeech\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create the target directory\n",
        "target_dir = '/content/lJspeech'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(\"/content/txt_to_speech_dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(target_dir)\n",
        "\n",
        "print(f'File successfully unzipped to {target_dir}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Config + Training"
      ],
      "metadata": {
        "id": "E3EsdsLQHYUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb5Qtm0fFLpy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from trainer import Trainer, TrainerArgs\n",
        "\n",
        "from TTS.config.shared_configs import BaseDatasetConfig\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig, XttsAudioConfig\n",
        "from TTS.utils.manage import ModelManager\n",
        "\n",
        "# Logging parameters\n",
        "RUN_NAME = \"GPT_XTTS_v2.0_LJSpeech_FT\"\n",
        "PROJECT_NAME = \"XTTS_trainer\"\n",
        "DASHBOARD_LOGGER = \"tensorboard\"\n",
        "LOGGER_URI = None\n",
        "\n",
        "# Set here the path that the checkpoints will be saved. Default: ./run/training/\n",
        "OUT_PATH = \"/content/run/training/\"\n",
        "\n",
        "# Training Parameters\n",
        "OPTIMIZER_WD_ONLY_ON_WEIGHTS = True  # for multi-gpu training please make it False\n",
        "START_WITH_EVAL = True  # if True it will star with evaluation\n",
        "BATCH_SIZE = 3  # set here the batch size\n",
        "GRAD_ACUMM_STEPS = 84  # set here the grad accumulation steps\n",
        "# Note: we recommend that BATCH_SIZE * GRAD_ACUMM_STEPS need to be at least 252 for more efficient training. You can increase/decrease BATCH_SIZE but then set GRAD_ACUMM_STEPS accordingly.\n",
        "\n",
        "# Define here the dataset that you want to use for the fine-tuning on.\n",
        "config_dataset = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\",\n",
        "    dataset_name=\"ljspeech\",\n",
        "    path=\"/content/lJspeech/\",\n",
        "    meta_file_train=\"/content/lJspeech/metadata.csv\",\n",
        "    language=\"ar\",\n",
        ")\n",
        "\n",
        "# Add here the configs of the datasets\n",
        "DATASETS_CONFIG_LIST = [config_dataset]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HChF56YIQvJL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the path where XTTS v2.0.1 files will be downloaded\n",
        "CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"XTTS_v2.0_original_model_files/\")\n",
        "os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)\n",
        "\n",
        "\n",
        "# DVAE files\n",
        "DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
        "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
        "\n",
        "# Set the path to the downloaded files\n",
        "DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n",
        "MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n",
        "\n",
        "# download DVAE files if needed\n",
        "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
        "    print(\" > Downloading DVAE files!\")\n",
        "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=False)\n",
        "\n",
        "\n",
        "# Download XTTS v2.0 checkpoint if needed\n",
        "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
        "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
        "\n",
        "# XTTS transfer learning parameters: You we need to provide the paths of XTTS model checkpoint that you want to do the fine tuning.\n",
        "TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json file\n",
        "XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth file\n",
        "\n",
        "# download XTTS v2.0 files if needed\n",
        "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
        "    print(\" > Downloading XTTS v2.0 files!\")\n",
        "    ModelManager._download_model_files(\n",
        "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=False\n",
        "    )\n",
        "\n",
        "\n",
        "# Training sentences generations\n",
        "SPEAKER_REFERENCE = [\n",
        "    \"/content/lJspeech/wavs/audio_10302.wav\"  # speaker reference to be used in training test sentences\n",
        "]\n",
        "LANGUAGE = config_dataset.language\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV2M826XRT5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973ae6e0-7f5c-4fb0-a3a3-bbe22049c898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> DVAE weights restored from: /content/run/training/XTTS_v2.0_original_model_files/dvae.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: False\n",
            " | > Precision: float32\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 1\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Found 38158 files in /content/lJspeech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Start Tensorboard: tensorboard --logdir=/content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000\n",
            "\n",
            " > Model has 518442047 parameters\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Filtering invalid eval samples!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Total eval samples after filtering: 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/TTS/TTS/tts/layers/xtts/trainer/gpt_trainer.py:277: UserWarning: \"kaiser_window\" resampling method name is being deprecated and replaced by \"sinc_interp_kaiser\" in the next release. The default behavior remains unchanged.\n",
            "  dvae_wav = torchaudio.functional.resample(\n",
            "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.09169619784635656 \u001b[0m(+0)\n",
            "     | > avg_loss_text_ce: 0.04040187088882221 \u001b[0m(+0)\n",
            "     | > avg_loss_mel_ce: 3.3352582314435173 \u001b[0m(+0)\n",
            "     | > avg_loss: 3.375660099702723 \u001b[0m(+0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/1000\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "\u001b[1m > TRAINING (2025-01-05 06:50:42) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Sampling by language: dict_keys(['ar'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:50:48 -- STEP: 0/12634 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > loss_text_ce: 0.042523689568042755  (0.042523689568042755)\n",
            "     | > loss_mel_ce: 3.792584180831909  (3.792584180831909)\n",
            "     | > loss: 0.04565604776144028  (0.04565604776144028)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.8857  (0.8856673240661621)\n",
            "     | > loader_time: 5.0869  (5.086939096450806)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:51:16 -- STEP: 50/12634 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > loss_text_ce: 0.03893004730343819  (0.040669028237462025)\n",
            "     | > loss_mel_ce: 3.3096044063568115  (3.5323894834518432)\n",
            "     | > loss: 0.039863504469394684  (0.04253641158342361)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3447  (0.33841997623443604)\n",
            "     | > loader_time: 0.0117  (0.02016297340393066)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:51:45 -- STEP: 100/12634 -- GLOBAL_STEP: 100\u001b[0m\n",
            "     | > loss_text_ce: 0.04068758711218834  (0.04070717386901377)\n",
            "     | > loss_mel_ce: 3.6755995750427246  (3.5176886749267577)\n",
            "     | > loss: 0.044241514056921005  (0.04236185610294342)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3496  (0.34368489027023313)\n",
            "     | > loader_time: 0.0257  (0.018990848064422597)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:52:14 -- STEP: 150/12634 -- GLOBAL_STEP: 150\u001b[0m\n",
            "     | > loss_text_ce: 0.038870252668857574  (0.04069924004375933)\n",
            "     | > loss_mel_ce: 3.2763586044311523  (3.4935718901952106)\n",
            "     | > loss: 0.03946701064705849  (0.042074657057722405)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.344  (0.3468423112233479)\n",
            "     | > loader_time: 0.023  (0.019219326972961415)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:52:45 -- STEP: 200/12634 -- GLOBAL_STEP: 200\u001b[0m\n",
            "     | > loss_text_ce: 0.03833475708961487  (0.040553164053708325)\n",
            "     | > loss_mel_ce: 2.9009172916412354  (3.456208863258362)\n",
            "     | > loss: 0.03499109670519829  (0.04162812009453774)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4342  (0.35191089510917656)\n",
            "     | > loader_time: 0.0107  (0.018602604866027817)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:53:16 -- STEP: 250/12634 -- GLOBAL_STEP: 250\u001b[0m\n",
            "     | > loss_text_ce: 0.039853692054748535  (0.040582872629165656)\n",
            "     | > loss_mel_ce: 3.569167137145996  (3.4183996381759645)\n",
            "     | > loss: 0.04296453297138214  (0.04117836397886277)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4473  (0.35620915412902826)\n",
            "     | > loader_time: 0.0118  (0.017899673461914054)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:53:47 -- STEP: 300/12634 -- GLOBAL_STEP: 300\u001b[0m\n",
            "     | > loss_text_ce: 0.03920523449778557  (0.04060870282351971)\n",
            "     | > loss_mel_ce: 3.299506664276123  (3.3804520146052033)\n",
            "     | > loss: 0.03974657133221626  (0.04072691402087609)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3553  (0.3578650554021199)\n",
            "     | > loader_time: 0.0183  (0.017994502385457353)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:54:18 -- STEP: 350/12634 -- GLOBAL_STEP: 350\u001b[0m\n",
            "     | > loss_text_ce: 0.04294793680310249  (0.04060200387878079)\n",
            "     | > loss_mel_ce: 3.3000049591064453  (3.3531819799968163)\n",
            "     | > loss: 0.03979706019163132  (0.04040219101522649)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4386  (0.35961502347673674)\n",
            "     | > loader_time: 0.0098  (0.017783023289271758)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:54:48 -- STEP: 400/12634 -- GLOBAL_STEP: 400\u001b[0m\n",
            "     | > loss_text_ce: 0.040709156543016434  (0.040598635766655206)\n",
            "     | > loss_mel_ce: 3.3269379138946533  (3.3264846503734575)\n",
            "     | > loss: 0.04009103775024414  (0.04008432556875047)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3561  (0.36069212615489943)\n",
            "     | > loader_time: 0.0147  (0.01732620179653167)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:55:19 -- STEP: 450/12634 -- GLOBAL_STEP: 450\u001b[0m\n",
            "     | > loss_text_ce: 0.04098229855298996  (0.04060135270986292)\n",
            "     | > loss_mel_ce: 2.692903518676758  (3.3010383314556537)\n",
            "     | > loss: 0.032546259462833405  (0.03978142551249925)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3531  (0.3616169023513793)\n",
            "     | > loader_time: 0.0258  (0.017401317490471715)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:55:50 -- STEP: 500/12634 -- GLOBAL_STEP: 500\u001b[0m\n",
            "     | > loss_text_ce: 0.039325371384620667  (0.0405896802470088)\n",
            "     | > loss_mel_ce: 3.374781608581543  (3.2774712128639214)\n",
            "     | > loss: 0.04064413160085678  (0.03950072564184663)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3655  (0.36256258487701404)\n",
            "     | > loader_time: 0.0101  (0.01726150608062742)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:56:21 -- STEP: 550/12634 -- GLOBAL_STEP: 550\u001b[0m\n",
            "     | > loss_text_ce: 0.04198407381772995  (0.040603387003595184)\n",
            "     | > loss_mel_ce: 2.718740463256836  (3.2579020673578434)\n",
            "     | > loss: 0.032865770161151886  (0.039267922792245016)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4233  (0.36400643522089166)\n",
            "     | > loader_time: 0.0121  (0.017209964232011255)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:56:53 -- STEP: 600/12634 -- GLOBAL_STEP: 600\u001b[0m\n",
            "     | > loss_text_ce: 0.04040238633751869  (0.04061215136200189)\n",
            "     | > loss_mel_ce: 2.825819969177246  (3.2331586555639897)\n",
            "     | > loss: 0.03412169590592384  (0.03897346269028881)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4545  (0.3656030702590941)\n",
            "     | > loader_time: 0.029  (0.01740194598833719)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:57:24 -- STEP: 650/12634 -- GLOBAL_STEP: 650\u001b[0m\n",
            "     | > loss_text_ce: 0.04080637916922569  (0.04059091970897639)\n",
            "     | > loss_mel_ce: 2.7904491424560547  (3.2139317651895376)\n",
            "     | > loss: 0.033705420792102814  (0.038744318364904495)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3653  (0.36593474278083205)\n",
            "     | > loader_time: 0.0103  (0.017175963108356177)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:57:54 -- STEP: 700/12634 -- GLOBAL_STEP: 700\u001b[0m\n",
            "     | > loss_text_ce: 0.040390659123659134  (0.04057042634912901)\n",
            "     | > loss_mel_ce: 2.561603546142578  (3.196154821940831)\n",
            "     | > loss: 0.030976122245192528  (0.038532444118921254)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.373  (0.36582896062306014)\n",
            "     | > loader_time: 0.0117  (0.017273151193346284)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:58:25 -- STEP: 750/12634 -- GLOBAL_STEP: 750\u001b[0m\n",
            "     | > loss_text_ce: 0.04151024669408798  (0.04054280887544159)\n",
            "     | > loss_mel_ce: 2.5549466609954834  (3.176149395306905)\n",
            "     | > loss: 0.030910203233361244  (0.03829395548005899)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3675  (0.3659961722691855)\n",
            "     | > loader_time: 0.025  (0.017388140042622874)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:58:56 -- STEP: 800/12634 -- GLOBAL_STEP: 800\u001b[0m\n",
            "     | > loss_text_ce: 0.04322825372219086  (0.04052170457318429)\n",
            "     | > loss_mel_ce: 2.8392693996429443  (3.1607360923290253)\n",
            "     | > loss: 0.03431544825434685  (0.038110212543979255)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3635  (0.3662317502498628)\n",
            "     | > loader_time: 0.0099  (0.01731540024280547)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:59:26 -- STEP: 850/12634 -- GLOBAL_STEP: 850\u001b[0m\n",
            "     | > loss_text_ce: 0.042347539216279984  (0.04051309654817865)\n",
            "     | > loss_mel_ce: 2.990776300430298  (3.1457739549524644)\n",
            "     | > loss: 0.03610861673951149  (0.037931989396319664)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.373  (0.3661054086685182)\n",
            "     | > loader_time: 0.0138  (0.017303737472085363)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 06:59:57 -- STEP: 900/12634 -- GLOBAL_STEP: 900\u001b[0m\n",
            "     | > loss_text_ce: 0.04206102341413498  (0.04045511643505762)\n",
            "     | > loss_mel_ce: 3.1428403854370117  (3.130042875342899)\n",
            "     | > loss: 0.03791549429297447  (0.037744024389733864)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3609  (0.36620981454849255)\n",
            "     | > loader_time: 0.0316  (0.017304591867658797)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:00:28 -- STEP: 950/12634 -- GLOBAL_STEP: 950\u001b[0m\n",
            "     | > loss_text_ce: 0.045321300625801086  (0.04045458091324884)\n",
            "     | > loss_mel_ce: 2.7750282287597656  (3.1152004874380013)\n",
            "     | > loss: 0.03357559069991112  (0.03756732291492976)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.363  (0.36665949972052336)\n",
            "     | > loader_time: 0.0091  (0.017272498984085876)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:00:59 -- STEP: 1000/12634 -- GLOBAL_STEP: 1000\u001b[0m\n",
            "     | > loss_text_ce: 0.040939655154943466  (0.040420380424708156)\n",
            "     | > loss_mel_ce: 2.9816908836364746  (3.101370196580887)\n",
            "     | > loss: 0.035983696579933167  (0.037402269450947635)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.35  (0.3667120821475984)\n",
            "     | > loader_time: 0.0266  (0.01727905774116515)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:01:30 -- STEP: 1050/12634 -- GLOBAL_STEP: 1050\u001b[0m\n",
            "     | > loss_text_ce: 0.0386696383357048  (0.04037323710819088)\n",
            "     | > loss_mel_ce: 2.6148934364318848  (3.0899901567186627)\n",
            "     | > loss: 0.03159003704786301  (0.03726623154999245)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3489  (0.3670298031398229)\n",
            "     | > loader_time: 0.0255  (0.017276313645499086)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:02:01 -- STEP: 1100/12634 -- GLOBAL_STEP: 1100\u001b[0m\n",
            "     | > loss_text_ce: 0.038817089051008224  (0.04031821901148019)\n",
            "     | > loss_mel_ce: 2.96826171875  (3.077830952731046)\n",
            "     | > loss: 0.035798557102680206  (0.03712082415311175)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3605  (0.3670910653201019)\n",
            "     | > loader_time: 0.0201  (0.01724433335390957)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:02:32 -- STEP: 1150/12634 -- GLOBAL_STEP: 1150\u001b[0m\n",
            "     | > loss_text_ce: 0.03828522562980652  (0.04030327428942145)\n",
            "     | > loss_mel_ce: 2.9658594131469727  (3.068143586490467)\n",
            "     | > loss: 0.03576362878084183  (0.03700532045053401)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4374  (0.3674745932869291)\n",
            "     | > loader_time: 0.0091  (0.01705690383911132)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:03:03 -- STEP: 1200/12634 -- GLOBAL_STEP: 1200\u001b[0m\n",
            "     | > loss_text_ce: 0.03751160204410553  (0.0402602411837628)\n",
            "     | > loss_mel_ce: 2.9598605632781982  (3.0591503759225227)\n",
            "     | > loss: 0.035683002322912216  (0.036897746102574)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3488  (0.36769744972387963)\n",
            "     | > loader_time: 0.0277  (0.017050116260846446)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:03:33 -- STEP: 1250/12634 -- GLOBAL_STEP: 1250\u001b[0m\n",
            "     | > loss_text_ce: 0.04017380252480507  (0.04022640464901927)\n",
            "     | > loss_mel_ce: 2.855104446411133  (3.0484499383926416)\n",
            "     | > loss: 0.03446760028600693  (0.03676995713114741)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.355  (0.3677320709228516)\n",
            "     | > loader_time: 0.0218  (0.017113433265686016)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:04:04 -- STEP: 1300/12634 -- GLOBAL_STEP: 1300\u001b[0m\n",
            "     | > loss_text_ce: 0.03931991383433342  (0.04019626378153381)\n",
            "     | > loss_mel_ce: 2.842406749725342  (3.0385235480161836)\n",
            "     | > loss: 0.034306272864341736  (0.03665142700362665)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3668  (0.36769215547121487)\n",
            "     | > loader_time: 0.0122  (0.01709724554648765)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:04:35 -- STEP: 1350/12634 -- GLOBAL_STEP: 1350\u001b[0m\n",
            "     | > loss_text_ce: 0.036499667912721634  (0.040152101693330014)\n",
            "     | > loss_mel_ce: 2.6279475688934326  (3.029978080502265)\n",
            "     | > loss: 0.03171961009502411  (0.03654916951363837)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3727  (0.3678115406742802)\n",
            "     | > loader_time: 0.0108  (0.017051901817321788)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:05:05 -- STEP: 1400/12634 -- GLOBAL_STEP: 1400\u001b[0m\n",
            "     | > loss_text_ce: 0.0386236310005188  (0.04012857177960022)\n",
            "     | > loss_mel_ce: 2.975620985031128  (3.0190594775336157)\n",
            "     | > loss: 0.035883866250514984  (0.036418906023193684)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3736  (0.36771505355834944)\n",
            "     | > loader_time: 0.0287  (0.017069584642137814)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:05:36 -- STEP: 1450/12634 -- GLOBAL_STEP: 1450\u001b[0m\n",
            "     | > loss_text_ce: 0.03928719088435173  (0.040112546073465524)\n",
            "     | > loss_mel_ce: 2.679401159286499  (3.0084930817834286)\n",
            "     | > loss: 0.0323653370141983  (0.03629292481803688)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3606  (0.3675095923193568)\n",
            "     | > loader_time: 0.0097  (0.01705412667373132)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:06:06 -- STEP: 1500/12634 -- GLOBAL_STEP: 1500\u001b[0m\n",
            "     | > loss_text_ce: 0.041441455483436584  (0.040095715840657575)\n",
            "     | > loss_mel_ce: 2.4682414531707764  (2.9983735224405947)\n",
            "     | > loss: 0.029877178370952606  (0.03617225351184608)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3523  (0.36741615502039576)\n",
            "     | > loader_time: 0.0113  (0.01693742259343467)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:06:38 -- STEP: 1550/12634 -- GLOBAL_STEP: 1550\u001b[0m\n",
            "     | > loss_text_ce: 0.038051825016736984  (0.04006889078165257)\n",
            "     | > loss_mel_ce: 2.5181727409362793  (2.9912928956554805)\n",
            "     | > loss: 0.030431246384978294  (0.036087640984164136)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3736  (0.36791440886835886)\n",
            "     | > loader_time: 0.0119  (0.01700314829426428)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:07:08 -- STEP: 1600/12634 -- GLOBAL_STEP: 1600\u001b[0m\n",
            "     | > loss_text_ce: 0.03869415074586868  (0.04003370485501365)\n",
            "     | > loss_mel_ce: 2.4725534915924072  (2.983425792604687)\n",
            "     | > loss: 0.029895804822444916  (0.035993566112592836)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3725  (0.3679171656072138)\n",
            "     | > loader_time: 0.0107  (0.017018183320760737)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:07:39 -- STEP: 1650/12634 -- GLOBAL_STEP: 1650\u001b[0m\n",
            "     | > loss_text_ce: 0.037225671112537384  (0.03999665088048489)\n",
            "     | > loss_mel_ce: 2.7467288970947266  (2.9762839564410144)\n",
            "     | > loss: 0.033142317086458206  (0.03590810313030626)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.366  (0.3679676683021313)\n",
            "     | > loader_time: 0.0099  (0.016972902326872864)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:08:10 -- STEP: 1700/12634 -- GLOBAL_STEP: 1700\u001b[0m\n",
            "     | > loss_text_ce: 0.03871159255504608  (0.03995847932556098)\n",
            "     | > loss_mel_ce: 3.0704565048217773  (2.9686748851046865)\n",
            "     | > loss: 0.037013906985521317  (0.035817064524573464)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3656  (0.3678976720922132)\n",
            "     | > loader_time: 0.0125  (0.016999680855694945)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:08:40 -- STEP: 1750/12634 -- GLOBAL_STEP: 1750\u001b[0m\n",
            "     | > loss_text_ce: 0.03941581770777702  (0.039927810292158826)\n",
            "     | > loss_mel_ce: 2.4126780033111572  (2.963122168132239)\n",
            "     | > loss: 0.029191594570875168  (0.03575059564305205)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3688  (0.3679403760092598)\n",
            "     | > loader_time: 0.011  (0.01705818489619666)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:09:11 -- STEP: 1800/12634 -- GLOBAL_STEP: 1800\u001b[0m\n",
            "     | > loss_text_ce: 0.037228457629680634  (0.03990326200094489)\n",
            "     | > loss_mel_ce: 2.992001533508301  (2.956205450428859)\n",
            "     | > loss: 0.03606226295232773  (0.035667961524385575)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3491  (0.36793936159875645)\n",
            "     | > loader_time: 0.0103  (0.017026425202687597)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:09:42 -- STEP: 1850/12634 -- GLOBAL_STEP: 1850\u001b[0m\n",
            "     | > loss_text_ce: 0.03654054179787636  (0.03986592400315647)\n",
            "     | > loss_mel_ce: 2.827503204345703  (2.951098284979126)\n",
            "     | > loss: 0.03409576043486595  (0.035606717434082516)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3562  (0.3681232641838691)\n",
            "     | > loader_time: 0.0116  (0.017000685253658828)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:10:13 -- STEP: 1900/12634 -- GLOBAL_STEP: 1900\u001b[0m\n",
            "     | > loss_text_ce: 0.038329191505908966  (0.039832233114070026)\n",
            "     | > loss_mel_ce: 2.8861405849456787  (2.944575734765908)\n",
            "     | > loss: 0.034815117716789246  (0.03552866694370386)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3689  (0.3680892493850305)\n",
            "     | > loader_time: 0.0243  (0.016971450855857464)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:10:43 -- STEP: 1950/12634 -- GLOBAL_STEP: 1950\u001b[0m\n",
            "     | > loss_text_ce: 0.04318660497665405  (0.039813969979683575)\n",
            "     | > loss_mel_ce: 2.779038667678833  (2.9378958471004797)\n",
            "     | > loss: 0.0335979200899601  (0.03544892705499365)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.357  (0.36801549569154385)\n",
            "     | > loader_time: 0.0261  (0.016973085403442396)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:11:14 -- STEP: 2000/12634 -- GLOBAL_STEP: 2000\u001b[0m\n",
            "     | > loss_text_ce: 0.041253846138715744  (0.03978675221651794)\n",
            "     | > loss_mel_ce: 2.5057363510131836  (2.9311433154344577)\n",
            "     | > loss: 0.030321311205625534  (0.03536821574717763)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3715  (0.3680871156454085)\n",
            "     | > loader_time: 0.0095  (0.016936454176902784)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:11:45 -- STEP: 2050/12634 -- GLOBAL_STEP: 2050\u001b[0m\n",
            "     | > loss_text_ce: 0.03941761329770088  (0.03975770847099585)\n",
            "     | > loss_mel_ce: 2.612908363342285  (2.9245147744620734)\n",
            "     | > loss: 0.03157530725002289  (0.03528895878301164)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3631  (0.3680948180687136)\n",
            "     | > loader_time: 0.0093  (0.016935741843246845)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:12:16 -- STEP: 2100/12634 -- GLOBAL_STEP: 2100\u001b[0m\n",
            "     | > loss_text_ce: 0.03855406492948532  (0.03972053357533047)\n",
            "     | > loss_mel_ce: 2.6747875213623047  (2.9182121637889336)\n",
            "     | > loss: 0.032301682978868484  (0.03521348514815884)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2935  (0.3682217563901627)\n",
            "     | > loader_time: 0.0227  (0.016935974756876644)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:12:47 -- STEP: 2150/12634 -- GLOBAL_STEP: 2150\u001b[0m\n",
            "     | > loss_text_ce: 0.03856544569134712  (0.03968601866170418)\n",
            "     | > loss_mel_ce: 2.6779377460479736  (2.9115675571352964)\n",
            "     | > loss: 0.032339323312044144  (0.035133971798038795)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3686  (0.3682446178170136)\n",
            "     | > loader_time: 0.0107  (0.016960325573765974)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:13:18 -- STEP: 2200/12634 -- GLOBAL_STEP: 2200\u001b[0m\n",
            "     | > loss_text_ce: 0.03798962011933327  (0.03966630776497452)\n",
            "     | > loss_mel_ce: 2.562992572784424  (2.9065061210502288)\n",
            "     | > loss: 0.030964074656367302  (0.03507348194972361)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3523  (0.36839264306155106)\n",
            "     | > loader_time: 0.0258  (0.01691494085571984)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:13:49 -- STEP: 2250/12634 -- GLOBAL_STEP: 2250\u001b[0m\n",
            "     | > loss_text_ce: 0.03658201918005943  (0.03962780165506734)\n",
            "     | > loss_mel_ce: 2.6012401580810547  (2.900705262713963)\n",
            "     | > loss: 0.03140264376997948  (0.03500396571308378)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4329  (0.36856216642591677)\n",
            "     | > loader_time: 0.0146  (0.01689714834425186)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:14:20 -- STEP: 2300/12634 -- GLOBAL_STEP: 2300\u001b[0m\n",
            "     | > loss_text_ce: 0.03694172948598862  (0.039596563357373944)\n",
            "     | > loss_mel_ce: 2.6812055110931396  (2.894872892732207)\n",
            "     | > loss: 0.03235889598727226  (0.034934160851104144)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3684  (0.3685985146398129)\n",
            "     | > loader_time: 0.0097  (0.016918480292610515)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:14:50 -- STEP: 2350/12634 -- GLOBAL_STEP: 2350\u001b[0m\n",
            "     | > loss_text_ce: 0.038371969014406204  (0.03956603636132912)\n",
            "     | > loss_mel_ce: 2.600637912750244  (2.8888879764840976)\n",
            "     | > loss: 0.03141678497195244  (0.03486254843387835)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3626  (0.3685655581697503)\n",
            "     | > loader_time: 0.01  (0.01686606924584573)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:15:21 -- STEP: 2400/12634 -- GLOBAL_STEP: 2400\u001b[0m\n",
            "     | > loss_text_ce: 0.03578061982989311  (0.03952382225543261)\n",
            "     | > loss_mel_ce: 2.853710651397705  (2.8837907176216473)\n",
            "     | > loss: 0.03439870849251747  (0.03480136423294126)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3674  (0.3685976640383403)\n",
            "     | > loader_time: 0.0203  (0.01683805485566458)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:15:52 -- STEP: 2450/12634 -- GLOBAL_STEP: 2450\u001b[0m\n",
            "     | > loss_text_ce: 0.03974490612745285  (0.03949322400804685)\n",
            "     | > loss_mel_ce: 2.4709298610687256  (2.8787582744870894)\n",
            "     | > loss: 0.02988898567855358  (0.03474108993322878)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3634  (0.3686690726572155)\n",
            "     | > loader_time: 0.0236  (0.016924393128375632)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:16:23 -- STEP: 2500/12634 -- GLOBAL_STEP: 2500\u001b[0m\n",
            "     | > loss_text_ce: 0.03496415540575981  (0.03945897506773472)\n",
            "     | > loss_mel_ce: 2.632478952407837  (2.873786161994937)\n",
            "     | > loss: 0.03175527602434158  (0.03468149039074784)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.356  (0.3686716797828676)\n",
            "     | > loader_time: 0.0105  (0.016913332176208506)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:16:54 -- STEP: 2550/12634 -- GLOBAL_STEP: 2550\u001b[0m\n",
            "     | > loss_text_ce: 0.034634578973054886  (0.039434494856818034)\n",
            "     | > loss_mel_ce: 2.7970285415649414  (2.8689384403415787)\n",
            "     | > loss: 0.03371027484536171  (0.034623487986186)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3591  (0.36868843041214294)\n",
            "     | > loader_time: 0.0369  (0.01689915068009321)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:17:24 -- STEP: 2600/12634 -- GLOBAL_STEP: 2600\u001b[0m\n",
            "     | > loss_text_ce: 0.0366092175245285  (0.03940364590201242)\n",
            "     | > loss_mel_ce: 2.81658935546875  (2.8633922774058145)\n",
            "     | > loss: 0.03396664932370186  (0.0345570949823238)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3533  (0.36865553461588346)\n",
            "     | > loader_time: 0.0257  (0.016936921706566445)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:17:55 -- STEP: 2650/12634 -- GLOBAL_STEP: 2650\u001b[0m\n",
            "     | > loss_text_ce: 0.036815766245126724  (0.03937645885039054)\n",
            "     | > loss_mel_ce: 2.4338254928588867  (2.8581129657097613)\n",
            "     | > loss: 0.029412398114800453  (0.034493922379641107)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3587  (0.3686417135202659)\n",
            "     | > loader_time: 0.0097  (0.016891620833918725)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:18:26 -- STEP: 2700/12634 -- GLOBAL_STEP: 2700\u001b[0m\n",
            "     | > loss_text_ce: 0.03757547587156296  (0.03935270037778)\n",
            "     | > loss_mel_ce: 2.497258424758911  (2.853174305756891)\n",
            "     | > loss: 0.030176594853401184  (0.034434845964251934)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3551  (0.36859319845835353)\n",
            "     | > loader_time: 0.0126  (0.016854115945321536)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:18:56 -- STEP: 2750/12634 -- GLOBAL_STEP: 2750\u001b[0m\n",
            "     | > loss_text_ce: 0.036683544516563416  (0.03932957191087982)\n",
            "     | > loss_mel_ce: 2.5348610877990723  (2.8487011356353804)\n",
            "     | > loss: 0.030613627284765244  (0.0343813186003404)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3658  (0.3685594320297239)\n",
            "     | > loader_time: 0.0122  (0.01684948574412952)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:19:26 -- STEP: 2800/12634 -- GLOBAL_STEP: 2800\u001b[0m\n",
            "     | > loss_text_ce: 0.03623531013727188  (0.03929836016547468)\n",
            "     | > loss_mel_ce: 2.4304659366607666  (2.8436381377492674)\n",
            "     | > loss: 0.02936549112200737  (0.03432067324606978)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3584  (0.36846462743622915)\n",
            "     | > loader_time: 0.0095  (0.016839534725461673)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:19:57 -- STEP: 2850/12634 -- GLOBAL_STEP: 2850\u001b[0m\n",
            "     | > loss_text_ce: 0.03708793222904205  (0.03927426379500774)\n",
            "     | > loss_mel_ce: 2.6219065189361572  (2.8391893063930103)\n",
            "     | > loss: 0.03165469691157341  (0.034267424107774384)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3743  (0.3684067405734146)\n",
            "     | > loader_time: 0.0112  (0.016809014855769636)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:20:27 -- STEP: 2900/12634 -- GLOBAL_STEP: 2900\u001b[0m\n",
            "     | > loss_text_ce: 0.03932114690542221  (0.039245605965883584)\n",
            "     | > loss_mel_ce: 2.52018666267395  (2.8339153094949454)\n",
            "     | > loss: 0.030470332130789757  (0.03420429726420301)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3582  (0.3683151151394022)\n",
            "     | > loader_time: 0.027  (0.016839972446704727)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:20:58 -- STEP: 2950/12634 -- GLOBAL_STEP: 2950\u001b[0m\n",
            "     | > loss_text_ce: 0.037129390984773636  (0.03921620787452847)\n",
            "     | > loss_mel_ce: 2.717944383621216  (2.829469753200731)\n",
            "     | > loss: 0.03279849886894226  (0.03415102399759384)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3532  (0.36835366321822344)\n",
            "     | > loader_time: 0.0289  (0.016841654292607706)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:21:29 -- STEP: 3000/12634 -- GLOBAL_STEP: 3000\u001b[0m\n",
            "     | > loss_text_ce: 0.03732137382030487  (0.03918773337577787)\n",
            "     | > loss_mel_ce: 2.5173730850219727  (2.824950056552893)\n",
            "     | > loss: 0.030413029715418816  (0.03409687910228977)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3606  (0.3683566374778748)\n",
            "     | > loader_time: 0.0131  (0.016781080961227417)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:21:59 -- STEP: 3050/12634 -- GLOBAL_STEP: 3050\u001b[0m\n",
            "     | > loss_text_ce: 0.033482518047094345  (0.03916385367879133)\n",
            "     | > loss_mel_ce: 2.8472397327423096  (2.8204222991036647)\n",
            "     | > loss: 0.03429431468248367  (0.034042692947827496)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3513  (0.36824093357461396)\n",
            "     | > loader_time: 0.0301  (0.016795532664314654)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:22:30 -- STEP: 3100/12634 -- GLOBAL_STEP: 3100\u001b[0m\n",
            "     | > loss_text_ce: 0.0403326116502285  (0.039133571177841275)\n",
            "     | > loss_mel_ce: 2.344343900680542  (2.815792649638274)\n",
            "     | > loss: 0.028389006853103638  (0.03398721756653933)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3589  (0.36829967452633766)\n",
            "     | > loader_time: 0.0107  (0.01680852705432523)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:23:00 -- STEP: 3150/12634 -- GLOBAL_STEP: 3150\u001b[0m\n",
            "     | > loss_text_ce: 0.037781622260808945  (0.03911023993872942)\n",
            "     | > loss_mel_ce: 2.4701316356658936  (2.811980315844224)\n",
            "     | > loss: 0.029856111854314804  (0.033941554885416864)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3546  (0.3682892492082384)\n",
            "     | > loader_time: 0.0272  (0.016795514424641916)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:23:33 -- STEP: 3200/12634 -- GLOBAL_STEP: 3200\u001b[0m\n",
            "     | > loss_text_ce: 0.04067648947238922  (0.03908562547585465)\n",
            "     | > loss_mel_ce: 2.560258150100708  (2.8082239364832695)\n",
            "     | > loss: 0.030963510274887085  (0.033896543051814755)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3675  (0.36870830893516543)\n",
            "     | > loader_time: 0.0118  (0.01682020984590052)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:24:03 -- STEP: 3250/12634 -- GLOBAL_STEP: 3250\u001b[0m\n",
            "     | > loss_text_ce: 0.038606464862823486  (0.039056118727303496)\n",
            "     | > loss_mel_ce: 2.6683149337768555  (2.804221114598793)\n",
            "     | > loss: 0.03222525492310524  (0.03384853913806962)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3685  (0.3687170694057758)\n",
            "     | > loader_time: 0.0102  (0.016813148645254253)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:24:34 -- STEP: 3300/12634 -- GLOBAL_STEP: 3300\u001b[0m\n",
            "     | > loss_text_ce: 0.038211412727832794  (0.039036482158822564)\n",
            "     | > loss_mel_ce: 2.4982385635375977  (2.8014375146952597)\n",
            "     | > loss: 0.03019583225250244  (0.03381516726969781)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.356  (0.3686931850693443)\n",
            "     | > loader_time: 0.0116  (0.01678821462573423)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:25:04 -- STEP: 3350/12634 -- GLOBAL_STEP: 3350\u001b[0m\n",
            "     | > loss_text_ce: 0.03851907327771187  (0.039009995626758304)\n",
            "     | > loss_mel_ce: 2.2925493717193604  (2.7977192706492464)\n",
            "     | > loss: 0.027750816196203232  (0.03377058714294622)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.365  (0.3686407759652209)\n",
            "     | > loader_time: 0.0327  (0.016816866077593855)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:25:35 -- STEP: 3400/12634 -- GLOBAL_STEP: 3400\u001b[0m\n",
            "     | > loss_text_ce: 0.03529664874076843  (0.03897548537537019)\n",
            "     | > loss_mel_ce: 2.725816249847412  (2.793851492404943)\n",
            "     | > loss: 0.03287039324641228  (0.03372413132504076)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3592  (0.368667171422173)\n",
            "     | > loader_time: 0.011  (0.016842348575591977)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:26:06 -- STEP: 3450/12634 -- GLOBAL_STEP: 3450\u001b[0m\n",
            "     | > loss_text_ce: 0.034084223210811615  (0.03894678334233123)\n",
            "     | > loss_mel_ce: 2.6583540439605713  (2.789764999514046)\n",
            "     | > loss: 0.03205283731222153  (0.03367514090963477)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3703  (0.3687424135899198)\n",
            "     | > loader_time: 0.0108  (0.016783235245856613)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:26:37 -- STEP: 3500/12634 -- GLOBAL_STEP: 3500\u001b[0m\n",
            "     | > loss_text_ce: 0.03777714818716049  (0.03891402814164759)\n",
            "     | > loss_mel_ce: 2.465725898742676  (2.7849068739754865)\n",
            "     | > loss: 0.02980360947549343  (0.03361691613761454)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3591  (0.36869406734194077)\n",
            "     | > loader_time: 0.0102  (0.016768162386757927)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:27:08 -- STEP: 3550/12634 -- GLOBAL_STEP: 3550\u001b[0m\n",
            "     | > loss_text_ce: 0.03919391706585884  (0.038878329637080024)\n",
            "     | > loss_mel_ce: 2.121436834335327  (2.7804449609971433)\n",
            "     | > loss: 0.025721793994307518  (0.0335633731455032)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3601  (0.3687345941973404)\n",
            "     | > loader_time: 0.0108  (0.016805792257819318)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:27:38 -- STEP: 3600/12634 -- GLOBAL_STEP: 3600\u001b[0m\n",
            "     | > loss_text_ce: 0.0395396463572979  (0.03885561791507322)\n",
            "     | > loss_mel_ce: 2.285796642303467  (2.7767164139615215)\n",
            "     | > loss: 0.027682574465870857  (0.0335187153005974)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3579  (0.36872836238808104)\n",
            "     | > loader_time: 0.0104  (0.016801933646202027)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:28:09 -- STEP: 3650/12634 -- GLOBAL_STEP: 3650\u001b[0m\n",
            "     | > loss_text_ce: 0.03842467442154884  (0.03882307550933673)\n",
            "     | > loss_mel_ce: 2.412494659423828  (2.7729305337879806)\n",
            "     | > loss: 0.02917761169373989  (0.033473257886832884)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3672  (0.3686220474765725)\n",
            "     | > loader_time: 0.0235  (0.01679304763062354)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:28:39 -- STEP: 3700/12634 -- GLOBAL_STEP: 3700\u001b[0m\n",
            "     | > loss_text_ce: 0.03744598105549812  (0.03879516248817784)\n",
            "     | > loss_mel_ce: 2.1784169673919678  (2.768973500986362)\n",
            "     | > loss: 0.02637932263314724  (0.03342581805445875)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3574  (0.3686314816732664)\n",
            "     | > loader_time: 0.0299  (0.01677988026593176)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:29:10 -- STEP: 3750/12634 -- GLOBAL_STEP: 3750\u001b[0m\n",
            "     | > loss_text_ce: 0.04055938124656677  (0.038766128507753225)\n",
            "     | > loss_mel_ce: 2.5249106884002686  (2.7652687847773283)\n",
            "     | > loss: 0.03054131008684635  (0.033381368646025825)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4945  (0.3686889804204305)\n",
            "     | > loader_time: 0.0233  (0.01677741527557368)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:29:42 -- STEP: 3800/12634 -- GLOBAL_STEP: 3800\u001b[0m\n",
            "     | > loss_text_ce: 0.03568572551012039  (0.03874022460836723)\n",
            "     | > loss_mel_ce: 2.430938482284546  (2.761806253822231)\n",
            "     | > loss: 0.02936457470059395  (0.033339839660023546)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3586  (0.36882420878661304)\n",
            "     | > loader_time: 0.0099  (0.016769471858677075)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:30:12 -- STEP: 3850/12634 -- GLOBAL_STEP: 3850\u001b[0m\n",
            "     | > loss_text_ce: 0.03915504738688469  (0.03870620417469122)\n",
            "     | > loss_mel_ce: 2.2405498027801514  (2.7577360412672016)\n",
            "     | > loss: 0.027139343321323395  (0.03329097973932707)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3517  (0.36884443939506234)\n",
            "     | > loader_time: 0.031  (0.016777680198867564)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:30:43 -- STEP: 3900/12634 -- GLOBAL_STEP: 3900\u001b[0m\n",
            "     | > loss_text_ce: 0.03529774397611618  (0.03868158750952438)\n",
            "     | > loss_mel_ce: 2.6549370288848877  (2.7539820894216924)\n",
            "     | > loss: 0.03202660381793976  (0.033245996775535566)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4273  (0.3688619623428736)\n",
            "     | > loader_time: 0.0121  (0.01677935319069101)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:31:14 -- STEP: 3950/12634 -- GLOBAL_STEP: 3950\u001b[0m\n",
            "     | > loss_text_ce: 0.033776961266994476  (0.03865839215537794)\n",
            "     | > loss_mel_ce: 2.4562366008758545  (2.7498087164721956)\n",
            "     | > loss: 0.029643019661307335  (0.03319603762813397)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3604  (0.36886922329286986)\n",
            "     | > loader_time: 0.0124  (0.016760531558266133)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:31:45 -- STEP: 4000/12634 -- GLOBAL_STEP: 4000\u001b[0m\n",
            "     | > loss_text_ce: 0.03537658601999283  (0.03863381840521471)\n",
            "     | > loss_mel_ce: 2.604968309402466  (2.746337537109856)\n",
            "     | > loss: 0.03143267706036568  (0.03315442151948823)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3463  (0.368908695936203)\n",
            "     | > loader_time: 0.0298  (0.01678151768445965)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:32:16 -- STEP: 4050/12634 -- GLOBAL_STEP: 4050\u001b[0m\n",
            "     | > loss_text_ce: 0.037477221339941025  (0.038610143524905056)\n",
            "     | > loss_mel_ce: 2.55366587638855  (2.7432980595106007)\n",
            "     | > loss: 0.030846942216157913  (0.033117955416257124)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3664  (0.36896822405450136)\n",
            "     | > loader_time: 0.0103  (0.016758145873929212)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:32:46 -- STEP: 4100/12634 -- GLOBAL_STEP: 4100\u001b[0m\n",
            "     | > loss_text_ce: 0.03673555329442024  (0.038579290751367824)\n",
            "     | > loss_mel_ce: 2.409496784210205  (2.7397495012167066)\n",
            "     | > loss: 0.02912181429564953  (0.03307534337952382)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.355  (0.368924010381466)\n",
            "     | > loader_time: 0.0257  (0.016738061556001955)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:33:17 -- STEP: 4150/12634 -- GLOBAL_STEP: 4150\u001b[0m\n",
            "     | > loss_text_ce: 0.038117486983537674  (0.03855337870542904)\n",
            "     | > loss_mel_ce: 2.3018367290496826  (2.7368114147416125)\n",
            "     | > loss: 0.027856597676873207  (0.033040057681052205)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3612  (0.3689608707198177)\n",
            "     | > loader_time: 0.0238  (0.016751692783401637)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:33:48 -- STEP: 4200/12634 -- GLOBAL_STEP: 4200\u001b[0m\n",
            "     | > loss_text_ce: 0.035444993525743484  (0.03853213735323934)\n",
            "     | > loss_mel_ce: 2.418840169906616  (2.7336173482735995)\n",
            "     | > loss: 0.029217680916190147  (0.033001780208377726)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2795  (0.3690442209584372)\n",
            "     | > loader_time: 0.0106  (0.016737470570064698)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:34:19 -- STEP: 4250/12634 -- GLOBAL_STEP: 4250\u001b[0m\n",
            "     | > loss_text_ce: 0.03626539558172226  (0.038512532311765636)\n",
            "     | > loss_mel_ce: 2.4945766925811768  (2.7304108196707366)\n",
            "     | > loss: 0.030129073187708855  (0.032963373855633006)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3607  (0.368985315098482)\n",
            "     | > loader_time: 0.026  (0.0167317770789651)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:34:49 -- STEP: 4300/12634 -- GLOBAL_STEP: 4300\u001b[0m\n",
            "     | > loss_text_ce: 0.03401590883731842  (0.038480441411307416)\n",
            "     | > loss_mel_ce: 2.2798805236816406  (2.7271335088375026)\n",
            "     | > loss: 0.027546387165784836  (0.03292397621369303)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3578  (0.36894904990528893)\n",
            "     | > loader_time: 0.0274  (0.016749336109604912)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:35:20 -- STEP: 4350/12634 -- GLOBAL_STEP: 4350\u001b[0m\n",
            "     | > loss_text_ce: 0.03543390333652496  (0.038455336530232594)\n",
            "     | > loss_mel_ce: 2.3531494140625  (2.724569293383896)\n",
            "     | > loss: 0.028435517102479935  (0.0328931509686271)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3499  (0.368904658350451)\n",
            "     | > loader_time: 0.0116  (0.016762063749905253)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:35:50 -- STEP: 4400/12634 -- GLOBAL_STEP: 4400\u001b[0m\n",
            "     | > loss_text_ce: 0.037995412945747375  (0.03842815607151191)\n",
            "     | > loss_mel_ce: 2.428956985473633  (2.721365136124872)\n",
            "     | > loss: 0.029368480667471886  (0.03285468266218571)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3663  (0.3688677262176163)\n",
            "     | > loader_time: 0.01  (0.016758552518757873)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:36:21 -- STEP: 4450/12634 -- GLOBAL_STEP: 4450\u001b[0m\n",
            "     | > loss_text_ce: 0.03516764938831329  (0.03840448663182813)\n",
            "     | > loss_mel_ce: 2.600267171859741  (2.7183692386177154)\n",
            "     | > loss: 0.03137422353029251  (0.032818735437363133)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3456  (0.3688719751057996)\n",
            "     | > loader_time: 0.0359  (0.016742091821820525)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:36:52 -- STEP: 4500/12634 -- GLOBAL_STEP: 4500\u001b[0m\n",
            "     | > loss_text_ce: 0.03538966923952103  (0.03837696011571426)\n",
            "     | > loss_mel_ce: 2.418888807296753  (2.7152729863060845)\n",
            "     | > loss: 0.02921760082244873  (0.0327815475935738)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4247  (0.36887516588634883)\n",
            "     | > loader_time: 0.0262  (0.016749519083234982)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:37:23 -- STEP: 4550/12634 -- GLOBAL_STEP: 4550\u001b[0m\n",
            "     | > loss_text_ce: 0.034043870866298676  (0.03834905356619061)\n",
            "     | > loss_mel_ce: 2.4173245429992676  (2.712029124249468)\n",
            "     | > loss: 0.029182957485318184  (0.03274259796427509)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3615  (0.368918657512455)\n",
            "     | > loader_time: 0.0101  (0.016749598848950713)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:37:54 -- STEP: 4600/12634 -- GLOBAL_STEP: 4600\u001b[0m\n",
            "     | > loss_text_ce: 0.03738206997513771  (0.03832297886073917)\n",
            "     | > loss_mel_ce: 2.4849236011505127  (2.7092770392998387)\n",
            "     | > loss: 0.030027449131011963  (0.03270952463190525)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3564  (0.3689390046181883)\n",
            "     | > loader_time: 0.0105  (0.016720580536386233)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:38:24 -- STEP: 4650/12634 -- GLOBAL_STEP: 4650\u001b[0m\n",
            "     | > loss_text_ce: 0.03629152476787567  (0.03829875524446211)\n",
            "     | > loss_mel_ce: 2.3694000244140625  (2.7062525306722156)\n",
            "     | > loss: 0.028639186173677444  (0.032673230200445234)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3716  (0.3689133713322302)\n",
            "     | > loader_time: 0.0115  (0.016728022021632035)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:38:55 -- STEP: 4700/12634 -- GLOBAL_STEP: 4700\u001b[0m\n",
            "     | > loss_text_ce: 0.03348993882536888  (0.03827759542244868)\n",
            "     | > loss_mel_ce: 2.5745832920074463  (2.7031960209379804)\n",
            "     | > loss: 0.031048491597175598  (0.03263659127492548)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3662  (0.36893136404930293)\n",
            "     | > loader_time: 0.0105  (0.016736793416611693)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:39:26 -- STEP: 4750/12634 -- GLOBAL_STEP: 4750\u001b[0m\n",
            "     | > loss_text_ce: 0.037826959043741226  (0.038250853856535386)\n",
            "     | > loss_mel_ce: 2.5085504055023193  (2.7003159493898092)\n",
            "     | > loss: 0.030314017087221146  (0.032601986355295404)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3595  (0.3689074010347066)\n",
            "     | > loader_time: 0.0133  (0.016732804850528103)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:39:57 -- STEP: 4800/12634 -- GLOBAL_STEP: 4800\u001b[0m\n",
            "     | > loss_text_ce: 0.037245962768793106  (0.038223976608133)\n",
            "     | > loss_mel_ce: 2.61405086517334  (2.6973006705443043)\n",
            "     | > loss: 0.031563058495521545  (0.0325657702128714)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3651  (0.3689104368786016)\n",
            "     | > loader_time: 0.0289  (0.016763744254906964)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:40:27 -- STEP: 4850/12634 -- GLOBAL_STEP: 4850\u001b[0m\n",
            "     | > loss_text_ce: 0.034756410866975784  (0.03819292641676891)\n",
            "     | > loss_mel_ce: 2.5855352878570557  (2.6943403238119528)\n",
            "     | > loss: 0.031193949282169342  (0.032530158344157074)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3572  (0.368909204129091)\n",
            "     | > loader_time: 0.0102  (0.016762607318838836)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:40:58 -- STEP: 4900/12634 -- GLOBAL_STEP: 4900\u001b[0m\n",
            "     | > loss_text_ce: 0.03651401028037071  (0.0381720277906529)\n",
            "     | > loss_mel_ce: 2.4430360794067383  (2.691241887296947)\n",
            "     | > loss: 0.029518455266952515  (0.03249302340101234)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4289  (0.368934825829097)\n",
            "     | > loader_time: 0.0105  (0.016749893889135226)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:41:29 -- STEP: 4950/12634 -- GLOBAL_STEP: 4950\u001b[0m\n",
            "     | > loss_text_ce: 0.03453492000699043  (0.038146585700563146)\n",
            "     | > loss_mel_ce: 2.396184206008911  (2.6889856433868395)\n",
            "     | > loss: 0.02893713302910328  (0.0324658604711295)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.386  (0.36897209143397736)\n",
            "     | > loader_time: 0.0124  (0.016763459841410287)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:42:00 -- STEP: 5000/12634 -- GLOBAL_STEP: 5000\u001b[0m\n",
            "     | > loss_text_ce: 0.037496212869882584  (0.03812232037819926)\n",
            "     | > loss_mel_ce: 2.3773276805877686  (2.685928870630262)\n",
            "     | > loss: 0.028747905045747757  (0.03242918144352743)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3536  (0.36904051308631863)\n",
            "     | > loader_time: 0.0267  (0.01677849187850948)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:42:31 -- STEP: 5050/12634 -- GLOBAL_STEP: 5050\u001b[0m\n",
            "     | > loss_text_ce: 0.0353425070643425  (0.0381026309629036)\n",
            "     | > loss_mel_ce: 2.3852741718292236  (2.6830557369477654)\n",
            "     | > loss: 0.028816865757107735  (0.03239474307635056)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4308  (0.3690650852599944)\n",
            "     | > loader_time: 0.0099  (0.01678186053096653)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:43:02 -- STEP: 5100/12634 -- GLOBAL_STEP: 5100\u001b[0m\n",
            "     | > loss_text_ce: 0.03476133570075035  (0.03807815440912172)\n",
            "     | > loss_mel_ce: 2.1730873584747314  (2.679901513959846)\n",
            "     | > loss: 0.02628391422331333  (0.032356901414254256)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3622  (0.3690471100339702)\n",
            "     | > loader_time: 0.0252  (0.01676326943378819)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:43:33 -- STEP: 5150/12634 -- GLOBAL_STEP: 5150\u001b[0m\n",
            "     | > loss_text_ce: 0.03622942045331001  (0.03804848493266751)\n",
            "     | > loss_mel_ce: 2.7397267818450928  (2.6773837027040486)\n",
            "     | > loss: 0.03304709866642952  (0.03232657425973613)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3651  (0.36909500279472895)\n",
            "     | > loader_time: 0.0251  (0.01677203613577533)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:44:04 -- STEP: 5200/12634 -- GLOBAL_STEP: 5200\u001b[0m\n",
            "     | > loss_text_ce: 0.03507241979241371  (0.03802229761325118)\n",
            "     | > loss_mel_ce: 2.365792989730835  (2.6743477083398726)\n",
            "     | > loss: 0.028581731021404266  (0.03229011971396049)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.363  (0.36909097501864824)\n",
            "     | > loader_time: 0.0108  (0.01674571647093844)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:44:34 -- STEP: 5250/12634 -- GLOBAL_STEP: 5250\u001b[0m\n",
            "     | > loss_text_ce: 0.03648388758301735  (0.037998347752151114)\n",
            "     | > loss_mel_ce: 2.5022003650665283  (2.671683891046613)\n",
            "     | > loss: 0.03022243268787861  (0.032258122487792064)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.5009  (0.3690503871100292)\n",
            "     | > loader_time: 0.0268  (0.016753909701392733)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:45:05 -- STEP: 5300/12634 -- GLOBAL_STEP: 5300\u001b[0m\n",
            "     | > loss_text_ce: 0.03383990749716759  (0.03797544654564202)\n",
            "     | > loss_mel_ce: 2.8847556114196777  (2.6692545093455404)\n",
            "     | > loss: 0.03474518656730652  (0.03222892864343704)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4264  (0.3690630542107351)\n",
            "     | > loader_time: 0.0203  (0.016761848071836057)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:45:36 -- STEP: 5350/12634 -- GLOBAL_STEP: 5350\u001b[0m\n",
            "     | > loss_text_ce: 0.03253352269530296  (0.03795326455696451)\n",
            "     | > loss_mel_ce: 2.1391375064849854  (2.6669858694299347)\n",
            "     | > loss: 0.025853225961327553  (0.0322016569543805)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3538  (0.36907106092043035)\n",
            "     | > loader_time: 0.0103  (0.016762514114379866)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:46:07 -- STEP: 5400/12634 -- GLOBAL_STEP: 5400\u001b[0m\n",
            "     | > loss_text_ce: 0.03556887060403824  (0.037932861743632945)\n",
            "     | > loss_mel_ce: 2.3351752758026123  (2.6643895927844214)\n",
            "     | > loss: 0.028223145753145218  (0.03217050601003911)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.359  (0.3691005714734396)\n",
            "     | > loader_time: 0.0211  (0.01675551167240848)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:46:37 -- STEP: 5450/12634 -- GLOBAL_STEP: 5450\u001b[0m\n",
            "     | > loss_text_ce: 0.03361647576093674  (0.0379090069155765)\n",
            "     | > loss_mel_ce: 2.366856575012207  (2.662016713750469)\n",
            "     | > loss: 0.028577061370015144  (0.03214197346171667)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3585  (0.3690474037730368)\n",
            "     | > loader_time: 0.0298  (0.016770463208539765)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:47:08 -- STEP: 5500/12634 -- GLOBAL_STEP: 5500\u001b[0m\n",
            "     | > loss_text_ce: 0.03625398129224777  (0.03788897963918074)\n",
            "     | > loss_mel_ce: 2.239537477493286  (2.6596828791228173)\n",
            "     | > loss: 0.02709275484085083  (0.03211395129392102)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3617  (0.3690179061889649)\n",
            "     | > loader_time: 0.0101  (0.0167820040095936)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:47:38 -- STEP: 5550/12634 -- GLOBAL_STEP: 5550\u001b[0m\n",
            "     | > loss_text_ce: 0.034929681569337845  (0.03786710815353172)\n",
            "     | > loss_mel_ce: 2.5571842193603516  (2.6570294675955863)\n",
            "     | > loss: 0.03085849992930889  (0.03208210268569701)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3588  (0.36899717442624225)\n",
            "     | > loader_time: 0.0104  (0.01676592852618242)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:48:09 -- STEP: 5600/12634 -- GLOBAL_STEP: 5600\u001b[0m\n",
            "     | > loss_text_ce: 0.035714130848646164  (0.03784307445432729)\n",
            "     | > loss_mel_ce: 2.57846999168396  (2.6544184078063244)\n",
            "     | > loss: 0.03112124092876911  (0.0320507325248661)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3587  (0.3689890595844815)\n",
            "     | > loader_time: 0.0226  (0.016770708858966813)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:48:40 -- STEP: 5650/12634 -- GLOBAL_STEP: 5650\u001b[0m\n",
            "     | > loss_text_ce: 0.032614052295684814  (0.037818513381731735)\n",
            "     | > loss_mel_ce: 2.4490809440612793  (2.652021306046337)\n",
            "     | > loss: 0.029543988406658173  (0.03202190320378395)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3682  (0.36897371591719924)\n",
            "     | > loader_time: 0.0123  (0.01677802018359698)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:49:10 -- STEP: 5700/12634 -- GLOBAL_STEP: 5700\u001b[0m\n",
            "     | > loss_text_ce: 0.035505786538124084  (0.03779748462892158)\n",
            "     | > loss_mel_ce: 2.7664794921875  (2.649693238107776)\n",
            "     | > loss: 0.03335696831345558  (0.031993937766539034)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4283  (0.3689639805074325)\n",
            "     | > loader_time: 0.0102  (0.016775182255527418)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:49:42 -- STEP: 5750/12634 -- GLOBAL_STEP: 5750\u001b[0m\n",
            "     | > loss_text_ce: 0.0318705253303051  (0.037773673606307664)\n",
            "     | > loss_mel_ce: 2.43009352684021  (2.64798736431287)\n",
            "     | > loss: 0.029309097677469254  (0.03197334628098698)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3627  (0.3690569103075112)\n",
            "     | > loader_time: 0.0101  (0.01676389408111572)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:50:13 -- STEP: 5800/12634 -- GLOBAL_STEP: 5800\u001b[0m\n",
            "     | > loss_text_ce: 0.03632286563515663  (0.03775302859087446)\n",
            "     | > loss_mel_ce: 2.3536765575408936  (2.645788262630326)\n",
            "     | > loss: 0.028452374041080475  (0.03194692072233775)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3657  (0.3690491191683146)\n",
            "     | > loader_time: 0.0127  (0.01676906741898634)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:50:43 -- STEP: 5850/12634 -- GLOBAL_STEP: 5850\u001b[0m\n",
            "     | > loss_text_ce: 0.037555430084466934  (0.03773105647096523)\n",
            "     | > loss_mel_ce: 2.4821102619171143  (2.6435075638436816)\n",
            "     | > loss: 0.02999602071940899  (0.03191950797334194)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3623  (0.3690743485067646)\n",
            "     | > loader_time: 0.0108  (0.016782704010987862)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:51:14 -- STEP: 5900/12634 -- GLOBAL_STEP: 5900\u001b[0m\n",
            "     | > loss_text_ce: 0.03406322002410889  (0.03771206393174954)\n",
            "     | > loss_mel_ce: 2.5877676010131836  (2.641165548017464)\n",
            "     | > loss: 0.031212273985147476  (0.031891400729763895)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3588  (0.3690398819567795)\n",
            "     | > loader_time: 0.0093  (0.01677438517748297)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:51:44 -- STEP: 5950/12634 -- GLOBAL_STEP: 5950\u001b[0m\n",
            "     | > loss_text_ce: 0.035381902009248734  (0.03768980133088947)\n",
            "     | > loss_mel_ce: 2.2751567363739014  (2.638452457900802)\n",
            "     | > loss: 0.02750641107559204  (0.03185883700628503)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3607  (0.3689933503976391)\n",
            "     | > loader_time: 0.0279  (0.016774827532407593)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:52:15 -- STEP: 6000/12634 -- GLOBAL_STEP: 6000\u001b[0m\n",
            "     | > loss_text_ce: 0.03605279698967934  (0.03766687605312712)\n",
            "     | > loss_mel_ce: 2.3377816677093506  (2.6359527928034403)\n",
            "     | > loss: 0.02825993299484253  (0.031828806166847655)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3651  (0.36897139012813585)\n",
            "     | > loader_time: 0.0093  (0.016781978766123435)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:52:46 -- STEP: 6050/12634 -- GLOBAL_STEP: 6050\u001b[0m\n",
            "     | > loss_text_ce: 0.03389877825975418  (0.03764218569078962)\n",
            "     | > loss_mel_ce: 2.2003097534179688  (2.633535533424246)\n",
            "     | > loss: 0.026597721502184868  (0.03179973533638758)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3677  (0.36898110228136566)\n",
            "     | > loader_time: 0.0101  (0.0167793713325311)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:53:17 -- STEP: 6100/12634 -- GLOBAL_STEP: 6100\u001b[0m\n",
            "     | > loss_text_ce: 0.03470226377248764  (0.037620065524929795)\n",
            "     | > loss_mel_ce: 2.2075390815734863  (2.6313775918131923)\n",
            "     | > loss: 0.026693349704146385  (0.031773782217966846)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3595  (0.36902179753194103)\n",
            "     | > loader_time: 0.0244  (0.01677565762254055)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:53:47 -- STEP: 6150/12634 -- GLOBAL_STEP: 6150\u001b[0m\n",
            "     | > loss_text_ce: 0.03312285616993904  (0.037596299091611385)\n",
            "     | > loss_mel_ce: 2.3923749923706055  (2.6292046143368926)\n",
            "     | > loss: 0.028874974697828293  (0.031747630505057974)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3592  (0.36899081927974064)\n",
            "     | > loader_time: 0.0105  (0.016782115959539608)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:54:19 -- STEP: 6200/12634 -- GLOBAL_STEP: 6200\u001b[0m\n",
            "     | > loss_text_ce: 0.03604594245553017  (0.03757161062571302)\n",
            "     | > loss_mel_ce: 2.741533041000366  (2.6268615652668794)\n",
            "     | > loss: 0.03306641802191734  (0.031719443155152294)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3554  (0.36906090540270664)\n",
            "     | > loader_time: 0.0132  (0.016770007648775617)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:54:50 -- STEP: 6250/12634 -- GLOBAL_STEP: 6250\u001b[0m\n",
            "     | > loss_text_ce: 0.035230591893196106  (0.03755258090555656)\n",
            "     | > loss_mel_ce: 2.3720922470092773  (2.6248254941558793)\n",
            "     | > loss: 0.028658606112003326  (0.03169497766911996)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4171  (0.3690740992736818)\n",
            "     | > loader_time: 0.031  (0.01677692550659176)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:55:20 -- STEP: 6300/12634 -- GLOBAL_STEP: 6300\u001b[0m\n",
            "     | > loss_text_ce: 0.03544136509299278  (0.03753029541393349)\n",
            "     | > loss_mel_ce: 2.4037301540374756  (2.6224606020109946)\n",
            "     | > loss: 0.029037756845355034  (0.03166655888574002)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3919  (0.3690815969875882)\n",
            "     | > loader_time: 0.0287  (0.01678674550283519)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:55:51 -- STEP: 6350/12634 -- GLOBAL_STEP: 6350\u001b[0m\n",
            "     | > loss_text_ce: 0.0340745709836483  (0.037507150008629066)\n",
            "     | > loss_mel_ce: 2.1981589794158936  (2.6203414189721608)\n",
            "     | > loss: 0.026574209332466125  (0.031641054973886355)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3538  (0.3690666784451704)\n",
            "     | > loader_time: 0.0106  (0.01678936387610245)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:56:22 -- STEP: 6400/12634 -- GLOBAL_STEP: 6400\u001b[0m\n",
            "     | > loss_text_ce: 0.03331444784998894  (0.0374843565377522)\n",
            "     | > loss_mel_ce: 2.2238962650299072  (2.6184102367237165)\n",
            "     | > loss: 0.026871556416153908  (0.03161779335845508)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3574  (0.3690940411761405)\n",
            "     | > loader_time: 0.0301  (0.0167807464674115)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:56:53 -- STEP: 6450/12634 -- GLOBAL_STEP: 6450\u001b[0m\n",
            "     | > loss_text_ce: 0.03570695221424103  (0.03746053064602974)\n",
            "     | > loss_mel_ce: 2.263674259185791  (2.616225363857058)\n",
            "     | > loss: 0.02737358771264553  (0.0315914993265342)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3715  (0.36910080122393246)\n",
            "     | > loader_time: 0.0106  (0.01679505418437394)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:57:24 -- STEP: 6500/12634 -- GLOBAL_STEP: 6500\u001b[0m\n",
            "     | > loss_text_ce: 0.03447540104389191  (0.037436433750276304)\n",
            "     | > loss_mel_ce: 2.2328312397003174  (2.614234056142656)\n",
            "     | > loss: 0.026991745457053185  (0.031567506415339786)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3783  (0.369184195995331)\n",
            "     | > loader_time: 0.016  (0.01679700172864473)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:57:55 -- STEP: 6550/12634 -- GLOBAL_STEP: 6550\u001b[0m\n",
            "     | > loss_text_ce: 0.03264616057276726  (0.03741297217697354)\n",
            "     | > loss_mel_ce: 2.2149956226348877  (2.611729581447044)\n",
            "     | > loss: 0.02675764076411724  (0.031537411936367)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3572  (0.36920999781776037)\n",
            "     | > loader_time: 0.03  (0.016801852342736623)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:58:27 -- STEP: 6600/12634 -- GLOBAL_STEP: 6600\u001b[0m\n",
            "     | > loss_text_ce: 0.034089893102645874  (0.03739656713791189)\n",
            "     | > loss_mel_ce: 2.664323568344116  (2.6099085404294864)\n",
            "     | > loss: 0.03212396800518036  (0.03151553757770962)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.369  (0.3692397442008511)\n",
            "     | > loader_time: 0.0103  (0.01681104631134958)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:58:58 -- STEP: 6650/12634 -- GLOBAL_STEP: 6650\u001b[0m\n",
            "     | > loss_text_ce: 0.03590172529220581  (0.037373270331076604)\n",
            "     | > loss_mel_ce: 2.5990209579467773  (2.607838418788475)\n",
            "     | > loss: 0.03136812895536423  (0.03149061592897991)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3666  (0.36926964386961525)\n",
            "     | > loader_time: 0.0108  (0.016797405723342325)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:59:28 -- STEP: 6700/12634 -- GLOBAL_STEP: 6700\u001b[0m\n",
            "     | > loss_text_ce: 0.03603777289390564  (0.037353277479701484)\n",
            "     | > loss_mel_ce: 2.40513277053833  (2.606037525561314)\n",
            "     | > loss: 0.02906155399978161  (0.031468938713643244)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3625  (0.36925678794063754)\n",
            "     | > loader_time: 0.0142  (0.016811955757995156)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 07:59:59 -- STEP: 6750/12634 -- GLOBAL_STEP: 6750\u001b[0m\n",
            "     | > loss_text_ce: 0.0339697040617466  (0.03733320786776363)\n",
            "     | > loss_mel_ce: 2.576817035675049  (2.6043888017336485)\n",
            "     | > loss: 0.03108079358935356  (0.031449072124781555)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.37  (0.3692897527835989)\n",
            "     | > loader_time: 0.0103  (0.016816966798570414)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:00:30 -- STEP: 6800/12634 -- GLOBAL_STEP: 6800\u001b[0m\n",
            "     | > loss_text_ce: 0.03592849150300026  (0.03730924686006103)\n",
            "     | > loss_mel_ce: 2.2238516807556152  (2.6024372958610997)\n",
            "     | > loss: 0.02690214477479458  (0.03142555465949164)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4439  (0.36927809561000163)\n",
            "     | > loader_time: 0.0102  (0.016802162633222692)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:01:01 -- STEP: 6850/12634 -- GLOBAL_STEP: 6850\u001b[0m\n",
            "     | > loss_text_ce: 0.03347375616431236  (0.0372881223432665)\n",
            "     | > loss_mel_ce: 2.5211753845214844  (2.600023139114793)\n",
            "     | > loss: 0.03041248954832554  (0.03139656321329151)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3534  (0.36926450349988743)\n",
            "     | > loader_time: 0.0336  (0.016810648980802017)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:01:31 -- STEP: 6900/12634 -- GLOBAL_STEP: 6900\u001b[0m\n",
            "     | > loss_text_ce: 0.03117523156106472  (0.03726512128433238)\n",
            "     | > loss_mel_ce: 2.2143616676330566  (2.597929455041881)\n",
            "     | > loss: 0.026732580736279488  (0.03137136458054845)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4233  (0.36924363671869487)\n",
            "     | > loader_time: 0.0184  (0.016815321307251465)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:02:02 -- STEP: 6950/12634 -- GLOBAL_STEP: 6950\u001b[0m\n",
            "     | > loss_text_ce: 0.03546323627233505  (0.037242887519139165)\n",
            "     | > loss_mel_ce: 2.0944156646728516  (2.5958601523989353)\n",
            "     | > loss: 0.02535570226609707  (0.0313464653363332)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3684  (0.36924320402762884)\n",
            "     | > loader_time: 0.0108  (0.016805849349756083)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:02:33 -- STEP: 7000/12634 -- GLOBAL_STEP: 7000\u001b[0m\n",
            "     | > loss_text_ce: 0.03483474254608154  (0.03722221850603817)\n",
            "     | > loss_mel_ce: 2.5276339054107666  (2.5940552763768565)\n",
            "     | > loss: 0.030505578964948654  (0.031324732656723815)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3518  (0.36924673553875526)\n",
            "     | > loader_time: 0.0328  (0.0167906612668719)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:03:03 -- STEP: 7050/12634 -- GLOBAL_STEP: 7050\u001b[0m\n",
            "     | > loss_text_ce: 0.03481515496969223  (0.037201065460735164)\n",
            "     | > loss_mel_ce: 2.390078067779541  (2.5922233492770053)\n",
            "     | > loss: 0.028867775574326515  (0.031302672177024884)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3563  (0.3692298629097906)\n",
            "     | > loader_time: 0.0126  (0.01679361103274303)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:03:34 -- STEP: 7100/12634 -- GLOBAL_STEP: 7100\u001b[0m\n",
            "     | > loss_text_ce: 0.03542061895132065  (0.037177678377590534)\n",
            "     | > loss_mel_ce: 2.384258508682251  (2.5903092749857524)\n",
            "     | > loss: 0.028805704787373543  (0.031279607160725295)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.365  (0.36920258011616464)\n",
            "     | > loader_time: 0.0102  (0.0167981309286306)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:04:04 -- STEP: 7150/12634 -- GLOBAL_STEP: 7150\u001b[0m\n",
            "     | > loss_text_ce: 0.0326395146548748  (0.037155617920981404)\n",
            "     | > loss_mel_ce: 2.370297431945801  (2.588410514551439)\n",
            "     | > loss: 0.028606392443180084  (0.031256740244587466)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3571  (0.36918590142176716)\n",
            "     | > loader_time: 0.0102  (0.016795265824644755)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:04:35 -- STEP: 7200/12634 -- GLOBAL_STEP: 7200\u001b[0m\n",
            "     | > loss_text_ce: 0.03337542340159416  (0.037132847027128754)\n",
            "     | > loss_mel_ce: 1.968668818473816  (2.5866502920289793)\n",
            "     | > loss: 0.023833859711885452  (0.03123551413158168)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3623  (0.3692131382889219)\n",
            "     | > loader_time: 0.0156  (0.016810629102918872)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:05:06 -- STEP: 7250/12634 -- GLOBAL_STEP: 7250\u001b[0m\n",
            "     | > loss_text_ce: 0.03495684638619423  (0.03711231428667387)\n",
            "     | > loss_mel_ce: 2.2803561687469482  (2.5851261421894165)\n",
            "     | > loss: 0.027563251554965973  (0.031217125053549694)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.363  (0.36921828276535573)\n",
            "     | > loader_time: 0.0274  (0.016815349841940035)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:05:38 -- STEP: 7300/12634 -- GLOBAL_STEP: 7300\u001b[0m\n",
            "     | > loss_text_ce: 0.0327615886926651  (0.037088228180136976)\n",
            "     | > loss_mel_ce: 2.3247148990631104  (2.5832420032481584)\n",
            "     | > loss: 0.02806519716978073  (0.031194408087391618)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4226  (0.3693205684831699)\n",
            "     | > loader_time: 0.0106  (0.01679758496480449)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:06:08 -- STEP: 7350/12634 -- GLOBAL_STEP: 7350\u001b[0m\n",
            "     | > loss_text_ce: 0.03198697045445442  (0.037068030050873335)\n",
            "     | > loss_mel_ce: 2.2456014156341553  (2.581362465433519)\n",
            "     | > loss: 0.027114147320389748  (0.031171792182995407)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3715  (0.36930311481968897)\n",
            "     | > loader_time: 0.0107  (0.016791233951542688)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:06:39 -- STEP: 7400/12634 -- GLOBAL_STEP: 7400\u001b[0m\n",
            "     | > loss_text_ce: 0.03425747528672218  (0.03704548527058716)\n",
            "     | > loss_mel_ce: 2.0716469287872314  (2.5792392743278154)\n",
            "     | > loss: 0.02507029101252556  (0.03114624770710603)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3503  (0.36926650114961584)\n",
            "     | > loader_time: 0.027  (0.01680107793292487)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:07:09 -- STEP: 7450/12634 -- GLOBAL_STEP: 7450\u001b[0m\n",
            "     | > loss_text_ce: 0.03363515064120293  (0.037023914761141224)\n",
            "     | > loss_mel_ce: 2.6216797828674316  (2.577334640826151)\n",
            "     | > loss: 0.031610891222953796  (0.031123316706527057)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3611  (0.3692613240056391)\n",
            "     | > loader_time: 0.01  (0.016782454132233726)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:07:40 -- STEP: 7500/12634 -- GLOBAL_STEP: 7500\u001b[0m\n",
            "     | > loss_text_ce: 0.033665671944618225  (0.037003965620944886)\n",
            "     | > loss_mel_ce: 2.509655237197876  (2.57552601485252)\n",
            "     | > loss: 0.03027763031423092  (0.031101547954976615)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3505  (0.3693052949269614)\n",
            "     | > loader_time: 0.0361  (0.01677337093353276)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:08:11 -- STEP: 7550/12634 -- GLOBAL_STEP: 7550\u001b[0m\n",
            "     | > loss_text_ce: 0.03191542625427246  (0.036983803318233664)\n",
            "     | > loss_mel_ce: 2.5132179260253906  (2.573795924091967)\n",
            "     | > loss: 0.03029920719563961  (0.031080711608542963)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3763  (0.36931239819684575)\n",
            "     | > loader_time: 0.0271  (0.016777679272834866)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:08:42 -- STEP: 7600/12634 -- GLOBAL_STEP: 7600\u001b[0m\n",
            "     | > loss_text_ce: 0.034460797905921936  (0.036960739334064865)\n",
            "     | > loss_mel_ce: 2.36954665184021  (2.5720760984797186)\n",
            "     | > loss: 0.028619136661291122  (0.031059962921579864)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.366  (0.36932601894203)\n",
            "     | > loader_time: 0.0099  (0.016762363345999513)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:09:13 -- STEP: 7650/12634 -- GLOBAL_STEP: 7650\u001b[0m\n",
            "     | > loss_text_ce: 0.033609695732593536  (0.036942430436367676)\n",
            "     | > loss_mel_ce: 2.197633981704712  (2.570432705333806)\n",
            "     | > loss: 0.02656242437660694  (0.0310401807554992)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3639  (0.3693459840849335)\n",
            "     | > loader_time: 0.0122  (0.016757919679280253)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:09:44 -- STEP: 7700/12634 -- GLOBAL_STEP: 7700\u001b[0m\n",
            "     | > loss_text_ce: 0.033140625804662704  (0.036922266845434114)\n",
            "     | > loss_mel_ce: 2.1875786781311035  (2.568646528395736)\n",
            "     | > loss: 0.02643713541328907  (0.03101867670314271)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3639  (0.36938820182503057)\n",
            "     | > loader_time: 0.0277  (0.016764101858262943)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:10:15 -- STEP: 7750/12634 -- GLOBAL_STEP: 7750\u001b[0m\n",
            "     | > loss_text_ce: 0.03448152542114258  (0.036902238147874016)\n",
            "     | > loss_mel_ce: 2.253434658050537  (2.5672413033362322)\n",
            "     | > loss: 0.027237098664045334  (0.0310017093965604)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3651  (0.3694260480326992)\n",
            "     | > loader_time: 0.0112  (0.01675404010280491)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:10:46 -- STEP: 7800/12634 -- GLOBAL_STEP: 7800\u001b[0m\n",
            "     | > loss_text_ce: 0.033647261559963226  (0.036882126292643626)\n",
            "     | > loss_mel_ce: 2.227074384689331  (2.5653259823719625)\n",
            "     | > loss: 0.02691335417330265  (0.030978668528155312)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.36  (0.36944073392794696)\n",
            "     | > loader_time: 0.0252  (0.01675018934103164)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:11:17 -- STEP: 7850/12634 -- GLOBAL_STEP: 7850\u001b[0m\n",
            "     | > loss_text_ce: 0.03457722067832947  (0.036863267951093265)\n",
            "     | > loss_mel_ce: 2.373403310775757  (2.563959977778656)\n",
            "     | > loss: 0.028666434809565544  (0.030962182064155158)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3766  (0.36946293347960074)\n",
            "     | > loader_time: 0.0126  (0.01676063145801525)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:11:48 -- STEP: 7900/12634 -- GLOBAL_STEP: 7900\u001b[0m\n",
            "     | > loss_text_ce: 0.03315966948866844  (0.0368457229539186)\n",
            "     | > loss_mel_ce: 2.7335357666015625  (2.5624578040913653)\n",
            "     | > loss: 0.03293685242533684  (0.030944090174110307)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4195  (0.3694706433634216)\n",
            "     | > loader_time: 0.0104  (0.016748799945734773)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:12:19 -- STEP: 7950/12634 -- GLOBAL_STEP: 7950\u001b[0m\n",
            "     | > loss_text_ce: 0.03437104821205139  (0.03682466472469784)\n",
            "     | > loss_mel_ce: 2.3853988647460938  (2.560859589531733)\n",
            "     | > loss: 0.028806786984205246  (0.030924813116449658)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3551  (0.36947083986030443)\n",
            "     | > loader_time: 0.0269  (0.016742936230305656)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:12:49 -- STEP: 8000/12634 -- GLOBAL_STEP: 8000\u001b[0m\n",
            "     | > loss_text_ce: 0.03182272985577583  (0.036805652154842376)\n",
            "     | > loss_mel_ce: 2.2599503993988037  (2.559342797175046)\n",
            "     | > loss: 0.027283012866973877  (0.030906529723433832)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3354  (0.36943211615085614)\n",
            "     | > loader_time: 0.0211  (0.016749787896871617)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:13:20 -- STEP: 8050/12634 -- GLOBAL_STEP: 8050\u001b[0m\n",
            "     | > loss_text_ce: 0.035905346274375916  (0.03678602222353219)\n",
            "     | > loss_mel_ce: 2.212719440460205  (2.5577913027668555)\n",
            "     | > loss: 0.02676934376358986  (0.030887825861341887)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4303  (0.369423305381159)\n",
            "     | > loader_time: 0.0106  (0.01674314102030694)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:13:50 -- STEP: 8100/12634 -- GLOBAL_STEP: 8100\u001b[0m\n",
            "     | > loss_text_ce: 0.036576900631189346  (0.03676825213970408)\n",
            "     | > loss_mel_ce: 2.7381982803344727  (2.556226698969614)\n",
            "     | > loss: 0.033033039420843124  (0.030868988076891847)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3588  (0.36940579429084885)\n",
            "     | > loader_time: 0.0213  (0.01673498612863051)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:14:21 -- STEP: 8150/12634 -- GLOBAL_STEP: 8150\u001b[0m\n",
            "     | > loss_text_ce: 0.03350934013724327  (0.03674776096034085)\n",
            "     | > loss_mel_ce: 2.3201537132263184  (2.5545816604930165)\n",
            "     | > loss: 0.028019797056913376  (0.03084916034084893)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3692  (0.3693807479355234)\n",
            "     | > loader_time: 0.0111  (0.01673000721843701)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:14:51 -- STEP: 8200/12634 -- GLOBAL_STEP: 8200\u001b[0m\n",
            "     | > loss_text_ce: 0.036052752286195755  (0.03672980582364266)\n",
            "     | > loss_mel_ce: 2.078413724899292  (2.55305284867926)\n",
            "     | > loss: 0.025172220543026924  (0.03083074644889415)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3669  (0.3693567581293061)\n",
            "     | > loader_time: 0.0302  (0.01674025401836493)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:15:22 -- STEP: 8250/12634 -- GLOBAL_STEP: 8250\u001b[0m\n",
            "     | > loss_text_ce: 0.03494437038898468  (0.03671041069179771)\n",
            "     | > loss_mel_ce: 2.200223207473755  (2.5515966711044276)\n",
            "     | > loss: 0.026609137654304504  (0.030813180106155847)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3536  (0.36936050371690243)\n",
            "     | > loader_time: 0.01  (0.01672856247063844)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:15:53 -- STEP: 8300/12634 -- GLOBAL_STEP: 8300\u001b[0m\n",
            "     | > loss_text_ce: 0.034519586712121964  (0.03669115168951359)\n",
            "     | > loss_mel_ce: 2.162214517593384  (2.550217733440626)\n",
            "     | > loss: 0.026151597499847412  (0.03079653490693818)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3674  (0.36940879198442034)\n",
            "     | > loader_time: 0.012  (0.016726917646017463)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:16:24 -- STEP: 8350/12634 -- GLOBAL_STEP: 8350\u001b[0m\n",
            "     | > loss_text_ce: 0.03332694247364998  (0.036671560019433114)\n",
            "     | > loss_mel_ce: 2.3717596530914307  (2.5486699798149948)\n",
            "     | > loss: 0.02863198332488537  (0.030777876033799067)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.353  (0.36939604979075374)\n",
            "     | > loader_time: 0.0275  (0.01674373558181493)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:16:55 -- STEP: 8400/12634 -- GLOBAL_STEP: 8400\u001b[0m\n",
            "     | > loss_text_ce: 0.03467898443341255  (0.03665256142239306)\n",
            "     | > loss_mel_ce: 2.3092665672302246  (2.5471905878328105)\n",
            "     | > loss: 0.02790411375463009  (0.030760038050689914)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2918  (0.3693804706562135)\n",
            "     | > loader_time: 0.01  (0.01674230442160656)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:17:26 -- STEP: 8450/12634 -- GLOBAL_STEP: 8450\u001b[0m\n",
            "     | > loss_text_ce: 0.0326610691845417  (0.036633636382292695)\n",
            "     | > loss_mel_ce: 2.2579922676086426  (2.5456585902434092)\n",
            "     | > loss: 0.02726968191564083  (0.030741574684235166)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3563  (0.36937872254636867)\n",
            "     | > loader_time: 0.0143  (0.016732010615647937)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:17:57 -- STEP: 8500/12634 -- GLOBAL_STEP: 8500\u001b[0m\n",
            "     | > loss_text_ce: 0.035626403987407684  (0.03661722179940516)\n",
            "     | > loss_mel_ce: 2.4889700412750244  (2.5441382340823866)\n",
            "     | > loss: 0.030054720118641853  (0.030723279792377226)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4565  (0.36938901598313273)\n",
            "     | > loader_time: 0.0233  (0.016740413693820764)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:18:27 -- STEP: 8550/12634 -- GLOBAL_STEP: 8550\u001b[0m\n",
            "     | > loss_text_ce: 0.03569269925355911  (0.036598252674335946)\n",
            "     | > loss_mel_ce: 2.150357723236084  (2.54274662468168)\n",
            "     | > loss: 0.026024410501122475  (0.030706487190828035)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3603  (0.3693806879143965)\n",
            "     | > loader_time: 0.0265  (0.016746016050639936)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:18:58 -- STEP: 8600/12634 -- GLOBAL_STEP: 8600\u001b[0m\n",
            "     | > loss_text_ce: 0.03310057148337364  (0.03657979677409624)\n",
            "     | > loss_mel_ce: 2.319782257080078  (2.5411016679364535)\n",
            "     | > loss: 0.02801050990819931  (0.030686684659747235)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3509  (0.3693850476797236)\n",
            "     | > loader_time: 0.011  (0.016734392670697974)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:19:29 -- STEP: 8650/12634 -- GLOBAL_STEP: 8650\u001b[0m\n",
            "     | > loss_text_ce: 0.034756921231746674  (0.03656183818947371)\n",
            "     | > loss_mel_ce: 2.082956314086914  (2.5396811921196814)\n",
            "     | > loss: 0.025210872292518616  (0.030669560441478186)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3503  (0.3694004822604228)\n",
            "     | > loader_time: 0.0264  (0.016729308663076092)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:20:00 -- STEP: 8700/12634 -- GLOBAL_STEP: 8700\u001b[0m\n",
            "     | > loss_text_ce: 0.03214099630713463  (0.03654413548137604)\n",
            "     | > loss_mel_ce: 2.4826114177703857  (2.538236827685909)\n",
            "     | > loss: 0.02993752807378769  (0.030652154879109317)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3222  (0.36940699810269223)\n",
            "     | > loader_time: 0.0214  (0.01673516136476367)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:20:31 -- STEP: 8750/12634 -- GLOBAL_STEP: 8750\u001b[0m\n",
            "     | > loss_text_ce: 0.028673948720097542  (0.0365247376354677)\n",
            "     | > loss_mel_ce: 2.0072078704833984  (2.5369114316804007)\n",
            "     | > loss: 0.024236688390374184  (0.030636145425907247)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3507  (0.36940642032623267)\n",
            "     | > loader_time: 0.0103  (0.016735545022147084)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:21:01 -- STEP: 8800/12634 -- GLOBAL_STEP: 8800\u001b[0m\n",
            "     | > loss_text_ce: 0.03109387308359146  (0.036506149149711474)\n",
            "     | > loss_mel_ce: 2.0168280601501465  (2.5354202179475216)\n",
            "     | > loss: 0.024380022659897804  (0.030618171590084085)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3537  (0.36940276839516356)\n",
            "     | > loader_time: 0.0248  (0.016741933741352813)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:21:32 -- STEP: 8850/12634 -- GLOBAL_STEP: 8850\u001b[0m\n",
            "     | > loss_text_ce: 0.032765571027994156  (0.036486286265238844)\n",
            "     | > loss_mel_ce: 2.5185883045196533  (2.5338312490915795)\n",
            "     | > loss: 0.030373262241482735  (0.030599018830785016)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4144  (0.36938850041836635)\n",
            "     | > loader_time: 0.0283  (0.01675234789228712)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:22:03 -- STEP: 8900/12634 -- GLOBAL_STEP: 8900\u001b[0m\n",
            "     | > loss_text_ce: 0.03426079824566841  (0.036468630460499044)\n",
            "     | > loss_mel_ce: 2.1732208728790283  (2.532398531128846)\n",
            "     | > loss: 0.026279544457793236  (0.030581752476020855)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4344  (0.36939381754800144)\n",
            "     | > loader_time: 0.031  (0.01676567985770411)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:22:34 -- STEP: 8950/12634 -- GLOBAL_STEP: 8950\u001b[0m\n",
            "     | > loss_text_ce: 0.03281301259994507  (0.03645012657236119)\n",
            "     | > loss_mel_ce: 2.3116767406463623  (2.530766236675511)\n",
            "     | > loss: 0.027910593897104263  (0.030562100114935646)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3609  (0.3693947266999566)\n",
            "     | > loader_time: 0.0103  (0.016758317814192993)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:23:05 -- STEP: 9000/12634 -- GLOBAL_STEP: 9000\u001b[0m\n",
            "     | > loss_text_ce: 0.0324709378182888  (0.03643124638104603)\n",
            "     | > loss_mel_ce: 2.4953620433807373  (2.529014239682086)\n",
            "     | > loss: 0.030093250796198845  (0.030541018243879125)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3678  (0.36937858340475244)\n",
            "     | > loader_time: 0.0208  (0.016767887406879043)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:23:36 -- STEP: 9050/12634 -- GLOBAL_STEP: 9050\u001b[0m\n",
            "     | > loss_text_ce: 0.033405836671590805  (0.03641290082951275)\n",
            "     | > loss_mel_ce: 2.320127010345459  (2.5274512369197972)\n",
            "     | > loss: 0.028018247336149216  (0.030522192668848976)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3721  (0.36940645752690726)\n",
            "     | > loader_time: 0.0122  (0.016775568572197214)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:24:07 -- STEP: 9100/12634 -- GLOBAL_STEP: 9100\u001b[0m\n",
            "     | > loss_text_ce: 0.032372914254665375  (0.03639776401856277)\n",
            "     | > loss_mel_ce: 2.1685216426849365  (2.5261926864005635)\n",
            "     | > loss: 0.026201127097010612  (0.030507029724194824)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4275  (0.36942867886889064)\n",
            "     | > loader_time: 0.0161  (0.016765602211375855)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:24:38 -- STEP: 9150/12634 -- GLOBAL_STEP: 9150\u001b[0m\n",
            "     | > loss_text_ce: 0.03185766562819481  (0.036377977947068305)\n",
            "     | > loss_mel_ce: 2.3939452171325684  (2.5248121794195044)\n",
            "     | > loss: 0.028878606855869293  (0.03049035956910078)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3558  (0.36947879900697744)\n",
            "     | > loader_time: 0.0124  (0.016756601307561528)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:25:09 -- STEP: 9200/12634 -- GLOBAL_STEP: 9200\u001b[0m\n",
            "     | > loss_text_ce: 0.0309789776802063  (0.03635939432146103)\n",
            "     | > loss_mel_ce: 2.0511891841888428  (2.523365314563972)\n",
            "     | > loss: 0.024787716567516327  (0.030472913754132174)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3701  (0.36949474487615613)\n",
            "     | > loader_time: 0.0254  (0.016758518167164053)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:25:40 -- STEP: 9250/12634 -- GLOBAL_STEP: 9250\u001b[0m\n",
            "     | > loss_text_ce: 0.03403366357088089  (0.036341132238708565)\n",
            "     | > loss_mel_ce: 2.6260952949523926  (2.522080771471994)\n",
            "     | > loss: 0.03166820481419563  (0.030457404169480586)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4563  (0.36948969704395973)\n",
            "     | > loader_time: 0.01  (0.016756517307178444)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:26:11 -- STEP: 9300/12634 -- GLOBAL_STEP: 9300\u001b[0m\n",
            "     | > loss_text_ce: 0.03472071513533592  (0.03632086941551769)\n",
            "     | > loss_mel_ce: 2.3791749477386475  (2.5206164173669623)\n",
            "     | > loss: 0.02873685210943222  (0.030439730158416216)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3619  (0.3695161820996187)\n",
            "     | > loader_time: 0.0304  (0.01674748207933164)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:26:42 -- STEP: 9350/12634 -- GLOBAL_STEP: 9350\u001b[0m\n",
            "     | > loss_text_ce: 0.031255293637514114  (0.03630045345959486)\n",
            "     | > loss_mel_ce: 2.2068562507629395  (2.519213942321218)\n",
            "     | > loss: 0.026644185185432434  (0.03042279097884101)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4194  (0.369514596551497)\n",
            "     | > loader_time: 0.0118  (0.016750019323379647)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:27:13 -- STEP: 9400/12634 -- GLOBAL_STEP: 9400\u001b[0m\n",
            "     | > loss_text_ce: 0.03167993575334549  (0.03628063129459277)\n",
            "     | > loss_mel_ce: 2.2923364639282227  (2.5181011921294107)\n",
            "     | > loss: 0.027666861191391945  (0.03040930797484648)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3581  (0.36956104169500603)\n",
            "     | > loader_time: 0.0098  (0.016750421726957343)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:27:43 -- STEP: 9450/12634 -- GLOBAL_STEP: 9450\u001b[0m\n",
            "     | > loss_text_ce: 0.03285405412316322  (0.03625993204455829)\n",
            "     | > loss_mel_ce: 1.8617956638336182  (2.516602501780891)\n",
            "     | > loss: 0.022555354982614517  (0.030391220002775197)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.365  (0.36951384910199964)\n",
            "     | > loader_time: 0.0104  (0.016735723788145418)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:28:14 -- STEP: 9500/12634 -- GLOBAL_STEP: 9500\u001b[0m\n",
            "     | > loss_text_ce: 0.031795237213373184  (0.03624292086868683)\n",
            "     | > loss_mel_ce: 2.0608997344970703  (2.515223142485864)\n",
            "     | > loss: 0.024913035333156586  (0.03037459654537475)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3571  (0.3695262502871057)\n",
            "     | > loader_time: 0.0255  (0.016739827984257803)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:28:45 -- STEP: 9550/12634 -- GLOBAL_STEP: 9550\u001b[0m\n",
            "     | > loss_text_ce: 0.03402079641819  (0.036223059554257496)\n",
            "     | > loss_mel_ce: 2.2541215419769287  (2.513940410264493)\n",
            "     | > loss: 0.027239792048931122  (0.030359089479279497)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3585  (0.3695665427153018)\n",
            "     | > loader_time: 0.0103  (0.016737326976516524)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:29:16 -- STEP: 9600/12634 -- GLOBAL_STEP: 9600\u001b[0m\n",
            "     | > loss_text_ce: 0.031768202781677246  (0.03620454780932039)\n",
            "     | > loss_mel_ce: 2.5710811614990234  (2.512507495929791)\n",
            "     | > loss: 0.030986303463578224  (0.030341810597262077)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3548  (0.3695819447934624)\n",
            "     | > loader_time: 0.01  (0.016734985783696216)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:29:47 -- STEP: 9650/12634 -- GLOBAL_STEP: 9650\u001b[0m\n",
            "     | > loss_text_ce: 0.02966422215104103  (0.03618497165122634)\n",
            "     | > loss_mel_ce: 2.3615612983703613  (2.5110244805701623)\n",
            "     | > loss: 0.028466971591114998  (0.030323922604206664)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3753  (0.3695992292641356)\n",
            "     | > loader_time: 0.0112  (0.01673066628411648)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:30:18 -- STEP: 9700/12634 -- GLOBAL_STEP: 9700\u001b[0m\n",
            "     | > loss_text_ce: 0.03440439701080322  (0.03616734297907679)\n",
            "     | > loss_mel_ce: 2.1401097774505615  (2.509586706014019)\n",
            "     | > loss: 0.025887075811624527  (0.03030659637519537)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3572  (0.369604909493751)\n",
            "     | > loader_time: 0.0291  (0.01673953680648021)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:30:49 -- STEP: 9750/12634 -- GLOBAL_STEP: 9750\u001b[0m\n",
            "     | > loss_text_ce: 0.03316935524344444  (0.03614846894240523)\n",
            "     | > loss_mel_ce: 2.0337791442871094  (2.5082681745137867)\n",
            "     | > loss: 0.024606529623270035  (0.030290674880720143)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3548  (0.3696217954586712)\n",
            "     | > loader_time: 0.0116  (0.01672888731345155)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:31:20 -- STEP: 9800/12634 -- GLOBAL_STEP: 9800\u001b[0m\n",
            "     | > loss_text_ce: 0.028759965673089027  (0.036132010568161316)\n",
            "     | > loss_mel_ce: 2.512880325317383  (2.5069198062468505)\n",
            "     | > loss: 0.03025762364268303  (0.03027442694413575)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3588  (0.3696152696560838)\n",
            "     | > loader_time: 0.0134  (0.016725648009047245)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:31:51 -- STEP: 9850/12634 -- GLOBAL_STEP: 9850\u001b[0m\n",
            "     | > loss_text_ce: 0.03263137862086296  (0.03611518828094296)\n",
            "     | > loss_mel_ce: 2.333939552307129  (2.5055189512465765)\n",
            "     | > loss: 0.02817346341907978  (0.030257549833525296)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3531  (0.3696192496924231)\n",
            "     | > loader_time: 0.0276  (0.016725639473968375)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:32:21 -- STEP: 9900/12634 -- GLOBAL_STEP: 9900\u001b[0m\n",
            "     | > loss_text_ce: 0.0324106439948082  (0.03609685403680551)\n",
            "     | > loss_mel_ce: 2.156777858734131  (2.504116954803463)\n",
            "     | > loss: 0.02606176771223545  (0.03024064113470645)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4483  (0.3696147026196873)\n",
            "     | > loader_time: 0.0113  (0.016728684011131846)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:32:52 -- STEP: 9950/12634 -- GLOBAL_STEP: 9950\u001b[0m\n",
            "     | > loss_text_ce: 0.03324626013636589  (0.0360782311626489)\n",
            "     | > loss_mel_ce: 2.197009563446045  (2.5027176871251786)\n",
            "     | > loss: 0.026550665497779846  (0.030223761484888072)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3567  (0.3696253447316997)\n",
            "     | > loader_time: 0.0274  (0.016727337381947604)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:33:24 -- STEP: 10000/12634 -- GLOBAL_STEP: 10000\u001b[0m\n",
            "     | > loss_text_ce: 0.03174581751227379  (0.03605941655803459)\n",
            "     | > loss_mel_ce: 2.031231164932251  (2.501360267114635)\n",
            "     | > loss: 0.024559251964092255  (0.030207377738505643)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3692  (0.3696604511976242)\n",
            "     | > loader_time: 0.0105  (0.01672923991680148)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000/checkpoint_10000.pth\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:35:16 -- STEP: 10050/12634 -- GLOBAL_STEP: 10050\u001b[0m\n",
            "     | > loss_text_ce: 0.031569529324769974  (0.03604120327947435)\n",
            "     | > loss_mel_ce: 2.3325417041778564  (2.500086233698903)\n",
            "     | > loss: 0.02814418077468872  (0.030191993848860895)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3696  (0.3696775324664901)\n",
            "     | > loader_time: 0.0145  (0.016716591445960834)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:35:47 -- STEP: 10100/12634 -- GLOBAL_STEP: 10100\u001b[0m\n",
            "     | > loss_text_ce: 0.03382553905248642  (0.036022105539162144)\n",
            "     | > loss_mel_ce: 2.459954023361206  (2.4988684984244895)\n",
            "     | > loss: 0.029687853530049324  (0.030177269645846754)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3696  (0.3697154686474567)\n",
            "     | > loader_time: 0.0129  (0.016714980366206427)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:36:18 -- STEP: 10150/12634 -- GLOBAL_STEP: 10150\u001b[0m\n",
            "     | > loss_text_ce: 0.030764374881982803  (0.0360037710058864)\n",
            "     | > loss_mel_ce: 2.2762279510498047  (2.497780609729839)\n",
            "     | > loss: 0.02746419422328472  (0.030164100320762055)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3606  (0.3697251600350067)\n",
            "     | > loader_time: 0.0128  (0.016713567202901607)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:36:49 -- STEP: 10200/12634 -- GLOBAL_STEP: 10200\u001b[0m\n",
            "     | > loss_text_ce: 0.029833711683750153  (0.03598486875092563)\n",
            "     | > loss_mel_ce: 2.3737311363220215  (2.496507558051274)\n",
            "     | > loss: 0.028613869100809097  (0.03014871991549933)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3581  (0.3697394657602501)\n",
            "     | > loader_time: 0.0104  (0.01671344443863514)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:37:20 -- STEP: 10250/12634 -- GLOBAL_STEP: 10250\u001b[0m\n",
            "     | > loss_text_ce: 0.03521615266799927  (0.03596710559907469)\n",
            "     | > loss_mel_ce: 2.0828375816345215  (2.495233178894691)\n",
            "     | > loss: 0.025214925408363342  (0.03013333726892388)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.435  (0.36975610660925173)\n",
            "     | > loader_time: 0.0106  (0.016712750620958287)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:37:51 -- STEP: 10300/12634 -- GLOBAL_STEP: 10300\u001b[0m\n",
            "     | > loss_text_ce: 0.033431679010391235  (0.03595131368041751)\n",
            "     | > loss_mel_ce: 2.340087413787842  (2.49400672578117)\n",
            "     | > loss: 0.028256181627511978  (0.030118548637346483)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3679  (0.3697372851093998)\n",
            "     | > loader_time: 0.0129  (0.01671257880127547)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:38:22 -- STEP: 10350/12634 -- GLOBAL_STEP: 10350\u001b[0m\n",
            "     | > loss_text_ce: 0.03306535258889198  (0.03593423767924157)\n",
            "     | > loss_mel_ce: 2.351407051086426  (2.492761507978761)\n",
            "     | > loss: 0.02838657610118389  (0.030103521330849023)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3595  (0.3697347045981369)\n",
            "     | > loader_time: 0.0201  (0.01672214650877434)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:38:53 -- STEP: 10400/12634 -- GLOBAL_STEP: 10400\u001b[0m\n",
            "     | > loss_text_ce: 0.03139768913388252  (0.035917167786974354)\n",
            "     | > loss_mel_ce: 2.3039231300354004  (2.491660919613561)\n",
            "     | > loss: 0.02780143730342388  (0.030090215875265728)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3629  (0.3697483924719006)\n",
            "     | > loader_time: 0.011  (0.01671780989720272)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:39:23 -- STEP: 10450/12634 -- GLOBAL_STEP: 10450\u001b[0m\n",
            "     | > loss_text_ce: 0.02962200529873371  (0.035898900593688825)\n",
            "     | > loss_mel_ce: 2.009936809539795  (2.4903397231352935)\n",
            "     | > loss: 0.02428046427667141  (0.0300742698785221)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.367  (0.36972905916460425)\n",
            "     | > loader_time: 0.0106  (0.016721745335884632)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:39:54 -- STEP: 10500/12634 -- GLOBAL_STEP: 10500\u001b[0m\n",
            "     | > loss_text_ce: 0.03210124000906944  (0.0358828523806517)\n",
            "     | > loss_mel_ce: 2.019214153289795  (2.489239165907814)\n",
            "     | > loss: 0.024420421570539474  (0.03006097695728147)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3009  (0.3697132623082119)\n",
            "     | > loader_time: 0.0109  (0.01672611574899582)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:40:25 -- STEP: 10550/12634 -- GLOBAL_STEP: 10550\u001b[0m\n",
            "     | > loss_text_ce: 0.03058490715920925  (0.03586355961258934)\n",
            "     | > loss_mel_ce: 2.1929588317871094  (2.488017580181501)\n",
            "     | > loss: 0.026470758020877838  (0.030046204594603967)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4305  (0.36970755522850024)\n",
            "     | > loader_time: 0.0104  (0.016726919011482124)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:40:55 -- STEP: 10600/12634 -- GLOBAL_STEP: 10600\u001b[0m\n",
            "     | > loss_text_ce: 0.032403476536273956  (0.0358447391114566)\n",
            "     | > loss_mel_ce: 2.3879096508026123  (2.4867291587816083)\n",
            "     | > loss: 0.028813252225518227  (0.030030642190667013)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3627  (0.3696749737352699)\n",
            "     | > loader_time: 0.0116  (0.01672016424952814)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:41:26 -- STEP: 10650/12634 -- GLOBAL_STEP: 10650\u001b[0m\n",
            "     | > loss_text_ce: 0.03270822763442993  (0.03582661522613577)\n",
            "     | > loss_mel_ce: 2.363590955734253  (2.4857186079249143)\n",
            "     | > loss: 0.02852737158536911  (0.030018396061875768)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3535  (0.36971381395635533)\n",
            "     | > loader_time: 0.0113  (0.01672883239710277)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:41:57 -- STEP: 10700/12634 -- GLOBAL_STEP: 10700\u001b[0m\n",
            "     | > loss_text_ce: 0.029673034325242043  (0.035807921165234756)\n",
            "     | > loss_mel_ce: 2.094254493713379  (2.4844967860484806)\n",
            "     | > loss: 0.02528485283255577  (0.030003628014090778)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4668  (0.3697257622602952)\n",
            "     | > loader_time: 0.0101  (0.016727322752230652)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:42:28 -- STEP: 10750/12634 -- GLOBAL_STEP: 10750\u001b[0m\n",
            "     | > loss_text_ce: 0.030462784692645073  (0.035791254647942375)\n",
            "     | > loss_mel_ce: 2.3691978454589844  (2.483155416843507)\n",
            "     | > loss: 0.028567388653755188  (0.029987460923749383)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3519  (0.3697069217327039)\n",
            "     | > loader_time: 0.0256  (0.01672546641771185)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:42:58 -- STEP: 10800/12634 -- GLOBAL_STEP: 10800\u001b[0m\n",
            "     | > loss_text_ce: 0.030541321262717247  (0.03577445137935369)\n",
            "     | > loss_mel_ce: 2.0653927326202393  (2.4820280249803206)\n",
            "     | > loss: 0.024951597675681114  (0.02997383955262467)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3579  (0.3696848271290473)\n",
            "     | > loader_time: 0.0276  (0.016729300971384423)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:43:29 -- STEP: 10850/12634 -- GLOBAL_STEP: 10850\u001b[0m\n",
            "     | > loss_text_ce: 0.03315236046910286  (0.035759233620172165)\n",
            "     | > loss_mel_ce: 2.3295369148254395  (2.480910964440647)\n",
            "     | > loss: 0.02812725305557251  (0.029960360048931076)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3689  (0.3696976689808941)\n",
            "     | > loader_time: 0.0122  (0.016728559463254897)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:44:00 -- STEP: 10900/12634 -- GLOBAL_STEP: 10900\u001b[0m\n",
            "     | > loss_text_ce: 0.03100728988647461  (0.035743006581799304)\n",
            "     | > loss_mel_ce: 2.129101276397705  (2.4796995921310003)\n",
            "     | > loss: 0.025715578347444534  (0.029945745769409723)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3422  (0.36967470525601714)\n",
            "     | > loader_time: 0.0265  (0.016718963745537187)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:44:30 -- STEP: 10950/12634 -- GLOBAL_STEP: 10950\u001b[0m\n",
            "     | > loss_text_ce: 0.03287931904196739  (0.03572633173639905)\n",
            "     | > loss_mel_ce: 2.293365001678467  (2.4785022741039135)\n",
            "     | > loss: 0.027693385258316994  (0.029931293473872456)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3495  (0.36965665795487496)\n",
            "     | > loader_time: 0.0318  (0.01672229174609601)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:45:01 -- STEP: 11000/12634 -- GLOBAL_STEP: 11000\u001b[0m\n",
            "     | > loss_text_ce: 0.0320599228143692  (0.035707977852868666)\n",
            "     | > loss_mel_ce: 2.201266050338745  (2.477378777829093)\n",
            "     | > loss: 0.026587214320898056  (0.02991770001907244)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3606  (0.3696445975303663)\n",
            "     | > loader_time: 0.0106  (0.01672977347807454)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:45:32 -- STEP: 11050/12634 -- GLOBAL_STEP: 11050\u001b[0m\n",
            "     | > loss_text_ce: 0.031596601009368896  (0.03569321353409884)\n",
            "     | > loss_mel_ce: 2.329000234603882  (2.476189817929169)\n",
            "     | > loss: 0.028102343901991844  (0.029903369969035202)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3758  (0.3696473484125625)\n",
            "     | > loader_time: 0.0124  (0.016726513577802166)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:46:03 -- STEP: 11100/12634 -- GLOBAL_STEP: 11100\u001b[0m\n",
            "     | > loss_text_ce: 0.03124961629509926  (0.03567646963974907)\n",
            "     | > loss_mel_ce: 2.0774736404418945  (2.475178256453703)\n",
            "     | > loss: 0.025103848427534103  (0.02989112823765292)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3697  (0.3697072850476527)\n",
            "     | > loader_time: 0.0312  (0.016729151987814703)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:46:34 -- STEP: 11150/12634 -- GLOBAL_STEP: 11150\u001b[0m\n",
            "     | > loss_text_ce: 0.032977696508169174  (0.03565927188041626)\n",
            "     | > loss_mel_ce: 1.9853171110153198  (2.474100058816483)\n",
            "     | > loss: 0.024027319625020027  (0.029878087816217057)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3579  (0.3697048187469701)\n",
            "     | > loader_time: 0.0099  (0.016735780549156296)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:47:05 -- STEP: 11200/12634 -- GLOBAL_STEP: 11200\u001b[0m\n",
            "     | > loss_text_ce: 0.030948087573051453  (0.03564142440578761)\n",
            "     | > loss_mel_ce: 2.141686201095581  (2.472795003748376)\n",
            "     | > loss: 0.025864696130156517  (0.029862338977566558)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3634  (0.36971530601382385)\n",
            "     | > loader_time: 0.0102  (0.016725995391607285)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:47:36 -- STEP: 11250/12634 -- GLOBAL_STEP: 11250\u001b[0m\n",
            "     | > loss_text_ce: 0.03218165412545204  (0.03562603306422629)\n",
            "     | > loss_mel_ce: 2.260885238647461  (2.471749922582848)\n",
            "     | > loss: 0.027298416942358017  (0.029849714304010108)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3412  (0.36973157431284714)\n",
            "     | > loader_time: 0.0362  (0.01672264247470431)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:48:07 -- STEP: 11300/12634 -- GLOBAL_STEP: 11300\u001b[0m\n",
            "     | > loss_text_ce: 0.031227104365825653  (0.035609477352252006)\n",
            "     | > loss_mel_ce: 2.1861937046051025  (2.4706660607641875)\n",
            "     | > loss: 0.026397867128252983  (0.029836614094674623)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3511  (0.3697180159324051)\n",
            "     | > loader_time: 0.0104  (0.01673317246732458)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:48:38 -- STEP: 11350/12634 -- GLOBAL_STEP: 11350\u001b[0m\n",
            "     | > loss_text_ce: 0.028734907507896423  (0.0355932669924153)\n",
            "     | > loss_mel_ce: 2.2087888717651367  (2.4695485953507545)\n",
            "     | > loss: 0.026637189090251923  (0.02982311795412316)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4193  (0.369728776347796)\n",
            "     | > loader_time: 0.01  (0.01673612063151622)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:49:09 -- STEP: 11400/12634 -- GLOBAL_STEP: 11400\u001b[0m\n",
            "     | > loss_text_ce: 0.03289736062288284  (0.035577394666901754)\n",
            "     | > loss_mel_ce: 2.300564765930176  (2.4684531438455335)\n",
            "     | > loss: 0.027779312804341316  (0.029809887909020023)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3542  (0.36974415354561513)\n",
            "     | > loader_time: 0.0287  (0.016742572596198615)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:49:40 -- STEP: 11450/12634 -- GLOBAL_STEP: 11450\u001b[0m\n",
            "     | > loss_text_ce: 0.032968975603580475  (0.03556148784470993)\n",
            "     | > loss_mel_ce: 2.090620279312134  (2.467226569715035)\n",
            "     | > loss: 0.025280825793743134  (0.029795096468945032)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.348  (0.36973968166451393)\n",
            "     | > loader_time: 0.0433  (0.016751589046295014)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:50:10 -- STEP: 11500/12634 -- GLOBAL_STEP: 11500\u001b[0m\n",
            "     | > loss_text_ce: 0.028851844370365143  (0.035544089060600616)\n",
            "     | > loss_mel_ce: 2.1043381690979004  (2.466160756484331)\n",
            "     | > loss: 0.025395117700099945  (0.029782201086535436)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3502  (0.3697424502165434)\n",
            "     | > loader_time: 0.0101  (0.01674979232705157)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:50:41 -- STEP: 11550/12634 -- GLOBAL_STEP: 11550\u001b[0m\n",
            "     | > loss_text_ce: 0.033041227608919144  (0.03552747623841737)\n",
            "     | > loss_mel_ce: 2.39400315284729  (2.465111701055017)\n",
            "     | > loss: 0.02889338694512844  (0.0297695145602802)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4385  (0.3697467130809648)\n",
            "     | > loader_time: 0.0105  (0.01674365233549307)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:51:13 -- STEP: 11600/12634 -- GLOBAL_STEP: 11600\u001b[0m\n",
            "     | > loss_text_ce: 0.0315699428319931  (0.03551052501553597)\n",
            "     | > loss_mel_ce: 2.257578134536743  (2.464215628350614)\n",
            "     | > loss: 0.02725176326930523  (0.029758645227853372)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4124  (0.3697595841925732)\n",
            "     | > loader_time: 0.0307  (0.016757732958629205)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:51:44 -- STEP: 11650/12634 -- GLOBAL_STEP: 11650\u001b[0m\n",
            "     | > loss_text_ce: 0.03172941133379936  (0.03549386054053576)\n",
            "     | > loss_mel_ce: 2.0152993202209473  (2.462957151038464)\n",
            "     | > loss: 0.024369390681385994  (0.029743464968842788)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3641  (0.3697888913379731)\n",
            "     | > loader_time: 0.0123  (0.016761070321046213)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:52:14 -- STEP: 11700/12634 -- GLOBAL_STEP: 11700\u001b[0m\n",
            "     | > loss_text_ce: 0.03229646384716034  (0.03547766921277607)\n",
            "     | > loss_mel_ce: 2.19581937789917  (2.461710207360433)\n",
            "     | > loss: 0.026525188237428665  (0.02972842764650658)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3676  (0.3697829980931743)\n",
            "     | > loader_time: 0.0107  (0.016756853670136528)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:52:45 -- STEP: 11750/12634 -- GLOBAL_STEP: 11750\u001b[0m\n",
            "     | > loss_text_ce: 0.033751070499420166  (0.035462699403946654)\n",
            "     | > loss_mel_ce: 2.2070999145507812  (2.4605639160338963)\n",
            "     | > loss: 0.02667679637670517  (0.029714603108453023)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3597  (0.36976113834787044)\n",
            "     | > loader_time: 0.0225  (0.01675486335348574)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:53:16 -- STEP: 11800/12634 -- GLOBAL_STEP: 11800\u001b[0m\n",
            "     | > loss_text_ce: 0.032580383121967316  (0.03544754151112821)\n",
            "     | > loss_mel_ce: 2.4298155307769775  (2.4595931302288925)\n",
            "     | > loss: 0.029314236715435982  (0.029702865682479217)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3681  (0.3698056928384114)\n",
            "     | > loader_time: 0.0115  (0.016757238032454127)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:53:47 -- STEP: 11850/12634 -- GLOBAL_STEP: 11850\u001b[0m\n",
            "     | > loss_text_ce: 0.032115690410137177  (0.03543250016538021)\n",
            "     | > loss_mel_ce: 2.1374621391296387  (2.4585901346387833)\n",
            "     | > loss: 0.02582830749452114  (0.029690746194073955)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3704  (0.3698042896125902)\n",
            "     | > loader_time: 0.0118  (0.016762548800762164)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:54:18 -- STEP: 11900/12634 -- GLOBAL_STEP: 11900\u001b[0m\n",
            "     | > loss_text_ce: 0.03373856097459793  (0.035415459076615655)\n",
            "     | > loss_mel_ce: 2.064242362976074  (2.4574451560132724)\n",
            "     | > loss: 0.024975964799523354  (0.029676912625578554)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3702  (0.36980184420818163)\n",
            "     | > loader_time: 0.0162  (0.016750780794800798)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:54:49 -- STEP: 11950/12634 -- GLOBAL_STEP: 11950\u001b[0m\n",
            "     | > loss_text_ce: 0.03284396231174469  (0.035400492131367096)\n",
            "     | > loss_mel_ce: 1.9057954549789429  (2.4564119584091606)\n",
            "     | > loss: 0.0230790413916111  (0.029664434476065867)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3712  (0.3697870112662547)\n",
            "     | > loader_time: 0.0111  (0.016763645435476867)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:55:19 -- STEP: 12000/12634 -- GLOBAL_STEP: 12000\u001b[0m\n",
            "     | > loss_text_ce: 0.03044886328279972  (0.03538512567073721)\n",
            "     | > loss_mel_ce: 1.976886510848999  (2.4553444009920042)\n",
            "     | > loss: 0.023896850645542145  (0.029651542524807187)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3541  (0.36978924103578054)\n",
            "     | > loader_time: 0.0115  (0.01676624600092567)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:55:50 -- STEP: 12050/12634 -- GLOBAL_STEP: 12050\u001b[0m\n",
            "     | > loss_text_ce: 0.03295019641518593  (0.035369367719129324)\n",
            "     | > loss_mel_ce: 2.1608715057373047  (2.454198283041175)\n",
            "     | > loss: 0.026116924360394478  (0.029637710667868408)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3619  (0.3697821975051132)\n",
            "     | > loader_time: 0.0326  (0.016763965163488076)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:56:21 -- STEP: 12100/12634 -- GLOBAL_STEP: 12100\u001b[0m\n",
            "     | > loss_text_ce: 0.03295086696743965  (0.0353536438975821)\n",
            "     | > loss_mel_ce: 2.131939172744751  (2.4530894613364564)\n",
            "     | > loss: 0.025772500783205032  (0.029624323221000545)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3697  (0.3697638296095805)\n",
            "     | > loader_time: 0.0267  (0.016773780673003374)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:56:52 -- STEP: 12150/12634 -- GLOBAL_STEP: 12150\u001b[0m\n",
            "     | > loss_text_ce: 0.0302947536110878  (0.03533746735855865)\n",
            "     | > loss_mel_ce: 2.3028154373168945  (2.4521449207376604)\n",
            "     | > loss: 0.027775119990110397  (0.029612886112014732)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3637  (0.3697862327049801)\n",
            "     | > loader_time: 0.0105  (0.016781616132445762)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:57:23 -- STEP: 12200/12634 -- GLOBAL_STEP: 12200\u001b[0m\n",
            "     | > loss_text_ce: 0.03089662455022335  (0.035321612711537706)\n",
            "     | > loss_mel_ce: 2.475511074066162  (2.451345919282716)\n",
            "     | > loss: 0.029838187620043755  (0.02960318544390996)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3598  (0.3697867768709789)\n",
            "     | > loader_time: 0.01  (0.01677830711739959)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:57:54 -- STEP: 12250/12634 -- GLOBAL_STEP: 12250\u001b[0m\n",
            "     | > loss_text_ce: 0.03198506310582161  (0.035307562968104375)\n",
            "     | > loss_mel_ce: 2.1496589183807373  (2.450403812719857)\n",
            "     | > loss: 0.025971952825784683  (0.029591802631409835)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3681  (0.36979759471270623)\n",
            "     | > loader_time: 0.0122  (0.01677364109973516)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:58:24 -- STEP: 12300/12634 -- GLOBAL_STEP: 12300\u001b[0m\n",
            "     | > loss_text_ce: 0.030980294570326805  (0.03529165977702989)\n",
            "     | > loss_mel_ce: 2.3057117462158203  (2.449452857157086)\n",
            "     | > loss: 0.02781776338815689  (0.029580292407180995)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.355  (0.3697738592023784)\n",
            "     | > loader_time: 0.031  (0.01677813679222166)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:58:55 -- STEP: 12350/12634 -- GLOBAL_STEP: 12350\u001b[0m\n",
            "     | > loss_text_ce: 0.0315084271132946  (0.035276822867965324)\n",
            "     | > loss_mel_ce: 2.3645265102386475  (2.4483640869426386)\n",
            "     | > loss: 0.02852422557771206  (0.029567154227239434)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.428  (0.36977426918894774)\n",
            "     | > loader_time: 0.0102  (0.016775553062377165)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:59:26 -- STEP: 12400/12634 -- GLOBAL_STEP: 12400\u001b[0m\n",
            "     | > loss_text_ce: 0.031184207648038864  (0.03526141605925769)\n",
            "     | > loss_mel_ce: 2.0807583332061768  (2.4473219418814147)\n",
            "     | > loss: 0.02514217421412468  (0.02955456432405742)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3593  (0.3697675924531887)\n",
            "     | > loader_time: 0.0131  (0.01677648121310816)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 08:59:57 -- STEP: 12450/12634 -- GLOBAL_STEP: 12450\u001b[0m\n",
            "     | > loss_text_ce: 0.03349250182509422  (0.03524602881023075)\n",
            "     | > loss_mel_ce: 2.2993123531341553  (2.4464810007164335)\n",
            "     | > loss: 0.027771487832069397  (0.029544369938024107)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3564  (0.3697548700049232)\n",
            "     | > loader_time: 0.0315  (0.01677907723499585)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:00:27 -- STEP: 12500/12634 -- GLOBAL_STEP: 12500\u001b[0m\n",
            "     | > loss_text_ce: 0.033089227974414825  (0.03523025763720264)\n",
            "     | > loss_mel_ce: 1.9702485799789429  (2.445439092330939)\n",
            "     | > loss: 0.023849260061979294  (0.029531778513342172)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3597  (0.3697401603889477)\n",
            "     | > loader_time: 0.0109  (0.016776641654968224)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:00:58 -- STEP: 12550/12634 -- GLOBAL_STEP: 12550\u001b[0m\n",
            "     | > loss_text_ce: 0.03300171718001366  (0.035215528357877814)\n",
            "     | > loss_mel_ce: 2.1133594512939453  (2.4444189333725816)\n",
            "     | > loss: 0.025551918894052505  (0.029519458414905133)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3537  (0.3697543484851195)\n",
            "     | > loader_time: 0.0259  (0.016773065019888667)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:01:29 -- STEP: 12600/12634 -- GLOBAL_STEP: 12600\u001b[0m\n",
            "     | > loss_text_ce: 0.032819729298353195  (0.035200073236954274)\n",
            "     | > loss_mel_ce: 2.2487025260925293  (2.4434665309909867)\n",
            "     | > loss: 0.02716097980737686  (0.029507936301922073)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.2963  (0.3697541527331833)\n",
            "     | > loader_time: 0.0124  (0.016767592638257892)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.10481043422923368 \u001b[0m(+0.01311423638287712)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.030653012193301146 \u001b[0m(-0.009748858695521063)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 1.9824791108860689 \u001b[0m(-1.3527791205574484)\n",
            "     | > avg_loss:\u001b[92m 2.0131321318009334 \u001b[0m(-1.3625279679017894)\n",
            "\n",
            " > BEST MODEL : /content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000/best_model_12634.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/1000\u001b[0m\n",
            " --> /content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-01-05 09:05:32) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:05:45 -- STEP: 16/12634 -- GLOBAL_STEP: 12650\u001b[0m\n",
            "     | > loss_text_ce: 0.03241506591439247  (0.030542486463673413)\n",
            "     | > loss_mel_ce: 1.9350053071975708  (2.2210952788591385)\n",
            "     | > loss: 0.023421671241521835  (0.02680521155707538)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3474  (0.35421593487262726)\n",
            "     | > loader_time: 0.0096  (0.018887430429458618)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:06:16 -- STEP: 66/12634 -- GLOBAL_STEP: 12700\u001b[0m\n",
            "     | > loss_text_ce: 0.029877573251724243  (0.031114102764563126)\n",
            "     | > loss_mel_ce: 2.2071237564086914  (2.1925626180388704)\n",
            "     | > loss: 0.02663096971809864  (0.026472342285242947)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4334  (0.37190228881257953)\n",
            "     | > loader_time: 0.012  (0.015060898029442984)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:06:47 -- STEP: 116/12634 -- GLOBAL_STEP: 12750\u001b[0m\n",
            "     | > loss_text_ce: 0.027244223281741142  (0.03113436825766132)\n",
            "     | > loss_mel_ce: 2.1021039485931396  (2.200711874098612)\n",
            "     | > loss: 0.025349384173750877  (0.026569598498914777)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3686  (0.37170619594639753)\n",
            "     | > loader_time: 0.0216  (0.015520136931846878)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:07:18 -- STEP: 166/12634 -- GLOBAL_STEP: 12800\u001b[0m\n",
            "     | > loss_text_ce: 0.029112812131643295  (0.031168312283165484)\n",
            "     | > loss_mel_ce: 2.4620935916900635  (2.1809760181300613)\n",
            "     | > loss: 0.02965722046792507  (0.026335051934044038)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4993  (0.36998540378478656)\n",
            "     | > loader_time: 0.0102  (0.016239814011447397)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:07:49 -- STEP: 216/12634 -- GLOBAL_STEP: 12850\u001b[0m\n",
            "     | > loss_text_ce: 0.03352881968021393  (0.031192418153363245)\n",
            "     | > loss_mel_ce: 2.354823589324951  (2.1884787916033366)\n",
            "     | > loss: 0.02843276783823967  (0.026424657682784725)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3626  (0.3707459855962683)\n",
            "     | > loader_time: 0.0106  (0.016214402737440885)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:08:20 -- STEP: 266/12634 -- GLOBAL_STEP: 12900\u001b[0m\n",
            "     | > loss_text_ce: 0.031046664342284203  (0.031221813053116762)\n",
            "     | > loss_mel_ce: 2.1957216262817383  (2.1854888021497816)\n",
            "     | > loss: 0.026509147137403488  (0.026389412518898793)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3455  (0.37072415997211206)\n",
            "     | > loader_time: 0.0304  (0.016600894748716434)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:08:51 -- STEP: 316/12634 -- GLOBAL_STEP: 12950\u001b[0m\n",
            "     | > loss_text_ce: 0.0329451784491539  (0.031181460252338197)\n",
            "     | > loss_mel_ce: 2.4861252307891846  (2.1889126206500626)\n",
            "     | > loss: 0.029988933354616165  (0.026429691882450358)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3594  (0.3713073934180828)\n",
            "     | > loader_time: 0.0256  (0.01690156701244885)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:09:22 -- STEP: 366/12634 -- GLOBAL_STEP: 13000\u001b[0m\n",
            "     | > loss_text_ce: 0.03254806995391846  (0.031239885429704125)\n",
            "     | > loss_mel_ce: 2.110802412033081  (2.1867769705793245)\n",
            "     | > loss: 0.025516079738736153  (0.026404963022535605)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3699  (0.3707140215107654)\n",
            "     | > loader_time: 0.0094  (0.01652823445575484)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:09:53 -- STEP: 416/12634 -- GLOBAL_STEP: 13050\u001b[0m\n",
            "     | > loss_text_ce: 0.03274528682231903  (0.031234140373551503)\n",
            "     | > loss_mel_ce: 2.1351871490478516  (2.1894136349169107)\n",
            "     | > loss: 0.02580871991813183  (0.026436283485963934)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3648  (0.37101356570537286)\n",
            "     | > loader_time: 0.0207  (0.01636871007772591)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:10:23 -- STEP: 466/12634 -- GLOBAL_STEP: 13100\u001b[0m\n",
            "     | > loss_text_ce: 0.03156823664903641  (0.03124996055269318)\n",
            "     | > loss_mel_ce: 2.105424404144287  (2.1889465586821917)\n",
            "     | > loss: 0.025440389290452003  (0.026430911396514184)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3611  (0.37041262444508444)\n",
            "     | > loader_time: 0.0164  (0.016618827381870763)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:10:54 -- STEP: 516/12634 -- GLOBAL_STEP: 13150\u001b[0m\n",
            "     | > loss_text_ce: 0.031671974807977676  (0.03126741275046916)\n",
            "     | > loss_mel_ce: 2.2468395233154297  (2.1900426736173704)\n",
            "     | > loss: 0.02712513692677021  (0.02644416816936906)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4315  (0.370906525804091)\n",
            "     | > loader_time: 0.0114  (0.016489536263221905)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:11:26 -- STEP: 566/12634 -- GLOBAL_STEP: 13200\u001b[0m\n",
            "     | > loss_text_ce: 0.031020881608128548  (0.03126975604375766)\n",
            "     | > loss_mel_ce: 2.2035224437713623  (2.1913930270360122)\n",
            "     | > loss: 0.026601707562804222  (0.026460271700558508)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3819  (0.3718619932134246)\n",
            "     | > loader_time: 0.0122  (0.016659858369995752)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:11:57 -- STEP: 616/12634 -- GLOBAL_STEP: 13250\u001b[0m\n",
            "     | > loss_text_ce: 0.029682738706469536  (0.031221811308876267)\n",
            "     | > loss_mel_ce: 2.658564805984497  (2.1913420248341233)\n",
            "     | > loss: 0.03200294449925423  (0.026459093749910196)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3658  (0.37174724874558407)\n",
            "     | > loader_time: 0.0103  (0.016901251170542326)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:12:28 -- STEP: 666/12634 -- GLOBAL_STEP: 13300\u001b[0m\n",
            "     | > loss_text_ce: 0.03111192397773266  (0.031206040061428568)\n",
            "     | > loss_mel_ce: 2.0260252952575684  (2.187711139698999)\n",
            "     | > loss: 0.02448972873389721  (0.02641568116720642)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3597  (0.37196922803426313)\n",
            "     | > loader_time: 0.0101  (0.016771843841484002)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:12:59 -- STEP: 716/12634 -- GLOBAL_STEP: 13350\u001b[0m\n",
            "     | > loss_text_ce: 0.029426464810967445  (0.031222104326452463)\n",
            "     | > loss_mel_ce: 2.0475382804870605  (2.189394349825446)\n",
            "     | > loss: 0.024725772440433502  (0.02643591063305235)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3632  (0.37224173046357156)\n",
            "     | > loader_time: 0.0103  (0.016694903040731426)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:13:30 -- STEP: 766/12634 -- GLOBAL_STEP: 13400\u001b[0m\n",
            "     | > loss_text_ce: 0.032293885946273804  (0.03122375506236566)\n",
            "     | > loss_mel_ce: 2.30849027633667  (2.190734827642962)\n",
            "     | > loss: 0.027866477146744728  (0.02645188835315775)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3594  (0.3722762037506304)\n",
            "     | > loader_time: 0.0264  (0.016753361368303837)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:14:01 -- STEP: 816/12634 -- GLOBAL_STEP: 13450\u001b[0m\n",
            "     | > loss_text_ce: 0.031174471601843834  (0.031234728352751075)\n",
            "     | > loss_mel_ce: 2.3640246391296387  (2.1895821224532854)\n",
            "     | > loss: 0.028514275327324867  (0.026438296309160975)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3583  (0.37162566973882577)\n",
            "     | > loader_time: 0.032  (0.016841594202845714)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:14:31 -- STEP: 866/12634 -- GLOBAL_STEP: 13500\u001b[0m\n",
            "     | > loss_text_ce: 0.031648680567741394  (0.031220903269533615)\n",
            "     | > loss_mel_ce: 2.556898593902588  (2.189141697476143)\n",
            "     | > loss: 0.030816039070487022  (0.026432888578047094)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3558  (0.37119748906230277)\n",
            "     | > loader_time: 0.01  (0.01680918103277547)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:15:02 -- STEP: 916/12634 -- GLOBAL_STEP: 13550\u001b[0m\n",
            "     | > loss_text_ce: 0.030061563476920128  (0.031222882883940466)\n",
            "     | > loss_mel_ce: 2.220651865005493  (2.18760157503415)\n",
            "     | > loss: 0.026794206351041794  (0.026414577351012727)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3581  (0.3709692429246862)\n",
            "     | > loader_time: 0.0193  (0.016727740847908266)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:15:32 -- STEP: 966/12634 -- GLOBAL_STEP: 13600\u001b[0m\n",
            "     | > loss_text_ce: 0.03331271931529045  (0.03125201292359125)\n",
            "     | > loss_mel_ce: 2.161503791809082  (2.1870877262721615)\n",
            "     | > loss: 0.026128768920898438  (0.026408806886701348)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.377  (0.3705952448874528)\n",
            "     | > loader_time: 0.0207  (0.016714339424117517)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:16:03 -- STEP: 1016/12634 -- GLOBAL_STEP: 13650\u001b[0m\n",
            "     | > loss_text_ce: 0.0320894755423069  (0.031259815951105295)\n",
            "     | > loss_mel_ce: 2.7345950603485107  (2.1866504772910895)\n",
            "     | > loss: 0.03293672204017639  (0.02640369444110203)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4281  (0.370507342608895)\n",
            "     | > loader_time: 0.0107  (0.01682608075967925)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:16:34 -- STEP: 1066/12634 -- GLOBAL_STEP: 13700\u001b[0m\n",
            "     | > loss_text_ce: 0.032849475741386414  (0.03125803174335669)\n",
            "     | > loss_mel_ce: 2.2486188411712646  (2.1858799539184903)\n",
            "     | > loss: 0.027160339057445526  (0.026394500316768935)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.358  (0.37048714044617453)\n",
            "     | > loader_time: 0.0106  (0.016809847520395257)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:17:04 -- STEP: 1116/12634 -- GLOBAL_STEP: 13750\u001b[0m\n",
            "     | > loss_text_ce: 0.03147195652127266  (0.03125142357829544)\n",
            "     | > loss_mel_ce: 2.344214677810669  (2.185763095228473)\n",
            "     | > loss: 0.028281984850764275  (0.026393030481379618)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3573  (0.3702966008989616)\n",
            "     | > loader_time: 0.0254  (0.01676326520126781)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:17:35 -- STEP: 1166/12634 -- GLOBAL_STEP: 13800\u001b[0m\n",
            "     | > loss_text_ce: 0.03137769177556038  (0.03124213368531259)\n",
            "     | > loss_mel_ce: 2.3130764961242676  (2.184644013592143)\n",
            "     | > loss: 0.027910171076655388  (0.026379597501104007)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3663  (0.3701166202846156)\n",
            "     | > loader_time: 0.0314  (0.016836944616065837)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:18:06 -- STEP: 1216/12634 -- GLOBAL_STEP: 13850\u001b[0m\n",
            "     | > loss_text_ce: 0.0340382345020771  (0.0312565390884533)\n",
            "     | > loss_mel_ce: 2.5057713985443115  (2.183873221278189)\n",
            "     | > loss: 0.030235830694437027  (0.02637059289631188)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3559  (0.3702242386184241)\n",
            "     | > loader_time: 0.0292  (0.01692194609265578)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:18:37 -- STEP: 1266/12634 -- GLOBAL_STEP: 13900\u001b[0m\n",
            "     | > loss_text_ce: 0.03090536594390869  (0.03125448478459367)\n",
            "     | > loss_mel_ce: 2.197972297668457  (2.184367867630992)\n",
            "     | > loss: 0.02653425745666027  (0.02637645708452939)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3583  (0.3704093400900961)\n",
            "     | > loader_time: 0.0102  (0.01685404721029562)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:19:08 -- STEP: 1316/12634 -- GLOBAL_STEP: 13950\u001b[0m\n",
            "     | > loss_text_ce: 0.031717680394649506  (0.03124328734251271)\n",
            "     | > loss_mel_ce: 2.47953724861145  (2.183701712762693)\n",
            "     | > loss: 0.02989589422941208  (0.02636839336741115)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4254  (0.37044756173362825)\n",
            "     | > loader_time: 0.0108  (0.016824317377026676)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:19:39 -- STEP: 1366/12634 -- GLOBAL_STEP: 14000\u001b[0m\n",
            "     | > loss_text_ce: 0.031031642109155655  (0.03124651453685484)\n",
            "     | > loss_mel_ce: 1.9968315362930298  (2.1826320817669504)\n",
            "     | > loss: 0.024141229689121246  (0.0263556980870195)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3717  (0.37032451950788153)\n",
            "     | > loader_time: 0.0486  (0.016890725663605406)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:20:09 -- STEP: 1416/12634 -- GLOBAL_STEP: 14050\u001b[0m\n",
            "     | > loss_text_ce: 0.029517628252506256  (0.03124164640745616)\n",
            "     | > loss_mel_ce: 2.490839719772339  (2.1821254379836823)\n",
            "     | > loss: 0.03000425547361374  (0.026349608668015664)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3643  (0.3701798545438692)\n",
            "     | > loader_time: 0.0104  (0.016864846486829788)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:20:40 -- STEP: 1466/12634 -- GLOBAL_STEP: 14100\u001b[0m\n",
            "     | > loss_text_ce: 0.02806471474468708  (0.031251078437236145)\n",
            "     | > loss_mel_ce: 2.2064101696014404  (2.1811011536059537)\n",
            "     | > loss: 0.02660089172422886  (0.02633752709313068)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3541  (0.3700329602008628)\n",
            "     | > loader_time: 0.0287  (0.016898031774679616)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:21:11 -- STEP: 1516/12634 -- GLOBAL_STEP: 14150\u001b[0m\n",
            "     | > loss_text_ce: 0.029466137290000916  (0.03123931591165563)\n",
            "     | > loss_mel_ce: 2.2795569896698  (2.1824746931605703)\n",
            "     | > loss: 0.02748837135732174  (0.026353738733903946)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3606  (0.3699574950188006)\n",
            "     | > loader_time: 0.0282  (0.016886223431942037)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:21:41 -- STEP: 1566/12634 -- GLOBAL_STEP: 14200\u001b[0m\n",
            "     | > loss_text_ce: 0.03050607070326805  (0.031222618489477386)\n",
            "     | > loss_mel_ce: 2.4039483070373535  (2.1843188551193897)\n",
            "     | > loss: 0.02898160181939602  (0.026375494256263562)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3622  (0.36989170122572906)\n",
            "     | > loader_time: 0.01  (0.01686164032606027)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:22:12 -- STEP: 1616/12634 -- GLOBAL_STEP: 14250\u001b[0m\n",
            "     | > loss_text_ce: 0.030640773475170135  (0.031209364120783872)\n",
            "     | > loss_mel_ce: 2.116417407989502  (2.183487895839284)\n",
            "     | > loss: 0.02556021697819233  (0.02636544409295599)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3631  (0.36976462632122614)\n",
            "     | > loader_time: 0.013  (0.01678940904612589)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:22:42 -- STEP: 1666/12634 -- GLOBAL_STEP: 14300\u001b[0m\n",
            "     | > loss_text_ce: 0.031322091817855835  (0.03119334002614624)\n",
            "     | > loss_mel_ce: 2.330601930618286  (2.183396424780658)\n",
            "     | > loss: 0.02811814285814762  (0.026364164385555524)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3556  (0.36970799524529363)\n",
            "     | > loader_time: 0.0326  (0.016843277437775642)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:23:13 -- STEP: 1716/12634 -- GLOBAL_STEP: 14350\u001b[0m\n",
            "     | > loss_text_ce: 0.030683398246765137  (0.031174918632337765)\n",
            "     | > loss_mel_ce: 2.253357410430908  (2.1830893309661015)\n",
            "     | > loss: 0.02719096466898918  (0.02636028919803165)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3621  (0.36973919276590955)\n",
            "     | > loader_time: 0.0315  (0.016898171051398857)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:23:44 -- STEP: 1766/12634 -- GLOBAL_STEP: 14400\u001b[0m\n",
            "     | > loss_text_ce: 0.029220934957265854  (0.031164095993338276)\n",
            "     | > loss_mel_ce: 2.2192788124084473  (2.182166419172346)\n",
            "     | > loss: 0.026767853647470474  (0.02634917331452345)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3613  (0.36978768978356513)\n",
            "     | > loader_time: 0.0131  (0.016885734360458357)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:24:15 -- STEP: 1816/12634 -- GLOBAL_STEP: 14450\u001b[0m\n",
            "     | > loss_text_ce: 0.029512671753764153  (0.031161359795430697)\n",
            "     | > loss_mel_ce: 2.1322641372680664  (2.1822351516606044)\n",
            "     | > loss: 0.025735437870025635  (0.02634995898318021)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4211  (0.3697325469113657)\n",
            "     | > loader_time: 0.0102  (0.01692356845355771)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:24:46 -- STEP: 1866/12634 -- GLOBAL_STEP: 14500\u001b[0m\n",
            "     | > loss_text_ce: 0.030808553099632263  (0.0311628753051864)\n",
            "     | > loss_mel_ce: 2.190397024154663  (2.1818322631962705)\n",
            "     | > loss: 0.02644292265176773  (0.026345180735862457)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3758  (0.3697831419886501)\n",
            "     | > loader_time: 0.0233  (0.01694991312609611)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:25:17 -- STEP: 1916/12634 -- GLOBAL_STEP: 14550\u001b[0m\n",
            "     | > loss_text_ce: 0.031955424696207047  (0.031152403924131954)\n",
            "     | > loss_mel_ce: 2.1995902061462402  (2.1822537576355887)\n",
            "     | > loss: 0.026566021144390106  (0.026350073864399637)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4173  (0.3698555466277615)\n",
            "     | > loader_time: 0.0294  (0.017018605249162048)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:25:48 -- STEP: 1966/12634 -- GLOBAL_STEP: 14600\u001b[0m\n",
            "     | > loss_text_ce: 0.03151513263583183  (0.03114795084049805)\n",
            "     | > loss_mel_ce: 2.009999990463257  (2.181489096956362)\n",
            "     | > loss: 0.024303751066327095  (0.02634091774951041)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3699  (0.3698680602158075)\n",
            "     | > loader_time: 0.0106  (0.016989705521359484)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:26:19 -- STEP: 2016/12634 -- GLOBAL_STEP: 14650\u001b[0m\n",
            "     | > loss_text_ce: 0.029383275657892227  (0.031142481073315787)\n",
            "     | > loss_mel_ce: 2.1537299156188965  (2.1805266019489107)\n",
            "     | > loss: 0.025989441201090813  (0.026329394352311887)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3614  (0.369883391119185)\n",
            "     | > loader_time: 0.025  (0.01699770502154793)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:26:50 -- STEP: 2066/12634 -- GLOBAL_STEP: 14700\u001b[0m\n",
            "     | > loss_text_ce: 0.028764503076672554  (0.031134626333171683)\n",
            "     | > loss_mel_ce: 2.3037214279174805  (2.180504600168546)\n",
            "     | > loss: 0.027767689898610115  (0.02632903891263055)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3578  (0.3698105641279194)\n",
            "     | > loader_time: 0.0119  (0.017078939388936197)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:27:20 -- STEP: 2116/12634 -- GLOBAL_STEP: 14750\u001b[0m\n",
            "     | > loss_text_ce: 0.030557287856936455  (0.031122838688348795)\n",
            "     | > loss_mel_ce: 2.030172348022461  (2.180617149137597)\n",
            "     | > loss: 0.0245324969291687  (0.026330238451128415)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3677  (0.36975709972850335)\n",
            "     | > loader_time: 0.0104  (0.017113629946861948)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:27:51 -- STEP: 2166/12634 -- GLOBAL_STEP: 14800\u001b[0m\n",
            "     | > loss_text_ce: 0.02872161753475666  (0.031120349487955345)\n",
            "     | > loss_mel_ce: 2.066591262817383  (2.180122896024508)\n",
            "     | > loss: 0.024944201111793518  (0.02632432485245243)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3632  (0.3699122857739282)\n",
            "     | > loader_time: 0.0108  (0.017032569245068137)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:28:22 -- STEP: 2216/12634 -- GLOBAL_STEP: 14850\u001b[0m\n",
            "     | > loss_text_ce: 0.03351287543773651  (0.031105753443698068)\n",
            "     | > loss_mel_ce: 1.978340744972229  (2.178303241191792)\n",
            "     | > loss: 0.023950640112161636  (0.02630248853334961)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3715  (0.36980922353396806)\n",
            "     | > loader_time: 0.0106  (0.0170079399747539)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:28:53 -- STEP: 2266/12634 -- GLOBAL_STEP: 14900\u001b[0m\n",
            "     | > loss_text_ce: 0.030446534976363182  (0.03109896101554012)\n",
            "     | > loss_mel_ce: 2.320561170578003  (2.178355295891694)\n",
            "     | > loss: 0.027988187968730927  (0.026303027366063596)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3668  (0.3698473533275166)\n",
            "     | > loader_time: 0.0198  (0.016991369090875716)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:29:23 -- STEP: 2316/12634 -- GLOBAL_STEP: 14950\u001b[0m\n",
            "     | > loss_text_ce: 0.028907984495162964  (0.03109963214353032)\n",
            "     | > loss_mel_ce: 2.1293485164642334  (2.17815725307185)\n",
            "     | > loss: 0.025693530216813087  (0.02630067770634752)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3593  (0.3698183034574022)\n",
            "     | > loader_time: 0.0103  (0.016950873513295894)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:29:54 -- STEP: 2366/12634 -- GLOBAL_STEP: 15000\u001b[0m\n",
            "     | > loss_text_ce: 0.03072160854935646  (0.031089081552544053)\n",
            "     | > loss_mel_ce: 2.0402650833129883  (2.178001802852375)\n",
            "     | > loss: 0.024654604494571686  (0.026298701504146187)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.361  (0.3698061126223687)\n",
            "     | > loader_time: 0.0116  (0.0169280386535374)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:30:26 -- STEP: 2416/12634 -- GLOBAL_STEP: 15050\u001b[0m\n",
            "     | > loss_text_ce: 0.030645055696368217  (0.031080333889147466)\n",
            "     | > loss_mel_ce: 2.0009140968322754  (2.1779589405320388)\n",
            "     | > loss: 0.02418522909283638  (0.026298087098734397)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3464  (0.37029563295130746)\n",
            "     | > loader_time: 0.0095  (0.016927217805622462)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:30:57 -- STEP: 2466/12634 -- GLOBAL_STEP: 15100\u001b[0m\n",
            "     | > loss_text_ce: 0.03125603497028351  (0.031068495696822913)\n",
            "     | > loss_mel_ce: 2.2515697479248047  (2.1778452840164673)\n",
            "     | > loss: 0.027176497504115105  (0.026296593109863303)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3606  (0.3702872344757231)\n",
            "     | > loader_time: 0.0106  (0.016874060626931083)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:31:28 -- STEP: 2516/12634 -- GLOBAL_STEP: 15150\u001b[0m\n",
            "     | > loss_text_ce: 0.03121512569487095  (0.03106619145747845)\n",
            "     | > loss_mel_ce: 2.377552032470703  (2.177258128723777)\n",
            "     | > loss: 0.028675800189375877  (0.026289575735465358)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3532  (0.3703228804758131)\n",
            "     | > loader_time: 0.0251  (0.016903533276010605)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:31:59 -- STEP: 2566/12634 -- GLOBAL_STEP: 15200\u001b[0m\n",
            "     | > loss_text_ce: 0.031019410118460655  (0.031057844611374005)\n",
            "     | > loss_mel_ce: 2.0048580169677734  (2.1770113600201704)\n",
            "     | > loss: 0.024236636236310005  (0.026286538643871333)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3741  (0.37037705706137747)\n",
            "     | > loader_time: 0.0098  (0.016894275939566796)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:32:31 -- STEP: 2616/12634 -- GLOBAL_STEP: 15250\u001b[0m\n",
            "     | > loss_text_ce: 0.030442029237747192  (0.031051710114845636)\n",
            "     | > loss_mel_ce: 2.1075854301452637  (2.1764362722361907)\n",
            "     | > loss: 0.025452708825469017  (0.026279619327441564)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3428  (0.37060850284515184)\n",
            "     | > loader_time: 0.0259  (0.016852705303682127)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:33:01 -- STEP: 2666/12634 -- GLOBAL_STEP: 15300\u001b[0m\n",
            "     | > loss_text_ce: 0.02921285852789879  (0.031044067792588812)\n",
            "     | > loss_mel_ce: 2.1281638145446777  (2.176781706942357)\n",
            "     | > loss: 0.025683056563138962  (0.026283640669489683)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3604  (0.37065193032467175)\n",
            "     | > loader_time: 0.0126  (0.016837302313115695)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:33:32 -- STEP: 2716/12634 -- GLOBAL_STEP: 15350\u001b[0m\n",
            "     | > loss_text_ce: 0.030516013503074646  (0.031032646630392742)\n",
            "     | > loss_mel_ce: 2.0114340782165527  (2.175678255280623)\n",
            "     | > loss: 0.024308929219841957  (0.026270368375811315)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3608  (0.37062979306317906)\n",
            "     | > loader_time: 0.0124  (0.016822797911507797)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:34:03 -- STEP: 2766/12634 -- GLOBAL_STEP: 15400\u001b[0m\n",
            "     | > loss_text_ce: 0.02921142429113388  (0.031026198202777765)\n",
            "     | > loss_mel_ce: 1.9805387258529663  (2.174923903211165)\n",
            "     | > loss: 0.023925596848130226  (0.026261311225776237)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3636  (0.3705967739709284)\n",
            "     | > loader_time: 0.0101  (0.016822481879443303)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:34:34 -- STEP: 2816/12634 -- GLOBAL_STEP: 15450\u001b[0m\n",
            "     | > loss_text_ce: 0.0323493517935276  (0.031019288844783464)\n",
            "     | > loss_mel_ce: 2.268418073654175  (2.174820934930308)\n",
            "     | > loss: 0.027390088886022568  (0.02626000315517143)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3562  (0.37057280675931376)\n",
            "     | > loader_time: 0.0322  (0.016834566962312624)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:35:04 -- STEP: 2866/12634 -- GLOBAL_STEP: 15500\u001b[0m\n",
            "     | > loss_text_ce: 0.029913894832134247  (0.031011682383934445)\n",
            "     | > loss_mel_ce: 2.2637016773223877  (2.1743858326005494)\n",
            "     | > loss: 0.02730494737625122  (0.026254732816220767)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.363  (0.37043883055136545)\n",
            "     | > loader_time: 0.0112  (0.01684900596269931)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:35:35 -- STEP: 2916/12634 -- GLOBAL_STEP: 15550\u001b[0m\n",
            "     | > loss_text_ce: 0.03228652849793434  (0.03100446333012583)\n",
            "     | > loss_mel_ce: 2.0854296684265137  (2.174342678734632)\n",
            "     | > loss: 0.0252109095454216  (0.026254133136102347)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.373  (0.37039490524469876)\n",
            "     | > loader_time: 0.0102  (0.01682380851567695)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:36:06 -- STEP: 2966/12634 -- GLOBAL_STEP: 15600\u001b[0m\n",
            "     | > loss_text_ce: 0.03195119649171829  (0.03099690071248716)\n",
            "     | > loss_mel_ce: 2.2216384410858154  (2.1743932639676355)\n",
            "     | > loss: 0.026828449219465256  (0.02625464530823724)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3637  (0.3704253651367514)\n",
            "     | > loader_time: 0.0112  (0.016795912547764268)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:36:37 -- STEP: 3016/12634 -- GLOBAL_STEP: 15650\u001b[0m\n",
            "     | > loss_text_ce: 0.028666328638792038  (0.03098646175321337)\n",
            "     | > loss_mel_ce: 2.3413169384002686  (2.1742076089986164)\n",
            "     | > loss: 0.02821408584713936  (0.026252310855230124)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3645  (0.37042125806568127)\n",
            "     | > loader_time: 0.0107  (0.016809650220036245)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:37:07 -- STEP: 3066/12634 -- GLOBAL_STEP: 15700\u001b[0m\n",
            "     | > loss_text_ce: 0.031833939254283905  (0.030979538119512852)\n",
            "     | > loss_mel_ce: 2.1143321990966797  (2.1742221146569296)\n",
            "     | > loss: 0.025549596175551414  (0.02625240111785507)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3634  (0.3704637341147841)\n",
            "     | > loader_time: 0.0108  (0.01675278084463185)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:37:38 -- STEP: 3116/12634 -- GLOBAL_STEP: 15750\u001b[0m\n",
            "     | > loss_text_ce: 0.028491074219346046  (0.030974225184745074)\n",
            "     | > loss_mel_ce: 2.0014233589172363  (2.17381332984938)\n",
            "     | > loss: 0.024165647104382515  (0.026247471385062754)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3695  (0.37040815595178733)\n",
            "     | > loader_time: 0.0106  (0.016788727052710666)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:38:09 -- STEP: 3166/12634 -- GLOBAL_STEP: 15800\u001b[0m\n",
            "     | > loss_text_ce: 0.03105883300304413  (0.03097056195290494)\n",
            "     | > loss_mel_ce: 2.0419304370880127  (2.1735923685985385)\n",
            "     | > loss: 0.024678444489836693  (0.02624479728201973)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4329  (0.37043672781237574)\n",
            "     | > loader_time: 0.0113  (0.01679417594504825)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:38:40 -- STEP: 3216/12634 -- GLOBAL_STEP: 15850\u001b[0m\n",
            "     | > loss_text_ce: 0.030241286382079124  (0.03096566661388439)\n",
            "     | > loss_mel_ce: 1.9799009561538696  (2.1730749111122187)\n",
            "     | > loss: 0.023930266499519348  (0.026238578796822246)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3732  (0.3704291181036486)\n",
            "     | > loader_time: 0.0109  (0.016773730071622944)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:39:11 -- STEP: 3266/12634 -- GLOBAL_STEP: 15900\u001b[0m\n",
            "     | > loss_text_ce: 0.03042084537446499  (0.030956868267636915)\n",
            "     | > loss_mel_ce: 2.2507052421569824  (2.1726093198066136)\n",
            "     | > loss: 0.02715626358985901  (0.026232931300409153)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3604  (0.3704108005641647)\n",
            "     | > loader_time: 0.0149  (0.016794635485960403)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:39:42 -- STEP: 3316/12634 -- GLOBAL_STEP: 15950\u001b[0m\n",
            "     | > loss_text_ce: 0.03190579265356064  (0.030955541481806525)\n",
            "     | > loss_mel_ce: 2.2451422214508057  (2.172002110859458)\n",
            "     | > loss: 0.027107715606689453  (0.026225686828809155)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3584  (0.37040997198608705)\n",
            "     | > loader_time: 0.0111  (0.016819837369447182)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:40:13 -- STEP: 3366/12634 -- GLOBAL_STEP: 16000\u001b[0m\n",
            "     | > loss_text_ce: 0.028397418558597565  (0.030947817698678843)\n",
            "     | > loss_mel_ce: 1.948390245437622  (2.171106000564248)\n",
            "     | > loss: 0.023533187806606293  (0.02621492689925859)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4281  (0.37044345652568333)\n",
            "     | > loader_time: 0.0106  (0.0167770675442719)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:40:44 -- STEP: 3416/12634 -- GLOBAL_STEP: 16050\u001b[0m\n",
            "     | > loss_text_ce: 0.026681043207645416  (0.030930952120471974)\n",
            "     | > loss_mel_ce: 2.5284247398376465  (2.170609399397148)\n",
            "     | > loss: 0.030417924746870995  (0.026208814196463055)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4421  (0.3705889279725119)\n",
            "     | > loader_time: 0.0272  (0.016802510835526988)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:41:15 -- STEP: 3466/12634 -- GLOBAL_STEP: 16100\u001b[0m\n",
            "     | > loss_text_ce: 0.030388377606868744  (0.030920610692732515)\n",
            "     | > loss_mel_ce: 2.0632355213165283  (2.170819833075046)\n",
            "     | > loss: 0.02492409385740757  (0.02621119624660475)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3652  (0.3705863514458312)\n",
            "     | > loader_time: 0.0101  (0.016790238406296353)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:41:46 -- STEP: 3516/12634 -- GLOBAL_STEP: 16150\u001b[0m\n",
            "     | > loss_text_ce: 0.027757594361901283  (0.03091380242004022)\n",
            "     | > loss_mel_ce: 1.890106201171875  (2.170244140056756)\n",
            "     | > loss: 0.022831713780760765  (0.02620426170682624)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3658  (0.37060170952099286)\n",
            "     | > loader_time: 0.0095  (0.016765162942081302)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:42:16 -- STEP: 3566/12634 -- GLOBAL_STEP: 16200\u001b[0m\n",
            "     | > loss_text_ce: 0.030106306076049805  (0.030900244037994167)\n",
            "     | > loss_mel_ce: 2.3141117095947266  (2.169411004425364)\n",
            "     | > loss: 0.02790735848248005  (0.026194182015637852)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3526  (0.3705396818700158)\n",
            "     | > loader_time: 0.031  (0.016754208290369665)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:42:47 -- STEP: 3616/12634 -- GLOBAL_STEP: 16250\u001b[0m\n",
            "     | > loss_text_ce: 0.03177419304847717  (0.030895260490262776)\n",
            "     | > loss_mel_ce: 2.1431925296783447  (2.1689939789671797)\n",
            "     | > loss: 0.025892462581396103  (0.026189158095739174)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3674  (0.37045374657727953)\n",
            "     | > loader_time: 0.0246  (0.01677191877259617)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:43:18 -- STEP: 3666/12634 -- GLOBAL_STEP: 16300\u001b[0m\n",
            "     | > loss_text_ce: 0.031150249764323235  (0.03088982300543256)\n",
            "     | > loss_mel_ce: 2.2225213050842285  (2.168918073762652)\n",
            "     | > loss: 0.026829425245523453  (0.026188189729812412)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3619  (0.37050282948666147)\n",
            "     | > loader_time: 0.0107  (0.016742381643741686)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:43:49 -- STEP: 3716/12634 -- GLOBAL_STEP: 16350\u001b[0m\n",
            "     | > loss_text_ce: 0.0307456161826849  (0.03088165677690914)\n",
            "     | > loss_mel_ce: 2.0389091968536377  (2.168041881755299)\n",
            "     | > loss: 0.024638747796416283  (0.0261776616538206)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3455  (0.37046590662361834)\n",
            "     | > loader_time: 0.0125  (0.016744860342680686)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:44:19 -- STEP: 3766/12634 -- GLOBAL_STEP: 16400\u001b[0m\n",
            "     | > loss_text_ce: 0.02902120351791382  (0.03088197404636435)\n",
            "     | > loss_mel_ce: 2.1831183433532715  (2.1678454527434554)\n",
            "     | > loss: 0.02633499540388584  (0.02617532699119122)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3676  (0.37046839585661295)\n",
            "     | > loader_time: 0.0142  (0.016761410571891944)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:44:50 -- STEP: 3816/12634 -- GLOBAL_STEP: 16450\u001b[0m\n",
            "     | > loss_text_ce: 0.030138496309518814  (0.030871310507082035)\n",
            "     | > loss_mel_ce: 1.986925721168518  (2.1679484773606874)\n",
            "     | > loss: 0.024012671783566475  (0.02617642652893543)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3629  (0.3704172244736731)\n",
            "     | > loader_time: 0.0109  (0.016758417995720754)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:45:21 -- STEP: 3866/12634 -- GLOBAL_STEP: 16500\u001b[0m\n",
            "     | > loss_text_ce: 0.034626465290784836  (0.030861752778407314)\n",
            "     | > loss_mel_ce: 2.135953664779663  (2.1677360232173624)\n",
            "     | > loss: 0.025840239599347115  (0.026173783530299505)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3696  (0.370345470205959)\n",
            "     | > loader_time: 0.0221  (0.01674920613446259)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:45:52 -- STEP: 3916/12634 -- GLOBAL_STEP: 16550\u001b[0m\n",
            "     | > loss_text_ce: 0.033517222851514816  (0.030859345365201497)\n",
            "     | > loss_mel_ce: 2.407092332839966  (2.1671472934281133)\n",
            "     | > loss: 0.029054874554276466  (0.02616674618403577)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3567  (0.37037269325129685)\n",
            "     | > loader_time: 0.0333  (0.016772091084286397)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:46:22 -- STEP: 3966/12634 -- GLOBAL_STEP: 16600\u001b[0m\n",
            "     | > loss_text_ce: 0.02937513217329979  (0.03085306514922454)\n",
            "     | > loss_mel_ce: 2.4284842014312744  (2.1669855467670804)\n",
            "     | > loss: 0.02926022931933403  (0.026164745865929793)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4159  (0.3703518652038264)\n",
            "     | > loader_time: 0.0171  (0.016778812406042606)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:46:53 -- STEP: 4016/12634 -- GLOBAL_STEP: 16650\u001b[0m\n",
            "     | > loss_text_ce: 0.030419711023569107  (0.030847695768361823)\n",
            "     | > loss_mel_ce: 2.007312774658203  (2.166460270870967)\n",
            "     | > loss: 0.024258721619844437  (0.02615842865817099)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3632  (0.37035510258608106)\n",
            "     | > loader_time: 0.0111  (0.01676744157337094)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:47:24 -- STEP: 4066/12634 -- GLOBAL_STEP: 16700\u001b[0m\n",
            "     | > loss_text_ce: 0.02904009073972702  (0.03084221336875151)\n",
            "     | > loss_mel_ce: 2.3729965686798096  (2.165830414252978)\n",
            "     | > loss: 0.02859567478299141  (0.026150865098246188)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3575  (0.3703058545834548)\n",
            "     | > loader_time: 0.0191  (0.016791925310678066)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:47:55 -- STEP: 4116/12634 -- GLOBAL_STEP: 16750\u001b[0m\n",
            "     | > loss_text_ce: 0.031757935881614685  (0.03083804986449599)\n",
            "     | > loss_mel_ce: 2.2763407230377197  (2.164936854436168)\n",
            "     | > loss: 0.027477364987134933  (0.02614017791613443)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.287  (0.3702705109200508)\n",
            "     | > loader_time: 0.0102  (0.016804447790392366)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:48:26 -- STEP: 4166/12634 -- GLOBAL_STEP: 16800\u001b[0m\n",
            "     | > loss_text_ce: 0.030439740046858788  (0.030828451206151998)\n",
            "     | > loss_mel_ce: 2.031700611114502  (2.1649437845182486)\n",
            "     | > loss: 0.024549292400479317  (0.02614014614704303)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3656  (0.3703480470197678)\n",
            "     | > loader_time: 0.0116  (0.016800531960998736)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:48:57 -- STEP: 4216/12634 -- GLOBAL_STEP: 16850\u001b[0m\n",
            "     | > loss_text_ce: 0.0334404855966568  (0.03082683409451093)\n",
            "     | > loss_mel_ce: 2.137036085128784  (2.1646519842817384)\n",
            "     | > loss: 0.025839008390903473  (0.026136653082961276)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3714  (0.3703175013499646)\n",
            "     | > loader_time: 0.0129  (0.01682917030079312)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:49:28 -- STEP: 4266/12634 -- GLOBAL_STEP: 16900\u001b[0m\n",
            "     | > loss_text_ce: 0.031013498082756996  (0.03082069304963398)\n",
            "     | > loss_mel_ce: 2.238248348236084  (2.1643164590441235)\n",
            "     | > loss: 0.027015022933483124  (0.026132585627515432)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3641  (0.3703686660072693)\n",
            "     | > loader_time: 0.0092  (0.016847074618654725)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:49:58 -- STEP: 4316/12634 -- GLOBAL_STEP: 16950\u001b[0m\n",
            "     | > loss_text_ce: 0.027958666905760765  (0.030816231636318383)\n",
            "     | > loss_mel_ce: 2.3192737102508545  (2.1639173760858275)\n",
            "     | > loss: 0.027943242341279984  (0.02612778153080593)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3587  (0.37029900166367447)\n",
            "     | > loader_time: 0.0107  (0.016845005435784488)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:50:29 -- STEP: 4366/12634 -- GLOBAL_STEP: 17000\u001b[0m\n",
            "     | > loss_text_ce: 0.0292766485363245  (0.0308118288320341)\n",
            "     | > loss_mel_ce: 1.930246114730835  (2.1633364181424644)\n",
            "     | > loss: 0.023327652364969254  (0.026120812952112316)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3657  (0.37028801271907774)\n",
            "     | > loader_time: 0.0231  (0.016857325184306996)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:51:00 -- STEP: 4416/12634 -- GLOBAL_STEP: 17050\u001b[0m\n",
            "     | > loss_text_ce: 0.029405010864138603  (0.030804392824327363)\n",
            "     | > loss_mel_ce: 1.9939115047454834  (2.162550259759463)\n",
            "     | > loss: 0.024087103083729744  (0.026111365399286286)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3555  (0.3702687160584371)\n",
            "     | > loader_time: 0.0293  (0.016882028592669417)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:51:31 -- STEP: 4466/12634 -- GLOBAL_STEP: 17100\u001b[0m\n",
            "     | > loss_text_ce: 0.032587382942438126  (0.030798375452220073)\n",
            "     | > loss_mel_ce: 2.2245142459869385  (2.162195371316254)\n",
            "     | > loss: 0.026870256289839745  (0.02610706889845908)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3585  (0.37027314319986404)\n",
            "     | > loader_time: 0.0106  (0.016878342713895402)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:52:02 -- STEP: 4516/12634 -- GLOBAL_STEP: 17150\u001b[0m\n",
            "     | > loss_text_ce: 0.028946682810783386  (0.030789091424609)\n",
            "     | > loss_mel_ce: 1.9141000509262085  (2.1619359074280924)\n",
            "     | > loss: 0.023131508380174637  (0.026103869518157893)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3685  (0.3702391365970307)\n",
            "     | > loader_time: 0.0135  (0.016871801301163825)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:52:33 -- STEP: 4566/12634 -- GLOBAL_STEP: 17200\u001b[0m\n",
            "     | > loss_text_ce: 0.030206341296434402  (0.03078220457293865)\n",
            "     | > loss_mel_ce: 1.9860974550247192  (2.161663500118093)\n",
            "     | > loss: 0.024003617465496063  (0.0261005445885661)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3577  (0.3703086740658357)\n",
            "     | > loader_time: 0.0302  (0.01689927963327014)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:53:04 -- STEP: 4616/12634 -- GLOBAL_STEP: 17250\u001b[0m\n",
            "     | > loss_text_ce: 0.029406310990452766  (0.030781931225274974)\n",
            "     | > loss_mel_ce: 1.7770591974258423  (2.1618814480521693)\n",
            "     | > loss: 0.02150554209947586  (0.026103135952532323)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3697  (0.3703330701517273)\n",
            "     | > loader_time: 0.0108  (0.01691531747631225)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:53:35 -- STEP: 4666/12634 -- GLOBAL_STEP: 17300\u001b[0m\n",
            "     | > loss_text_ce: 0.032328713685274124  (0.030772872780123528)\n",
            "     | > loss_mel_ce: 2.1929049491882324  (2.1613802859009597)\n",
            "     | > loss: 0.02649087645113468  (0.0260970618961434)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3616  (0.37028027163316274)\n",
            "     | > loader_time: 0.0108  (0.016915044302190266)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:54:06 -- STEP: 4716/12634 -- GLOBAL_STEP: 17350\u001b[0m\n",
            "     | > loss_text_ce: 0.03052402101457119  (0.030768582617518008)\n",
            "     | > loss_mel_ce: 2.2205307483673096  (2.161138273428014)\n",
            "     | > loss: 0.026798270642757416  (0.026094129721004493)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3665  (0.37026178007716315)\n",
            "     | > loader_time: 0.0213  (0.016925737754685886)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:54:36 -- STEP: 4766/12634 -- GLOBAL_STEP: 17400\u001b[0m\n",
            "     | > loss_text_ce: 0.03031018376350403  (0.03076359903595424)\n",
            "     | > loss_mel_ce: 2.1464157104492188  (2.1605876261978882)\n",
            "     | > loss: 0.025913404300808907  (0.02608751506668537)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3472  (0.3702486147662443)\n",
            "     | > loader_time: 0.013  (0.01692541261905891)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:55:07 -- STEP: 4816/12634 -- GLOBAL_STEP: 17450\u001b[0m\n",
            "     | > loss_text_ce: 0.029307981953024864  (0.030752254590435412)\n",
            "     | > loss_mel_ce: 2.181746482849121  (2.1606136309694617)\n",
            "     | > loss: 0.026322077959775925  (0.026087689595962187)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3637  (0.37019212162771864)\n",
            "     | > loader_time: 0.0281  (0.01695166533175499)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:55:38 -- STEP: 4866/12634 -- GLOBAL_STEP: 17500\u001b[0m\n",
            "     | > loss_text_ce: 0.033881306648254395  (0.030746228632735715)\n",
            "     | > loss_mel_ce: 2.442913055419922  (2.16047414797988)\n",
            "     | > loss: 0.02948564663529396  (0.02608595734850287)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4369  (0.3702895063654265)\n",
            "     | > loader_time: 0.0106  (0.016930560344440498)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:56:09 -- STEP: 4916/12634 -- GLOBAL_STEP: 17550\u001b[0m\n",
            "     | > loss_text_ce: 0.02866121008992195  (0.030737538702643487)\n",
            "     | > loss_mel_ce: 2.1916379928588867  (2.1597659299779077)\n",
            "     | > loss: 0.026432134211063385  (0.026077422731312735)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3529  (0.37029229576166683)\n",
            "     | > loader_time: 0.0132  (0.016924248079248718)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:56:40 -- STEP: 4966/12634 -- GLOBAL_STEP: 17600\u001b[0m\n",
            "     | > loss_text_ce: 0.03003087267279625  (0.03073038688950476)\n",
            "     | > loss_mel_ce: 1.8627914190292358  (2.159664293306276)\n",
            "     | > loss: 0.0225335992872715  (0.026076127628732404)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3595  (0.37026692579409964)\n",
            "     | > loader_time: 0.0269  (0.01693765871283802)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:57:11 -- STEP: 5016/12634 -- GLOBAL_STEP: 17650\u001b[0m\n",
            "     | > loss_text_ce: 0.03278381749987602  (0.03073193336669146)\n",
            "     | > loss_mel_ce: 2.24865460395813  (2.1595553926161037)\n",
            "     | > loss: 0.027159981429576874  (0.026074849604220494)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3589  (0.3702574500151607)\n",
            "     | > loader_time: 0.0105  (0.016951284292592222)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:57:41 -- STEP: 5066/12634 -- GLOBAL_STEP: 17700\u001b[0m\n",
            "     | > loss_text_ce: 0.030734557658433914  (0.030728716381553042)\n",
            "     | > loss_mel_ce: 2.229487180709839  (2.1588512665190995)\n",
            "     | > loss: 0.02690740115940571  (0.026066428853034892)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3538  (0.3702254461479712)\n",
            "     | > loader_time: 0.027  (0.016935395008483255)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:58:12 -- STEP: 5116/12634 -- GLOBAL_STEP: 17750\u001b[0m\n",
            "     | > loss_text_ce: 0.03213630989193916  (0.03072344020017777)\n",
            "     | > loss_mel_ce: 1.9798842668533325  (2.1587039789620364)\n",
            "     | > loss: 0.023952625691890717  (0.02606461261726035)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3658  (0.3702357970148998)\n",
            "     | > loader_time: 0.0214  (0.016953080403236256)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:58:43 -- STEP: 5166/12634 -- GLOBAL_STEP: 17800\u001b[0m\n",
            "     | > loss_text_ce: 0.02815469726920128  (0.030717755511743435)\n",
            "     | > loss_mel_ce: 2.208834648132324  (2.1579298156663707)\n",
            "     | > loss: 0.026630824431777  (0.026055328714172012)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3604  (0.3701873886645229)\n",
            "     | > loader_time: 0.0108  (0.01696600828159702)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:59:14 -- STEP: 5216/12634 -- GLOBAL_STEP: 17850\u001b[0m\n",
            "     | > loss_text_ce: 0.030936842784285545  (0.030716553591820253)\n",
            "     | > loss_mel_ce: 1.8942824602127075  (2.1578545307317767)\n",
            "     | > loss: 0.02291927859187126  (0.026054418156569115)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3669  (0.3701466659735314)\n",
            "     | > loader_time: 0.01  (0.01695567136344737)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 09:59:44 -- STEP: 5266/12634 -- GLOBAL_STEP: 17900\u001b[0m\n",
            "     | > loss_text_ce: 0.02908019907772541  (0.030712305369372705)\n",
            "     | > loss_mel_ce: 2.2260732650756836  (2.1575781886585763)\n",
            "     | > loss: 0.02684706449508667  (0.026051077796121504)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3729  (0.37014720189086897)\n",
            "     | > loader_time: 0.0119  (0.016951713913346392)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 10:00:15 -- STEP: 5316/12634 -- GLOBAL_STEP: 17950\u001b[0m\n",
            "     | > loss_text_ce: 0.030583593994379044  (0.030710307725314863)\n",
            "     | > loss_mel_ce: 1.9180703163146973  (2.1576295599307773)\n",
            "     | > loss: 0.023198261857032776  (0.026051665575329716)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.366  (0.3701496409957259)\n",
            "     | > loader_time: 0.0157  (0.016966193667742647)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 10:00:46 -- STEP: 5366/12634 -- GLOBAL_STEP: 18000\u001b[0m\n",
            "     | > loss_text_ce: 0.029533781111240387  (0.03070694799672087)\n",
            "     | > loss_mel_ce: 2.1037797927856445  (2.157050413957428)\n",
            "     | > loss: 0.025396591052412987  (0.02604473098255818)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3547  (0.3701335946170864)\n",
            "     | > loader_time: 0.0107  (0.01695448446753666)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 10:01:16 -- STEP: 5416/12634 -- GLOBAL_STEP: 18050\u001b[0m\n",
            "     | > loss_text_ce: 0.03242536634206772  (0.030702573962253742)\n",
            "     | > loss_mel_ce: 1.8955566883087158  (2.1569906343957728)\n",
            "     | > loss: 0.022952167317271233  (0.026043967248946198)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3451  (0.370069390209598)\n",
            "     | > loader_time: 0.0326  (0.016956145865526323)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 10:01:47 -- STEP: 5466/12634 -- GLOBAL_STEP: 18100\u001b[0m\n",
            "     | > loss_text_ce: 0.029868999496102333  (0.030696164295922417)\n",
            "     | > loss_mel_ce: 1.876161813735962  (2.1568322231644865)\n",
            "     | > loss: 0.022690843790769577  (0.02604200509320596)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3542  (0.3700394423244379)\n",
            "     | > loader_time: 0.0241  (0.016954546091628983)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 10:02:18 -- STEP: 5516/12634 -- GLOBAL_STEP: 18150\u001b[0m\n",
            "     | > loss_text_ce: 0.030448181554675102  (0.030693806029459078)\n",
            "     | > loss_mel_ce: 2.0209271907806396  (2.15637799148719)\n",
            "     | > loss: 0.02442113682627678  (0.02603656950084582)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.4286  (0.3700908780357301)\n",
            "     | > loader_time: 0.0109  (0.016967392512384428)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 10:02:49 -- STEP: 5566/12634 -- GLOBAL_STEP: 18200\u001b[0m\n",
            "     | > loss_text_ce: 0.031704116612672806  (0.030690090069523855)\n",
            "     | > loss_mel_ce: 2.009207010269165  (2.1561377788678064)\n",
            "     | > loss: 0.024296563118696213  (0.02603366558931625)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3629  (0.3700837354800533)\n",
            "     | > loader_time: 0.0096  (0.016964937729926355)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 10:03:20 -- STEP: 5616/12634 -- GLOBAL_STEP: 18250\u001b[0m\n",
            "     | > loss_text_ce: 0.028974510729312897  (0.030682363139433597)\n",
            "     | > loss_mel_ce: 2.1140966415405273  (2.1560205590521186)\n",
            "     | > loss: 0.025512753054499626  (0.026032178128732524)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3603  (0.37007108424124224)\n",
            "     | > loader_time: 0.0112  (0.01695747953704283)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2025-01-05 10:03:51 -- STEP: 5666/12634 -- GLOBAL_STEP: 18300\u001b[0m\n",
            "     | > loss_text_ce: 0.02988016977906227  (0.030679576411880103)\n",
            "     | > loss_mel_ce: 1.952086329460144  (2.1557754142058023)\n",
            "     | > loss: 0.023594839498400688  (0.026029226562469147)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.3621  (0.37007874563899185)\n",
            "     | > loader_time: 0.01  (0.016961633506866497)\n",
            "\n",
            " > Keyboard interrupt detected.\n",
            " > Saving model before exiting...\n",
            "\n",
            " > CHECKPOINT : /content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000/checkpoint_18347.pth\n",
            " ! Run is kept in /content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # init args and config\n",
        "    model_args = GPTArgs(\n",
        "        max_conditioning_length=132300,  # 6 secs\n",
        "        min_conditioning_length=66150,  # 3 secs\n",
        "        debug_loading_failures=False,\n",
        "        max_wav_length=255995,  # ~11.6 seconds\n",
        "        max_text_length=200,\n",
        "        mel_norm_file=MEL_NORM_FILE,\n",
        "        dvae_checkpoint=DVAE_CHECKPOINT,\n",
        "        xtts_checkpoint=XTTS_CHECKPOINT,  # checkpoint path of the model that you want to fine-tune\n",
        "        tokenizer_file=TOKENIZER_FILE,\n",
        "        gpt_num_audio_tokens=1026,\n",
        "        gpt_start_audio_token=1024,\n",
        "        gpt_stop_audio_token=1025,\n",
        "        gpt_use_masking_gt_prompt_approach=True,\n",
        "        gpt_use_perceiver_resampler=True,\n",
        "    )\n",
        "    # define audio config\n",
        "    audio_config = XttsAudioConfig(sample_rate=44100, dvae_sample_rate=22050, output_sample_rate=24000)\n",
        "    # training parameters config\n",
        "    config = GPTTrainerConfig(\n",
        "        output_path=OUT_PATH,\n",
        "        model_args=model_args,\n",
        "        run_name=RUN_NAME,\n",
        "        project_name=PROJECT_NAME,\n",
        "        run_description=\"\"\"\n",
        "            GPT XTTS training\n",
        "            \"\"\",\n",
        "        dashboard_logger=DASHBOARD_LOGGER,\n",
        "        logger_uri=LOGGER_URI,\n",
        "        audio=audio_config,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        batch_group_size=48,\n",
        "        eval_batch_size=BATCH_SIZE,\n",
        "        num_loader_workers=8,\n",
        "        eval_split_max_size=256,\n",
        "        print_step=50,\n",
        "        plot_step=100,\n",
        "        log_model_step=1000,\n",
        "        save_step=10000,\n",
        "        save_n_checkpoints=1,\n",
        "        save_checkpoints=True,\n",
        "        # target_loss=\"loss\",\n",
        "        print_eval=False,\n",
        "        # Optimizer values like tortoise, pytorch implementation with modifications to not apply WD to non-weight parameters.\n",
        "        optimizer=\"AdamW\",\n",
        "        optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n",
        "        optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
        "        lr=5e-06,  # learning rate\n",
        "        lr_scheduler=\"MultiStepLR\",\n",
        "        # it was adjusted accordly for the new step scheme\n",
        "        lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n",
        "        test_sentences=[\n",
        "            {\n",
        "                \"text\": \"صباح الخير انا بتكلم مصرى عادى\",\n",
        "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
        "                \"language\": LANGUAGE,\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"اهلا انا محمود و دا المشروع\",\n",
        "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
        "                \"language\": LANGUAGE,\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # init the model from config\n",
        "    model = GPTTrainer.init_from_config(config)\n",
        "\n",
        "    # load training samples\n",
        "    train_samples, eval_samples = load_tts_samples(\n",
        "        DATASETS_CONFIG_LIST,\n",
        "        eval_split=True,\n",
        "        eval_split_max_size=config.eval_split_max_size,\n",
        "        eval_split_size=config.eval_split_size,\n",
        "    )\n",
        "\n",
        "    # init the trainer and 🚀\n",
        "    trainer = Trainer(\n",
        "        TrainerArgs(\n",
        "            restore_path=None,  # xtts checkpoint is restored via xtts_checkpoint key so no need of restore it using Trainer restore_path parameter\n",
        "            skip_train_epoch=False,\n",
        "            start_with_eval=START_WITH_EVAL,\n",
        "            grad_accum_steps=GRAD_ACUMM_STEPS,\n",
        "        ),\n",
        "        config,\n",
        "        output_path=OUT_PATH,\n",
        "        model=model,\n",
        "        train_samples=train_samples,\n",
        "        eval_samples=eval_samples,\n",
        "    )\n",
        "    trainer.fit()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading Training weights to drive"
      ],
      "metadata": {
        "id": "DQR2n4IOHjCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save this file in google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "!mkdir -p /content/drive/MyDrive/weights/\n",
        "#!cp -r /content/txt_to_speech_dataset /content/drive/MyDrive/txt_to_speech_dataset_files\n",
        "!cp /content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000/best_model.pth /content/drive/MyDrive/weights/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsOlrinV7cwO",
        "outputId": "0137732f-2276-4115-b51d-a30c1ff5014a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Inference"
      ],
      "metadata": {
        "id": "y9eCNtxyHuC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Finetuned_model\n",
        "!gdown --id 1-131EwOwmJtgC5tg0B9CiGOpN0f1yOGz #checkpoint.pth\n",
        "!gdown --id 1I38OqwNPx7ikwi-MoRhPjklUBJS-Q20d #config.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBu6btv5JBcf",
        "outputId": "e9f12a39-1154-4984-cb9e-b0c6c79c23e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Finetuned_model\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-131EwOwmJtgC5tg0B9CiGOpN0f1yOGz\n",
            "From (redirected): https://drive.google.com/uc?id=1-131EwOwmJtgC5tg0B9CiGOpN0f1yOGz&confirm=t&uuid=54e16da6-fab4-425d-96f2-9fcf1bb4a636\n",
            "To: /content/Finetuned_model/checkpoint_18347.pth\n",
            "100% 5.61G/5.61G [01:21<00:00, 69.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Model"
      ],
      "metadata": {
        "id": "jL8lCk_5I3N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "\n",
        "# Add here the xtts_config path\n",
        "CONFIG_PATH = \"/content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000/config.json\"\n",
        "# Add here the vocab file that you have used to train the model\n",
        "TOKENIZER_PATH = \"/content/run/training/XTTS_v2.0_original_model_files/vocab.json\"\n",
        "# Add here the checkpoint that you want to do inference with\n",
        "XTTS_CHECKPOINT = \"/content/run/training/XTTS_v2.0_original_model_files/model.pth\"\n",
        "# Add here the speaker reference\n",
        "SPEAKER_REFERENCE = \"/content/lJspeech/wavs/audio_10302.wav\"\n",
        "\n",
        "# output wav path\n",
        "OUTPUT_WAV_PATH = \"Original.wav\"\n",
        "\n",
        "print(\"Loading model...\")\n",
        "config = XttsConfig()\n",
        "config.load_json(CONFIG_PATH)\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(config, checkpoint_path=XTTS_CHECKPOINT, vocab_path=TOKENIZER_PATH, use_deepspeed=False)\n",
        "model.cuda()\n",
        "\n",
        "print(\"Computing speaker latents...\")\n",
        "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=[SPEAKER_REFERENCE])\n",
        "\n"
      ],
      "metadata": {
        "id": "ayx5E1GcZ3Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26822eb7-f535-467b-e3da-4498396f88d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing speaker latents...\n",
            "Inference...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuned Model"
      ],
      "metadata": {
        "id": "-esr6AdWI51n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "\n",
        "# Add here the xtts_config path\n",
        "CONFIG_PATH = \"/content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000/config.json\"\n",
        "# Add here the vocab file that you have used to train the model\n",
        "TOKENIZER_PATH = \"/content/run/training/XTTS_v2.0_original_model_files/vocab.json\"\n",
        "# Add here the checkpoint that you want to do inference with\n",
        "XTTS_CHECKPOINT = \"/content/run/training/GPT_XTTS_v2.0_LJSpeech_FT-January-05-2025_06+50AM-0000000/checkpoint_18347.pth\"\n",
        "# Add here the speaker reference\n",
        "SPEAKER_REFERENCE = \"/content/lJspeech/wavs/audio_10302.wav\"\n",
        "\n",
        "# output wav path\n",
        "OUTPUT_WAV_PATH1 = \"Finetuned.wav\"\n",
        "\n",
        "print(\"Loading model...\")\n",
        "config = XttsConfig()\n",
        "config.load_json(CONFIG_PATH)\n",
        "model1 = Xtts.init_from_config(config)\n",
        "model1.load_checkpoint(config, checkpoint_path=XTTS_CHECKPOINT, vocab_path=TOKENIZER_PATH, use_deepspeed=False)\n",
        "model1.cuda()\n",
        "\n",
        "print(\"Computing speaker latents...\")\n",
        "gpt_cond_latent, speaker_embedding = model1.get_conditioning_latents(audio_path=[SPEAKER_REFERENCE])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5DOniC3FDPT",
        "outputId": "6a922d40-6d36-4c06-d43c-f6ca86f8702c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/TTS/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing speaker latents...\n",
            "Inference...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_WAV_PATH1 = \"Finetuned.wav\"\n"
      ],
      "metadata": {
        "id": "aiFB7lCdFEaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_WAV_PATH = \"Original.wav\""
      ],
      "metadata": {
        "id": "SOSnW1NYGFjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing FineTuned VS Original Model"
      ],
      "metadata": {
        "id": "lb4WAHroH3rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence =  \"الصبح وأنا نازل من البيت لقيت الجو برد جدًا، فاضطريت أرجع أخد جاكيت، ولما وصلت للمحطة اكتشفت إن الميكروباصات كلها زحمة والناس واقفة مستنية\"\n",
        "#Test\n",
        "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=[SPEAKER_REFERENCE])\n",
        "out = model.inference(\n",
        "   sentence,\n",
        "    \"ar\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=0.7, # Add custom parameters here\n",
        ")\n",
        "torchaudio.save(OUTPUT_WAV_PATH, torch.tensor(out[\"wav\"]).unsqueeze(0), 24000)\n",
        "\n",
        "out1 = model1.inference(\n",
        "    sentence,\n",
        "    \"ar\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=0.7, # Add custom parameters here\n",
        ")\n",
        "torchaudio.save(OUTPUT_WAV_PATH1, torch.tensor(out1[\"wav\"]).unsqueeze(0), 24000)\n",
        "\n"
      ],
      "metadata": {
        "id": "ty6JpxbAd-da"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
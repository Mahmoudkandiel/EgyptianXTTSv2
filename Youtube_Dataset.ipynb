{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOiUnXKnwYqT"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3dzFkCwvV95"
      },
      "outputs": [],
      "source": [
        "!pip install arabic-reshaper\n",
        "!pip install python-bidi\n",
        "!pip install yt-dlp\n",
        "!pip install pydub\n",
        "!pip install english_to_arabic_transphonator\n",
        "!pip install num2words\n",
        "!pip install pytube\n",
        "!pip install youtube_dl\n",
        "!pip install ffmpeg\n",
        "!pip install langdetect\n",
        "!sudo apt-get install parallel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-AtXSqjwcJL"
      },
      "source": [
        "# Auto-genrated Sub import and proccess using playlist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dieWK8693wUa"
      },
      "source": [
        "Importing subtitles in a playlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIUSF3u1Tu44"
      },
      "outputs": [],
      "source": [
        "# Playlist URL\n",
        "playlist_url=\"https://youtube.com/playlist?list=PLAaDo_d_X-35PX49IAmRJoj_Vva-MlYOd&si=2CSSBl7takDvMVB2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "69YeaBuAwjkU"
      },
      "outputs": [],
      "source": [
        "# Download all videos in the playlist and their Arabic subtitles\n",
        "!yt-dlp --write-auto-sub --sub-lang ar --skip-download \"$playlist_url\" -o \"/content/auto_generated_subtitles/%(title)s.%(ext)s\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FICYLZaI3sVk"
      },
      "source": [
        "Getting Audio files | may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGA2oXG_7Qf1"
      },
      "outputs": [],
      "source": [
        "!yt-dlp -f bestaudio[ext=m4a] \"$playlist_url\" -o \"audio/%(title)s.%(ext)s\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fhHLgEa32vj"
      },
      "source": [
        "Cleaning the auto-genrated subtitles whole folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoEBMVDszwFn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def clean_webvtt(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
        "        lines = infile.readlines()\n",
        "\n",
        "    clean_lines = []\n",
        "    prev_text = \"\"  # Track the previous text to avoid duplicates\n",
        "\n",
        "    for line in lines:\n",
        "        # If the line is a timestamp, add it to the clean output\n",
        "        if '-->' in line:\n",
        "            clean_lines.append(line)\n",
        "        # Remove <c> tags and their contents from caption lines\n",
        "        elif re.search(r'<[^>]+>', line):\n",
        "            clean_line = re.sub(r'<[^>]+>', '', line)  # Remove any markup like <c> tags\n",
        "            # Add the line if it's not the same as the previous caption text\n",
        "            if clean_line.strip() != prev_text:\n",
        "                clean_lines.append(clean_line)\n",
        "                prev_text = clean_line.strip()\n",
        "        # Keep the normal text lines (Arabic captions)\n",
        "        elif line.strip():\n",
        "            if line.strip() != prev_text:\n",
        "                clean_lines.append(line)\n",
        "                prev_text = line.strip()\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.writelines(clean_lines)\n",
        "\n",
        "def read_vtt_file(file_path):\n",
        "    \"\"\"Read the content of a .vtt file.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def clean_vtt_timestamps(input_text):\n",
        "    # Split into lines\n",
        "    lines = input_text.strip().split('\\n')\n",
        "\n",
        "    # Initialize output list with header\n",
        "    output_lines = []\n",
        "    i = 0\n",
        "\n",
        "    # Add header lines\n",
        "    while i < len(lines) and '-->' not in lines[i]:\n",
        "        output_lines.append(lines[i])\n",
        "        i += 1\n",
        "\n",
        "    # Process the rest of the content\n",
        "    while i < len(lines):\n",
        "        current_line = lines[i]\n",
        "        current_line = current_line.replace(\" align:start position:100%\", \"\")\n",
        "        # If this is a timestamp line\n",
        "        if '-->' in current_line:\n",
        "            next_line = lines[i + 1] if i + 1 < len(lines) else \"\"\n",
        "\n",
        "            # Only keep timestamp if next line has text (not another timestamp)\n",
        "            if i + 1 < len(lines) and '-->' not in next_line and next_line.strip():\n",
        "                output_lines.append(current_line)\n",
        "                output_lines.append(next_line)\n",
        "                output_lines.append(\"\")  # Add a blank line between blocks\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return '\\n'.join(output_lines)\n",
        "\n",
        "\n",
        "def save_as_vtt(file_name, content):\n",
        "    \"\"\"Save the cleaned content to a .vtt file.\"\"\"\n",
        "    with open(file_name, 'w', encoding='utf-8') as file:\n",
        "        file.write(content)\n",
        "    print(f\"File saved as {file_name}\")\n",
        "\n",
        "def process_vtt_file(input_file_path, output_file_path):\n",
        "    \"\"\"Read, clean, and save a .vtt file.\"\"\"\n",
        "    # Read the unclean file\n",
        "    clean_webvtt(input_file_path,output_file_path)\n",
        "\n",
        "    unclean_text = read_vtt_file(output_file_path)\n",
        "    # Clean the content\n",
        "    cleaned_content = clean_vtt_timestamps(unclean_text)\n",
        "\n",
        "    # Save the cleaned content to a new file\n",
        "    save_as_vtt(output_file_path, cleaned_content)\n",
        "\n",
        "def process_all_subtitles(input_folder, output_folder):\n",
        "    \"\"\"Process all .vtt files in the input folder and save them to the output folder.\"\"\"\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # List all files in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".vtt\"):\n",
        "            input_file_path = os.path.join(input_folder, filename)\n",
        "            output_file_path = os.path.join(output_folder, filename)\n",
        "\n",
        "            # Clean and save the file\n",
        "            process_vtt_file(input_file_path, output_file_path)\n",
        "# Example usage\n",
        "input_folder = '/content/auto_generated_subtitles'  # Replace with the folder containing your .vtt files\n",
        "output_folder = '/content/cleaned_subtitles'  # Replace with the folder where you want to save cleaned files\n",
        "\n",
        "process_all_subtitles(input_folder, output_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxEPrbHm3--h"
      },
      "source": [
        "# Converting the subtitles and audio into JLspeech dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1uTp4T14HIv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "from pydub import AudioSegment\n",
        "from datetime import timedelta\n",
        "from num2words import num2words\n",
        "from english_to_arabic_transphonator.transphonator import Transphonator\n",
        "from langdetect import detect\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "# Reusing the Transphonator object\n",
        "trans = Transphonator()\n",
        "\n",
        "# Function to remove diacritics (التشكيل) from Arabic text\n",
        "def remove_diacritics(text):\n",
        "    if isinstance(text, str):\n",
        "        return re.sub(r'[\\u064B-\\u0652\\u0670\\u0640]', '', text)\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "# Function to convert timestamp to milliseconds\n",
        "def timestamp_to_ms(timestamp):\n",
        "    time_obj = timedelta(hours=int(timestamp.split(\":\")[0]),\n",
        "                         minutes=int(timestamp.split(\":\")[1]),\n",
        "                         seconds=float(timestamp.split(\":\")[2].replace(\",\", \".\")))\n",
        "    return int(time_obj.total_seconds() * 1000)\n",
        "\n",
        "# Function to convert numbers to Arabic words\n",
        "def convert_numbers_to_arabic_words(text):\n",
        "    text_with_arabic_words = re.sub(r'\\d+', lambda x: num2words(x.group(), lang='ar'), text)\n",
        "    return text_with_arabic_words\n",
        "\n",
        "# Function to transliterate only English words to Arabic and keep Arabic words unchanged\n",
        "def transliterate_english_to_arabic(text):\n",
        "    words = text.split()\n",
        "    transliterated_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if re.match(r'^[a-zA-Z]+$', word):  # If it's an English word\n",
        "            transliterated_word = trans.transphonate_english_word(word)\n",
        "            transliterated_word = remove_diacritics(transliterated_word)\n",
        "            transliterated_words.append(transliterated_word or word)\n",
        "        else:\n",
        "            match = re.match(r'^(.*?)([a-zA-Z]+)(.*?)$', word)\n",
        "            if match:\n",
        "                arabic_part, english_part, punctuation = match.groups()\n",
        "                transliterated_word = trans.transphonate_english_word(english_part)\n",
        "                transliterated_word = remove_diacritics(transliterated_word)\n",
        "                transliterated_words.append(arabic_part + (transliterated_word or english_part) + punctuation)\n",
        "            else:\n",
        "                transliterated_words.append(word)\n",
        "\n",
        "    return ' '.join(transliterated_words)\n",
        "\n",
        "# Function to normalize Arabic text\n",
        "def normalize_arabic_text(text):\n",
        "    text = \" \".join(text.split())\n",
        "    text = remove_diacritics(text)\n",
        "    text = convert_numbers_to_arabic_words(text)\n",
        "    text = transliterate_english_to_arabic(text)\n",
        "    return text\n",
        "\n",
        "# Function to parse .vtt file and return start and end timestamps with text\n",
        "def parse_vtt_subtitles(vtt_file):\n",
        "    with open(vtt_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        subtitles = f.read()\n",
        "\n",
        "    pattern = re.compile(r\"(\\d{2}:\\d{2}:\\d{2}[\\.,]\\d{3}) --> (\\d{2}:\\d{2}:\\d{2}[\\.,]\\d{3})\\n(.*?)\\n\", re.DOTALL)\n",
        "    segments = []\n",
        "\n",
        "    for match in pattern.finditer(subtitles):\n",
        "        start_time = match.group(1)\n",
        "        end_time = match.group(2)\n",
        "        text = match.group(3).strip().replace(\"\\n\", \" \")\n",
        "        normalized_text = normalize_arabic_text(text)\n",
        "        segments.append({\n",
        "            \"start\": timestamp_to_ms(start_time),\n",
        "            \"end\": timestamp_to_ms(end_time),\n",
        "            \"text\": text,\n",
        "            \"normalized_text\": normalized_text\n",
        "        })\n",
        "\n",
        "    return segments\n",
        "\n",
        "audio_count = 1\n",
        "# Function to process a single file (audio and subtitle pair)\n",
        "def process_single_file(audio_file, vtt_file, output_dir):\n",
        "    global audio_count\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "    segments = parse_vtt_subtitles(vtt_file)\n",
        "    with open(f\"{output_dir}/metadata.csv\", \"a\", encoding=\"utf-8-sig\", newline=\"\") as metadata_file:\n",
        "        csv_writer = csv.writer(metadata_file, delimiter='|')  # Set delimiter to '|'\n",
        "        for segment in segments:\n",
        "            start_time = segment[\"start\"]\n",
        "            end_time = segment[\"end\"]\n",
        "            original_start_time = segment[\"start\"]\n",
        "\n",
        "            original_end_time = segment[\"end\"]\n",
        "\n",
        "            text = segment[\"text\"]\n",
        "            normalized_text = segment[\"normalized_text\"]\n",
        "\n",
        "            start_time = max(0, original_start_time - 100)  # Subtract 0.3 seconds, ensure >= 0\n",
        "            end_time = min(len(audio), original_end_time + 200)\n",
        "\n",
        "            # Uncomment conditions if required\n",
        "            if re.search(r'\\[.*?\\]', text) or (end_time - start_time) > 12000:\n",
        "                 continue\n",
        "\n",
        "            audio_segment = audio[start_time:end_time]\n",
        "            audio_filename = f\"audio_{audio_count}\"  # Updated naming format\n",
        "            audio_count += 1  # Increment audio number for this video\n",
        "\n",
        "            try:\n",
        "              audio_segment.export(f\"{output_dir}/wavs/{audio_filename}.wav\", format=\"wav\")\n",
        "              csv_writer.writerow([audio_filename, text, normalized_text])\n",
        "            except Exception as e:\n",
        "              print(f\"Error exporting {audio_filename}: {e}\")\n",
        "\n",
        "# Main function to process multiple files in parallel\n",
        "def process_files(audio_files, vtt_files, output_dir):\n",
        "    print(audio_files,vtt_files)\n",
        "    os.makedirs(f\"{output_dir}/wavs\", exist_ok=True)\n",
        "\n",
        "    with open(f\"{output_dir}/metadata.csv\", \"w\", encoding=\"utf-8-sig\", newline=\"\") as metadata_file:\n",
        "        csv_writer = csv.writer(metadata_file)\n",
        "        csv_writer.writerow([\"Filename|Original Text|Normalized Text\"])\n",
        "\n",
        "    #with ProcessPoolExecutor() as executor:\n",
        "        for audio_file, vtt_file in zip(audio_files, vtt_files):\n",
        "            #executor.submit(process_single_file, audio_file, vtt_file, output_dir)\n",
        "            process_single_file(audio_file, vtt_file, output_dir)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Get list of all .vtt and .mp3 files\n",
        "    audio_dir = \"/content/audio/\"\n",
        "    vtt_dir = \"/content/cleaned_subtitles/\"\n",
        "\n",
        "    # List all audio and subtitle files\n",
        "    audio_files = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir)] #if f.endswith(\".m4a\")]\n",
        "    vtt_files = [os.path.join(vtt_dir, f) for f in os.listdir(vtt_dir)]# if f.endswith(\".ar.vtt\")]\n",
        "    # Ensure matching files (same name for audio and subtitle)\n",
        "    #audio_files = [f for f in audio_files if os.path.basename(f).replace(\".m4a\", \".ar.vtt\") in os.listdir(vtt_dir)]\n",
        "    # Ensure matching files (same name for audio and subtitle)\n",
        "    #audio_files = [f for f in audio_files if os.path.basename(f).replace(\".m4a\", \".ar.vtt\") in os.listdir(vtt_dir)]\n",
        "    def match_files(audio_files, vtt_files):\n",
        "    # Extract base names from the files (without paths and extensions)\n",
        "      audio_base_names = [os.path.splitext(os.path.basename(file))[0] for file in audio_files]\n",
        "      vtt_base_names = [os.path.splitext(os.path.basename(file))[0] for file in vtt_files]\n",
        "\n",
        "    # Sort the files based on the base names to align them\n",
        "      sorted_audio_files = [audio_files[audio_base_names.index(name)] for name in sorted(audio_base_names)]\n",
        "      sorted_vtt_files = [vtt_files[vtt_base_names.index(name)] for name in sorted(vtt_base_names)]\n",
        "\n",
        "      return sorted_audio_files, sorted_vtt_files\n",
        "    sorted_audio_files, sorted_vtt_files = match_files(audio_files, vtt_files)\n",
        "    output_dir = \"/content/txt_to_speech_dataset\"\n",
        "    process_files(sorted_audio_files, sorted_vtt_files, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h5uPxxeoMkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56efed1f-4d60-48bd-a984-4b31e152a77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped directory saved to: /content/txt_to_speech_dataset.zip\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Path of the directory to zip\n",
        "directory_path = \"/content/txt_to_speech_dataset\"\n",
        "\n",
        "# Path where the zip file will be saved\n",
        "output_zip_path = \"/content/txt_to_speech_dataset.zip\"\n",
        "\n",
        "# Create a zip file\n",
        "shutil.make_archive(base_name=output_zip_path.replace('.zip', ''), format='zip', root_dir=directory_path)\n",
        "\n",
        "print(f\"Zipped directory saved to: {output_zip_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b57-k4UiYEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8bbd800-8283-4b19-dc19-e7b4965d021b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfeMOZgjhJsD"
      },
      "outputs": [],
      "source": [
        "# prompt: save this file in google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "!mkdir -p /content/drive/MyDrive/dataset/\n",
        "#!cp -r /content/txt_to_speech_dataset /content/drive/MyDrive/txt_to_speech_dataset_files\n",
        "!cp /content/txt_to_speech_dataset.zip /content/drive/MyDrive/dataset/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jOiUnXKnwYqT"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}